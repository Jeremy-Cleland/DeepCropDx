2025-03-03 23:37:25,600 - INFO - Starting experiment: resnet_attention
2025-03-03 23:37:25,600 - INFO - Command line arguments: Namespace(data_dir='data/raw', output_dir='models/resnet_attention_v1', model='resnet_attention', img_size=224, batch_size=32, num_workers=16, epochs=30, lr=0.001, weight_decay=0.0001, use_weights=True, freeze_backbone=False, no_cuda=False, no_mps=False, use_mps=True, use_amp=False, memory_efficient=True, cache_dataset=True, mps_graph=True, mps_fallback=False, pin_memory=False, optimize_for_m_series=True, patience=10, keep_top_k=3, version=None, find_lr=False, experiment_name='resnet_attention', resnet_version=50)
2025-03-03 23:37:25,600 - INFO - Processing dataset...
2025-03-03 23:37:25,825 - INFO - Class distribution:
2025-03-03 23:37:25,826 - INFO -   Tomato_healthy: 1591 images
2025-03-03 23:37:25,826 - INFO -   Potato___Early_blight: 1000 images
2025-03-03 23:37:25,826 - INFO -   Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Early_blight: 1000 images
2025-03-03 23:37:25,826 - INFO -   Tomato__Target_Spot: 1404 images
2025-03-03 23:37:25,826 - INFO -   Potato___Late_blight: 1000 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Leaf_Mold: 952 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Septoria_leaf_spot: 1771 images
2025-03-03 23:37:25,826 - INFO -   Tomato__Tomato_mosaic_virus: 373 images
2025-03-03 23:37:25,826 - INFO -   Pepper__bell___Bacterial_spot: 997 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Bacterial_spot: 2127 images
2025-03-03 23:37:25,826 - INFO -   Tomato_Late_blight: 1909 images
2025-03-03 23:37:25,826 - INFO -   Pepper__bell___healthy: 1478 images
2025-03-03 23:37:25,826 - INFO -   Potato___healthy: 152 images
2025-03-03 23:37:25,826 - INFO - Creating model: resnet_attention with 15 classes
2025-03-03 23:37:26,115 - INFO - Model architecture:
ResNetWithAttention(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (7): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (attention): ResidualAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=128, bias=False)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=128, out_features=2048, bias=False)
      (3): Sigmoid()
    )
  )
  (avg_pool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=2048, out_features=15, bias=True)
  )
)
2025-03-03 23:37:26,116 - INFO - Using class weights: [0.5015516  0.7979687  0.24874336 0.7979687  0.5683538  0.7979687
 0.8382024  0.47611496 0.4505752  2.1393263  0.8003698  0.3751616
 0.4180035  0.5398976  5.249794  ]
2025-03-03 23:37:26,116 - INFO - Training all parameters (full model)
2025-03-03 23:37:26,116 - INFO - Starting training for 30 epochs
2025-03-03 23:37:26,116 - INFO - Using Automatic Mixed Precision: False
2025-03-03 23:37:26,116 - INFO - Early stopping patience: 10
2025-03-03 23:37:26,116 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:37:26,116 - INFO - Starting training: resnet_attention
2025-03-03 23:37:26,116 - INFO - Total epochs: 30
2025-03-03 23:37:26,116 - INFO - Training batches per epoch: 452
2025-03-03 23:37:26,116 - INFO - Validation batches per epoch: 97
2025-03-03 23:37:26,116 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:37:26,117 - INFO - Training model: resnet_attention_v1
2025-03-03 23:37:26,117 - INFO - Epoch 1/30
2025-03-03 23:37:26,117 - INFO - ----------------------------------------
2025-03-03 23:37:54,060 - INFO - [TRAIN] Epoch: 1/30 | Batch: 0/452 (0.2%) | Loss: 2.7264 | Batch time: 1.16s
2025-03-03 23:38:01,075 - INFO - [TRAIN] Epoch: 1/30 | Batch: 45/452 (10.2%) | Loss: 2.3372 | Batch time: 0.15s
2025-03-03 23:38:07,919 - INFO - [TRAIN] Epoch: 1/30 | Batch: 90/452 (20.1%) | Loss: 2.2093 | Batch time: 0.15s
2025-03-03 23:38:14,927 - INFO - [TRAIN] Epoch: 1/30 | Batch: 135/452 (30.1%) | Loss: 2.5758 | Batch time: 0.16s
2025-03-03 23:38:22,000 - INFO - [TRAIN] Epoch: 1/30 | Batch: 180/452 (40.0%) | Loss: 2.2775 | Batch time: 0.16s
2025-03-03 23:38:29,121 - INFO - [TRAIN] Epoch: 1/30 | Batch: 225/452 (50.0%) | Loss: 1.8553 | Batch time: 0.16s
2025-03-03 23:38:36,295 - INFO - [TRAIN] Epoch: 1/30 | Batch: 270/452 (60.0%) | Loss: 1.6872 | Batch time: 0.16s
2025-03-03 23:38:43,554 - INFO - [TRAIN] Epoch: 1/30 | Batch: 315/452 (69.9%) | Loss: 1.8756 | Batch time: 0.16s
2025-03-03 23:38:50,795 - INFO - [TRAIN] Epoch: 1/30 | Batch: 360/452 (79.9%) | Loss: 1.4854 | Batch time: 0.16s
2025-03-03 23:38:58,037 - INFO - [TRAIN] Epoch: 1/30 | Batch: 405/452 (89.8%) | Loss: 1.1709 | Batch time: 0.16s
2025-03-03 23:39:05,281 - INFO - [TRAIN] Epoch: 1/30 | Batch: 450/452 (99.8%) | Loss: 1.6030 | Batch time: 0.16s
2025-03-03 23:39:05,646 - INFO - [TRAIN] Epoch: 1/30 | Batch: 451/452 (100.0%) | Loss: 0.9611 | Batch time: 0.36s
2025-03-03 23:39:35,353 - INFO - [VAL] Epoch: 1/30 | Batch: 0/97 (1.0%) | Loss: 1.0463 | Batch time: 0.57s
2025-03-03 23:39:35,732 - INFO - [VAL] Epoch: 1/30 | Batch: 9/97 (10.3%) | Loss: 0.8698 | Batch time: 0.04s
2025-03-03 23:39:36,110 - INFO - [VAL] Epoch: 1/30 | Batch: 18/97 (19.6%) | Loss: 1.2099 | Batch time: 0.04s
2025-03-03 23:39:36,482 - INFO - [VAL] Epoch: 1/30 | Batch: 27/97 (28.9%) | Loss: 0.7625 | Batch time: 0.04s
2025-03-03 23:39:36,858 - INFO - [VAL] Epoch: 1/30 | Batch: 36/97 (38.1%) | Loss: 0.8965 | Batch time: 0.04s
2025-03-03 23:39:37,231 - INFO - [VAL] Epoch: 1/30 | Batch: 45/97 (47.4%) | Loss: 0.8070 | Batch time: 0.04s
2025-03-03 23:39:37,602 - INFO - [VAL] Epoch: 1/30 | Batch: 54/97 (56.7%) | Loss: 1.0389 | Batch time: 0.04s
2025-03-03 23:39:37,985 - INFO - [VAL] Epoch: 1/30 | Batch: 63/97 (66.0%) | Loss: 0.6067 | Batch time: 0.04s
2025-03-03 23:39:38,362 - INFO - [VAL] Epoch: 1/30 | Batch: 72/97 (75.3%) | Loss: 0.9998 | Batch time: 0.04s
2025-03-03 23:39:38,737 - INFO - [VAL] Epoch: 1/30 | Batch: 81/97 (84.5%) | Loss: 0.7097 | Batch time: 0.04s
2025-03-03 23:39:39,108 - INFO - [VAL] Epoch: 1/30 | Batch: 90/97 (93.8%) | Loss: 0.7137 | Batch time: 0.04s
2025-03-03 23:39:39,460 - INFO - [VAL] Epoch: 1/30 | Batch: 96/97 (100.0%) | Loss: 1.0344 | Batch time: 0.14s
2025-03-03 23:39:40,518 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 1)
2025-03-03 23:39:40,518 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:39:40,518 - INFO - Epoch 1/30 completed in 134.40s
2025-03-03 23:39:40,518 - INFO - Training   - Loss: 1.9101, Accuracy: 0.3913, F1: 0.3983
2025-03-03 23:39:40,518 - INFO - Validation - Loss: 1.0044, Accuracy: 0.6321, F1: 0.6438
2025-03-03 23:39:40,518 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:39:40,518 - INFO - Epoch 2/30
2025-03-03 23:39:40,518 - INFO - ----------------------------------------
2025-03-03 23:39:41,019 - INFO - [TRAIN] Epoch: 2/30 | Batch: 0/452 (0.2%) | Loss: 1.2614 | Batch time: 0.23s
2025-03-03 23:39:47,843 - INFO - [TRAIN] Epoch: 2/30 | Batch: 45/452 (10.2%) | Loss: 0.8970 | Batch time: 0.15s
2025-03-03 23:39:54,769 - INFO - [TRAIN] Epoch: 2/30 | Batch: 90/452 (20.1%) | Loss: 1.3010 | Batch time: 0.15s
2025-03-03 23:40:01,824 - INFO - [TRAIN] Epoch: 2/30 | Batch: 135/452 (30.1%) | Loss: 1.4254 | Batch time: 0.15s
2025-03-03 23:40:08,971 - INFO - [TRAIN] Epoch: 2/30 | Batch: 180/452 (40.0%) | Loss: 1.1393 | Batch time: 0.16s
2025-03-03 23:40:16,110 - INFO - [TRAIN] Epoch: 2/30 | Batch: 225/452 (50.0%) | Loss: 1.2214 | Batch time: 0.16s
2025-03-03 23:40:23,236 - INFO - [TRAIN] Epoch: 2/30 | Batch: 270/452 (60.0%) | Loss: 1.5326 | Batch time: 0.16s
2025-03-03 23:40:30,342 - INFO - [TRAIN] Epoch: 2/30 | Batch: 315/452 (69.9%) | Loss: 1.0814 | Batch time: 0.16s
2025-03-03 23:40:37,441 - INFO - [TRAIN] Epoch: 2/30 | Batch: 360/452 (79.9%) | Loss: 1.5249 | Batch time: 0.16s
2025-03-03 23:40:44,566 - INFO - [TRAIN] Epoch: 2/30 | Batch: 405/452 (89.8%) | Loss: 1.1635 | Batch time: 0.16s
2025-03-03 23:40:51,711 - INFO - [TRAIN] Epoch: 2/30 | Batch: 450/452 (99.8%) | Loss: 0.7416 | Batch time: 0.16s
2025-03-03 23:40:51,790 - INFO - [TRAIN] Epoch: 2/30 | Batch: 451/452 (100.0%) | Loss: 0.9041 | Batch time: 0.08s
2025-03-03 23:40:51,899 - INFO - [VAL] Epoch: 2/30 | Batch: 0/97 (1.0%) | Loss: 0.9080 | Batch time: 0.04s
2025-03-03 23:40:52,279 - INFO - [VAL] Epoch: 2/30 | Batch: 9/97 (10.3%) | Loss: 0.5856 | Batch time: 0.04s
2025-03-03 23:40:52,660 - INFO - [VAL] Epoch: 2/30 | Batch: 18/97 (19.6%) | Loss: 0.5984 | Batch time: 0.04s
2025-03-03 23:40:53,066 - INFO - [VAL] Epoch: 2/30 | Batch: 27/97 (28.9%) | Loss: 0.6822 | Batch time: 0.04s
2025-03-03 23:40:53,461 - INFO - [VAL] Epoch: 2/30 | Batch: 36/97 (38.1%) | Loss: 0.4908 | Batch time: 0.04s
2025-03-03 23:40:53,859 - INFO - [VAL] Epoch: 2/30 | Batch: 45/97 (47.4%) | Loss: 0.7230 | Batch time: 0.04s
2025-03-03 23:40:54,258 - INFO - [VAL] Epoch: 2/30 | Batch: 54/97 (56.7%) | Loss: 0.4644 | Batch time: 0.04s
2025-03-03 23:40:54,654 - INFO - [VAL] Epoch: 2/30 | Batch: 63/97 (66.0%) | Loss: 0.7952 | Batch time: 0.04s
2025-03-03 23:40:55,053 - INFO - [VAL] Epoch: 2/30 | Batch: 72/97 (75.3%) | Loss: 0.7282 | Batch time: 0.04s
2025-03-03 23:40:55,447 - INFO - [VAL] Epoch: 2/30 | Batch: 81/97 (84.5%) | Loss: 0.3959 | Batch time: 0.04s
2025-03-03 23:40:55,838 - INFO - [VAL] Epoch: 2/30 | Batch: 90/97 (93.8%) | Loss: 0.5219 | Batch time: 0.04s
2025-03-03 23:40:56,100 - INFO - [VAL] Epoch: 2/30 | Batch: 96/97 (100.0%) | Loss: 0.6194 | Batch time: 0.05s
2025-03-03 23:40:56,827 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 2)
2025-03-03 23:40:56,827 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:40:56,827 - INFO - Epoch 2/30 completed in 76.31s
2025-03-03 23:40:56,827 - INFO - Training   - Loss: 1.2411, Accuracy: 0.5952, F1: 0.6013
2025-03-03 23:40:56,827 - INFO - Validation - Loss: 0.6776, Accuracy: 0.7829, F1: 0.7740
2025-03-03 23:40:56,827 - INFO - Validation F1 improved from 0.6438 to 0.7740
2025-03-03 23:40:56,827 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:40:56,827 - INFO - Epoch 3/30
2025-03-03 23:40:56,827 - INFO - ----------------------------------------
2025-03-03 23:40:57,269 - INFO - [TRAIN] Epoch: 3/30 | Batch: 0/452 (0.2%) | Loss: 1.0428 | Batch time: 0.22s
2025-03-03 23:41:04,421 - INFO - [TRAIN] Epoch: 3/30 | Batch: 45/452 (10.2%) | Loss: 1.0081 | Batch time: 0.16s
2025-03-03 23:41:11,875 - INFO - [TRAIN] Epoch: 3/30 | Batch: 90/452 (20.1%) | Loss: 1.1824 | Batch time: 0.16s
2025-03-03 23:41:19,330 - INFO - [TRAIN] Epoch: 3/30 | Batch: 135/452 (30.1%) | Loss: 0.7445 | Batch time: 0.17s
2025-03-03 23:41:26,891 - INFO - [TRAIN] Epoch: 3/30 | Batch: 180/452 (40.0%) | Loss: 1.2231 | Batch time: 0.17s
2025-03-03 23:41:34,473 - INFO - [TRAIN] Epoch: 3/30 | Batch: 225/452 (50.0%) | Loss: 1.1666 | Batch time: 0.17s
2025-03-03 23:41:42,096 - INFO - [TRAIN] Epoch: 3/30 | Batch: 270/452 (60.0%) | Loss: 1.0033 | Batch time: 0.17s
2025-03-03 23:41:49,833 - INFO - [TRAIN] Epoch: 3/30 | Batch: 315/452 (69.9%) | Loss: 0.7683 | Batch time: 0.17s
2025-03-03 23:41:57,613 - INFO - [TRAIN] Epoch: 3/30 | Batch: 360/452 (79.9%) | Loss: 0.6226 | Batch time: 0.17s
2025-03-03 23:42:05,464 - INFO - [TRAIN] Epoch: 3/30 | Batch: 405/452 (89.8%) | Loss: 0.8531 | Batch time: 0.17s
2025-03-03 23:42:13,282 - INFO - [TRAIN] Epoch: 3/30 | Batch: 450/452 (99.8%) | Loss: 1.0422 | Batch time: 0.17s
2025-03-03 23:42:13,366 - INFO - [TRAIN] Epoch: 3/30 | Batch: 451/452 (100.0%) | Loss: 1.5630 | Batch time: 0.08s
2025-03-03 23:42:13,477 - INFO - [VAL] Epoch: 3/30 | Batch: 0/97 (1.0%) | Loss: 0.5179 | Batch time: 0.05s
2025-03-03 23:42:13,891 - INFO - [VAL] Epoch: 3/30 | Batch: 9/97 (10.3%) | Loss: 0.3507 | Batch time: 0.05s
2025-03-03 23:42:14,322 - INFO - [VAL] Epoch: 3/30 | Batch: 18/97 (19.6%) | Loss: 1.0101 | Batch time: 0.05s
2025-03-03 23:42:14,776 - INFO - [VAL] Epoch: 3/30 | Batch: 27/97 (28.9%) | Loss: 0.6157 | Batch time: 0.05s
2025-03-03 23:42:15,225 - INFO - [VAL] Epoch: 3/30 | Batch: 36/97 (38.1%) | Loss: 0.5605 | Batch time: 0.05s
2025-03-03 23:42:15,676 - INFO - [VAL] Epoch: 3/30 | Batch: 45/97 (47.4%) | Loss: 0.6866 | Batch time: 0.05s
2025-03-03 23:42:16,129 - INFO - [VAL] Epoch: 3/30 | Batch: 54/97 (56.7%) | Loss: 0.5058 | Batch time: 0.05s
2025-03-03 23:42:16,579 - INFO - [VAL] Epoch: 3/30 | Batch: 63/97 (66.0%) | Loss: 0.5881 | Batch time: 0.05s
2025-03-03 23:42:17,028 - INFO - [VAL] Epoch: 3/30 | Batch: 72/97 (75.3%) | Loss: 0.9229 | Batch time: 0.05s
2025-03-03 23:42:17,464 - INFO - [VAL] Epoch: 3/30 | Batch: 81/97 (84.5%) | Loss: 0.3106 | Batch time: 0.05s
2025-03-03 23:42:17,896 - INFO - [VAL] Epoch: 3/30 | Batch: 90/97 (93.8%) | Loss: 0.4564 | Batch time: 0.05s
2025-03-03 23:42:18,176 - INFO - [VAL] Epoch: 3/30 | Batch: 96/97 (100.0%) | Loss: 0.4741 | Batch time: 0.04s
2025-03-03 23:42:18,180 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:42:18,180 - INFO - Epoch 3/30 completed in 81.35s
2025-03-03 23:42:18,180 - INFO - Training   - Loss: 0.9764, Accuracy: 0.6753, F1: 0.6801
2025-03-03 23:42:18,180 - INFO - Validation - Loss: 0.6957, Accuracy: 0.7729, F1: 0.7704
2025-03-03 23:42:18,180 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:42:18,180 - INFO - Epoch 4/30
2025-03-03 23:42:18,180 - INFO - ----------------------------------------
2025-03-03 23:42:18,565 - INFO - [TRAIN] Epoch: 4/30 | Batch: 0/452 (0.2%) | Loss: 0.3909 | Batch time: 0.19s
2025-03-03 23:42:26,591 - INFO - [TRAIN] Epoch: 4/30 | Batch: 45/452 (10.2%) | Loss: 0.7030 | Batch time: 0.18s
2025-03-03 23:42:34,653 - INFO - [TRAIN] Epoch: 4/30 | Batch: 90/452 (20.1%) | Loss: 0.6218 | Batch time: 0.18s
2025-03-03 23:42:42,796 - INFO - [TRAIN] Epoch: 4/30 | Batch: 135/452 (30.1%) | Loss: 0.9212 | Batch time: 0.18s
2025-03-03 23:42:51,023 - INFO - [TRAIN] Epoch: 4/30 | Batch: 180/452 (40.0%) | Loss: 1.2553 | Batch time: 0.18s
2025-03-03 23:42:59,217 - INFO - [TRAIN] Epoch: 4/30 | Batch: 225/452 (50.0%) | Loss: 1.6344 | Batch time: 0.18s
2025-03-03 23:43:07,409 - INFO - [TRAIN] Epoch: 4/30 | Batch: 270/452 (60.0%) | Loss: 0.8970 | Batch time: 0.18s
2025-03-03 23:43:15,681 - INFO - [TRAIN] Epoch: 4/30 | Batch: 315/452 (69.9%) | Loss: 0.7724 | Batch time: 0.18s
2025-03-03 23:43:23,961 - INFO - [TRAIN] Epoch: 4/30 | Batch: 360/452 (79.9%) | Loss: 0.7340 | Batch time: 0.18s
2025-03-03 23:43:32,279 - INFO - [TRAIN] Epoch: 4/30 | Batch: 405/452 (89.8%) | Loss: 0.6903 | Batch time: 0.18s
2025-03-03 23:43:40,286 - INFO - [TRAIN] Epoch: 4/30 | Batch: 450/452 (99.8%) | Loss: 0.9779 | Batch time: 0.17s
2025-03-03 23:43:40,373 - INFO - [TRAIN] Epoch: 4/30 | Batch: 451/452 (100.0%) | Loss: 1.0482 | Batch time: 0.09s
2025-03-03 23:43:40,484 - INFO - [VAL] Epoch: 4/30 | Batch: 0/97 (1.0%) | Loss: 0.1958 | Batch time: 0.05s
2025-03-03 23:43:40,905 - INFO - [VAL] Epoch: 4/30 | Batch: 9/97 (10.3%) | Loss: 0.2131 | Batch time: 0.05s
2025-03-03 23:43:41,352 - INFO - [VAL] Epoch: 4/30 | Batch: 18/97 (19.6%) | Loss: 0.5383 | Batch time: 0.05s
2025-03-03 23:43:41,818 - INFO - [VAL] Epoch: 4/30 | Batch: 27/97 (28.9%) | Loss: 0.2079 | Batch time: 0.05s
2025-03-03 23:43:42,292 - INFO - [VAL] Epoch: 4/30 | Batch: 36/97 (38.1%) | Loss: 0.2014 | Batch time: 0.05s
2025-03-03 23:43:42,767 - INFO - [VAL] Epoch: 4/30 | Batch: 45/97 (47.4%) | Loss: 0.4859 | Batch time: 0.05s
2025-03-03 23:43:43,235 - INFO - [VAL] Epoch: 4/30 | Batch: 54/97 (56.7%) | Loss: 0.3207 | Batch time: 0.05s
2025-03-03 23:43:43,698 - INFO - [VAL] Epoch: 4/30 | Batch: 63/97 (66.0%) | Loss: 0.1232 | Batch time: 0.05s
2025-03-03 23:43:44,157 - INFO - [VAL] Epoch: 4/30 | Batch: 72/97 (75.3%) | Loss: 0.7297 | Batch time: 0.05s
2025-03-03 23:43:44,612 - INFO - [VAL] Epoch: 4/30 | Batch: 81/97 (84.5%) | Loss: 0.2911 | Batch time: 0.05s
2025-03-03 23:43:45,057 - INFO - [VAL] Epoch: 4/30 | Batch: 90/97 (93.8%) | Loss: 0.2304 | Batch time: 0.05s
2025-03-03 23:43:45,351 - INFO - [VAL] Epoch: 4/30 | Batch: 96/97 (100.0%) | Loss: 0.1865 | Batch time: 0.05s
2025-03-03 23:43:46,089 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 4)
2025-03-03 23:43:46,089 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:43:46,089 - INFO - Epoch 4/30 completed in 87.91s
2025-03-03 23:43:46,089 - INFO - Training   - Loss: 0.8454, Accuracy: 0.7241, F1: 0.7279
2025-03-03 23:43:46,089 - INFO - Validation - Loss: 0.4333, Accuracy: 0.8443, F1: 0.8408
2025-03-03 23:43:46,089 - INFO - Validation F1 improved from 0.7740 to 0.8408
2025-03-03 23:43:46,089 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:43:46,089 - INFO - Epoch 5/30
2025-03-03 23:43:46,089 - INFO - ----------------------------------------
2025-03-03 23:43:46,516 - INFO - [TRAIN] Epoch: 5/30 | Batch: 0/452 (0.2%) | Loss: 0.7553 | Batch time: 0.22s
2025-03-03 23:43:54,599 - INFO - [TRAIN] Epoch: 5/30 | Batch: 45/452 (10.2%) | Loss: 0.6538 | Batch time: 0.18s
2025-03-03 23:44:02,739 - INFO - [TRAIN] Epoch: 5/30 | Batch: 90/452 (20.1%) | Loss: 0.5652 | Batch time: 0.18s
2025-03-03 23:44:10,803 - INFO - [TRAIN] Epoch: 5/30 | Batch: 135/452 (30.1%) | Loss: 0.6583 | Batch time: 0.18s
2025-03-03 23:44:18,914 - INFO - [TRAIN] Epoch: 5/30 | Batch: 180/452 (40.0%) | Loss: 1.3074 | Batch time: 0.18s
2025-03-03 23:44:27,000 - INFO - [TRAIN] Epoch: 5/30 | Batch: 225/452 (50.0%) | Loss: 0.7770 | Batch time: 0.18s
2025-03-03 23:44:35,069 - INFO - [TRAIN] Epoch: 5/30 | Batch: 270/452 (60.0%) | Loss: 1.0554 | Batch time: 0.18s
2025-03-03 23:44:43,082 - INFO - [TRAIN] Epoch: 5/30 | Batch: 315/452 (69.9%) | Loss: 0.5046 | Batch time: 0.18s
2025-03-03 23:44:51,082 - INFO - [TRAIN] Epoch: 5/30 | Batch: 360/452 (79.9%) | Loss: 0.4472 | Batch time: 0.18s
2025-03-03 23:44:59,150 - INFO - [TRAIN] Epoch: 5/30 | Batch: 405/452 (89.8%) | Loss: 0.9558 | Batch time: 0.18s
2025-03-03 23:45:07,040 - INFO - [TRAIN] Epoch: 5/30 | Batch: 450/452 (99.8%) | Loss: 0.6635 | Batch time: 0.17s
2025-03-03 23:45:07,125 - INFO - [TRAIN] Epoch: 5/30 | Batch: 451/452 (100.0%) | Loss: 0.6842 | Batch time: 0.08s
2025-03-03 23:45:07,237 - INFO - [VAL] Epoch: 5/30 | Batch: 0/97 (1.0%) | Loss: 0.3422 | Batch time: 0.05s
2025-03-03 23:45:07,649 - INFO - [VAL] Epoch: 5/30 | Batch: 9/97 (10.3%) | Loss: 0.2718 | Batch time: 0.05s
2025-03-03 23:45:08,083 - INFO - [VAL] Epoch: 5/30 | Batch: 18/97 (19.6%) | Loss: 0.6721 | Batch time: 0.05s
2025-03-03 23:45:08,545 - INFO - [VAL] Epoch: 5/30 | Batch: 27/97 (28.9%) | Loss: 0.3224 | Batch time: 0.05s
2025-03-03 23:45:09,002 - INFO - [VAL] Epoch: 5/30 | Batch: 36/97 (38.1%) | Loss: 0.3113 | Batch time: 0.05s
2025-03-03 23:45:09,462 - INFO - [VAL] Epoch: 5/30 | Batch: 45/97 (47.4%) | Loss: 0.7067 | Batch time: 0.05s
2025-03-03 23:45:09,920 - INFO - [VAL] Epoch: 5/30 | Batch: 54/97 (56.7%) | Loss: 0.2159 | Batch time: 0.05s
2025-03-03 23:45:10,373 - INFO - [VAL] Epoch: 5/30 | Batch: 63/97 (66.0%) | Loss: 0.2913 | Batch time: 0.05s
2025-03-03 23:45:10,824 - INFO - [VAL] Epoch: 5/30 | Batch: 72/97 (75.3%) | Loss: 0.5263 | Batch time: 0.05s
2025-03-03 23:45:11,263 - INFO - [VAL] Epoch: 5/30 | Batch: 81/97 (84.5%) | Loss: 0.3834 | Batch time: 0.05s
2025-03-03 23:45:11,694 - INFO - [VAL] Epoch: 5/30 | Batch: 90/97 (93.8%) | Loss: 0.1852 | Batch time: 0.05s
2025-03-03 23:45:11,976 - INFO - [VAL] Epoch: 5/30 | Batch: 96/97 (100.0%) | Loss: 0.5253 | Batch time: 0.04s
2025-03-03 23:45:11,980 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:45:11,980 - INFO - Epoch 5/30 completed in 85.89s
2025-03-03 23:45:11,981 - INFO - Training   - Loss: 0.7901, Accuracy: 0.7370, F1: 0.7398
2025-03-03 23:45:11,981 - INFO - Validation - Loss: 0.4774, Accuracy: 0.8346, F1: 0.8323
2025-03-03 23:45:11,981 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:45:12,471 - INFO - Checkpoint saved: checkpoint_epoch_5.pth (Epoch 5)
2025-03-03 23:45:12,471 - INFO - Epoch 6/30
2025-03-03 23:45:12,471 - INFO - ----------------------------------------
2025-03-03 23:45:12,853 - INFO - [TRAIN] Epoch: 6/30 | Batch: 0/452 (0.2%) | Loss: 0.8507 | Batch time: 0.18s
2025-03-03 23:45:20,776 - INFO - [TRAIN] Epoch: 6/30 | Batch: 45/452 (10.2%) | Loss: 0.9896 | Batch time: 0.17s
2025-03-03 23:45:28,786 - INFO - [TRAIN] Epoch: 6/30 | Batch: 90/452 (20.1%) | Loss: 0.5561 | Batch time: 0.18s
2025-03-03 23:45:36,795 - INFO - [TRAIN] Epoch: 6/30 | Batch: 135/452 (30.1%) | Loss: 0.5339 | Batch time: 0.18s
2025-03-03 23:45:44,791 - INFO - [TRAIN] Epoch: 6/30 | Batch: 180/452 (40.0%) | Loss: 0.6735 | Batch time: 0.18s
2025-03-03 23:45:52,773 - INFO - [TRAIN] Epoch: 6/30 | Batch: 225/452 (50.0%) | Loss: 0.7145 | Batch time: 0.18s
2025-03-03 23:46:00,784 - INFO - [TRAIN] Epoch: 6/30 | Batch: 270/452 (60.0%) | Loss: 1.0515 | Batch time: 0.18s
2025-03-03 23:46:08,840 - INFO - [TRAIN] Epoch: 6/30 | Batch: 315/452 (69.9%) | Loss: 0.8484 | Batch time: 0.18s
2025-03-03 23:46:16,907 - INFO - [TRAIN] Epoch: 6/30 | Batch: 360/452 (79.9%) | Loss: 0.6490 | Batch time: 0.18s
2025-03-03 23:46:25,086 - INFO - [TRAIN] Epoch: 6/30 | Batch: 405/452 (89.8%) | Loss: 0.6332 | Batch time: 0.19s
2025-03-03 23:46:33,248 - INFO - [TRAIN] Epoch: 6/30 | Batch: 450/452 (99.8%) | Loss: 0.5542 | Batch time: 0.18s
2025-03-03 23:46:33,343 - INFO - [TRAIN] Epoch: 6/30 | Batch: 451/452 (100.0%) | Loss: 1.5367 | Batch time: 0.09s
2025-03-03 23:46:33,511 - INFO - [VAL] Epoch: 6/30 | Batch: 0/97 (1.0%) | Loss: 0.0738 | Batch time: 0.05s
2025-03-03 23:46:33,954 - INFO - [VAL] Epoch: 6/30 | Batch: 9/97 (10.3%) | Loss: 0.1842 | Batch time: 0.05s
2025-03-03 23:46:34,415 - INFO - [VAL] Epoch: 6/30 | Batch: 18/97 (19.6%) | Loss: 0.5460 | Batch time: 0.05s
2025-03-03 23:46:34,883 - INFO - [VAL] Epoch: 6/30 | Batch: 27/97 (28.9%) | Loss: 0.2489 | Batch time: 0.05s
2025-03-03 23:46:35,350 - INFO - [VAL] Epoch: 6/30 | Batch: 36/97 (38.1%) | Loss: 0.1584 | Batch time: 0.05s
2025-03-03 23:46:35,806 - INFO - [VAL] Epoch: 6/30 | Batch: 45/97 (47.4%) | Loss: 0.2818 | Batch time: 0.05s
2025-03-03 23:46:36,260 - INFO - [VAL] Epoch: 6/30 | Batch: 54/97 (56.7%) | Loss: 0.1170 | Batch time: 0.05s
2025-03-03 23:46:36,713 - INFO - [VAL] Epoch: 6/30 | Batch: 63/97 (66.0%) | Loss: 0.1264 | Batch time: 0.05s
2025-03-03 23:46:37,159 - INFO - [VAL] Epoch: 6/30 | Batch: 72/97 (75.3%) | Loss: 0.3190 | Batch time: 0.05s
2025-03-03 23:46:37,605 - INFO - [VAL] Epoch: 6/30 | Batch: 81/97 (84.5%) | Loss: 0.1549 | Batch time: 0.05s
2025-03-03 23:46:38,048 - INFO - [VAL] Epoch: 6/30 | Batch: 90/97 (93.8%) | Loss: 0.1903 | Batch time: 0.05s
2025-03-03 23:46:38,347 - INFO - [VAL] Epoch: 6/30 | Batch: 96/97 (100.0%) | Loss: 0.4166 | Batch time: 0.05s
2025-03-03 23:46:39,160 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 6)
2025-03-03 23:46:39,160 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:46:39,160 - INFO - Epoch 6/30 completed in 86.69s
2025-03-03 23:46:39,160 - INFO - Training   - Loss: 0.6969, Accuracy: 0.7704, F1: 0.7727
2025-03-03 23:46:39,160 - INFO - Validation - Loss: 0.2801, Accuracy: 0.8970, F1: 0.9000
2025-03-03 23:46:39,160 - INFO - Validation F1 improved from 0.8408 to 0.9000
2025-03-03 23:46:39,160 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:46:39,160 - INFO - Epoch 7/30
2025-03-03 23:46:39,160 - INFO - ----------------------------------------
2025-03-03 23:46:39,622 - INFO - [TRAIN] Epoch: 7/30 | Batch: 0/452 (0.2%) | Loss: 0.4209 | Batch time: 0.23s
2025-03-03 23:46:47,477 - INFO - [TRAIN] Epoch: 7/30 | Batch: 45/452 (10.2%) | Loss: 0.8030 | Batch time: 0.17s
2025-03-03 23:46:55,446 - INFO - [TRAIN] Epoch: 7/30 | Batch: 90/452 (20.1%) | Loss: 0.4742 | Batch time: 0.18s
2025-03-03 23:47:03,379 - INFO - [TRAIN] Epoch: 7/30 | Batch: 135/452 (30.1%) | Loss: 0.5741 | Batch time: 0.18s
2025-03-03 23:47:11,466 - INFO - [TRAIN] Epoch: 7/30 | Batch: 180/452 (40.0%) | Loss: 0.3609 | Batch time: 0.18s
2025-03-03 23:47:19,417 - INFO - [TRAIN] Epoch: 7/30 | Batch: 225/452 (50.0%) | Loss: 0.8582 | Batch time: 0.18s
2025-03-03 23:47:27,551 - INFO - [TRAIN] Epoch: 7/30 | Batch: 270/452 (60.0%) | Loss: 0.3900 | Batch time: 0.18s
2025-03-03 23:47:35,860 - INFO - [TRAIN] Epoch: 7/30 | Batch: 315/452 (69.9%) | Loss: 0.6937 | Batch time: 0.19s
2025-03-03 23:47:44,069 - INFO - [TRAIN] Epoch: 7/30 | Batch: 360/452 (79.9%) | Loss: 0.5412 | Batch time: 0.18s
2025-03-03 23:47:52,037 - INFO - [TRAIN] Epoch: 7/30 | Batch: 405/452 (89.8%) | Loss: 0.5609 | Batch time: 0.18s
2025-03-03 23:47:59,881 - INFO - [TRAIN] Epoch: 7/30 | Batch: 450/452 (99.8%) | Loss: 0.6349 | Batch time: 0.17s
2025-03-03 23:47:59,966 - INFO - [TRAIN] Epoch: 7/30 | Batch: 451/452 (100.0%) | Loss: 0.6988 | Batch time: 0.08s
2025-03-03 23:48:00,082 - INFO - [VAL] Epoch: 7/30 | Batch: 0/97 (1.0%) | Loss: 0.1340 | Batch time: 0.05s
2025-03-03 23:48:00,493 - INFO - [VAL] Epoch: 7/30 | Batch: 9/97 (10.3%) | Loss: 0.2884 | Batch time: 0.05s
2025-03-03 23:48:00,921 - INFO - [VAL] Epoch: 7/30 | Batch: 18/97 (19.6%) | Loss: 0.3316 | Batch time: 0.05s
2025-03-03 23:48:01,373 - INFO - [VAL] Epoch: 7/30 | Batch: 27/97 (28.9%) | Loss: 0.2017 | Batch time: 0.05s
2025-03-03 23:48:01,814 - INFO - [VAL] Epoch: 7/30 | Batch: 36/97 (38.1%) | Loss: 0.2339 | Batch time: 0.05s
2025-03-03 23:48:02,254 - INFO - [VAL] Epoch: 7/30 | Batch: 45/97 (47.4%) | Loss: 0.3590 | Batch time: 0.05s
2025-03-03 23:48:02,692 - INFO - [VAL] Epoch: 7/30 | Batch: 54/97 (56.7%) | Loss: 0.1318 | Batch time: 0.05s
2025-03-03 23:48:03,129 - INFO - [VAL] Epoch: 7/30 | Batch: 63/97 (66.0%) | Loss: 0.1478 | Batch time: 0.05s
2025-03-03 23:48:03,566 - INFO - [VAL] Epoch: 7/30 | Batch: 72/97 (75.3%) | Loss: 0.5045 | Batch time: 0.05s
2025-03-03 23:48:03,996 - INFO - [VAL] Epoch: 7/30 | Batch: 81/97 (84.5%) | Loss: 0.1487 | Batch time: 0.05s
2025-03-03 23:48:04,422 - INFO - [VAL] Epoch: 7/30 | Batch: 90/97 (93.8%) | Loss: 0.0866 | Batch time: 0.05s
2025-03-03 23:48:04,704 - INFO - [VAL] Epoch: 7/30 | Batch: 96/97 (100.0%) | Loss: 0.1540 | Batch time: 0.05s
2025-03-03 23:48:04,708 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:48:04,708 - INFO - Epoch 7/30 completed in 85.55s
2025-03-03 23:48:04,708 - INFO - Training   - Loss: 0.6454, Accuracy: 0.7865, F1: 0.7887
2025-03-03 23:48:04,708 - INFO - Validation - Loss: 0.2897, Accuracy: 0.8963, F1: 0.8952
2025-03-03 23:48:04,708 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:48:04,708 - INFO - Epoch 8/30
2025-03-03 23:48:04,708 - INFO - ----------------------------------------
2025-03-03 23:48:05,078 - INFO - [TRAIN] Epoch: 8/30 | Batch: 0/452 (0.2%) | Loss: 0.5185 | Batch time: 0.19s
2025-03-03 23:48:12,869 - INFO - [TRAIN] Epoch: 8/30 | Batch: 45/452 (10.2%) | Loss: 0.7022 | Batch time: 0.17s
2025-03-03 23:48:20,662 - INFO - [TRAIN] Epoch: 8/30 | Batch: 90/452 (20.1%) | Loss: 0.9018 | Batch time: 0.17s
2025-03-03 23:48:28,486 - INFO - [TRAIN] Epoch: 8/30 | Batch: 135/452 (30.1%) | Loss: 0.1981 | Batch time: 0.17s
2025-03-03 23:48:36,336 - INFO - [TRAIN] Epoch: 8/30 | Batch: 180/452 (40.0%) | Loss: 0.3453 | Batch time: 0.17s
2025-03-03 23:48:44,178 - INFO - [TRAIN] Epoch: 8/30 | Batch: 225/452 (50.0%) | Loss: 0.4359 | Batch time: 0.17s
2025-03-03 23:48:52,014 - INFO - [TRAIN] Epoch: 8/30 | Batch: 270/452 (60.0%) | Loss: 0.7842 | Batch time: 0.17s
2025-03-03 23:48:59,853 - INFO - [TRAIN] Epoch: 8/30 | Batch: 315/452 (69.9%) | Loss: 0.2171 | Batch time: 0.17s
2025-03-03 23:49:07,692 - INFO - [TRAIN] Epoch: 8/30 | Batch: 360/452 (79.9%) | Loss: 0.5478 | Batch time: 0.17s
2025-03-03 23:49:15,543 - INFO - [TRAIN] Epoch: 8/30 | Batch: 405/452 (89.8%) | Loss: 0.4543 | Batch time: 0.17s
2025-03-03 23:49:23,364 - INFO - [TRAIN] Epoch: 8/30 | Batch: 450/452 (99.8%) | Loss: 0.2029 | Batch time: 0.17s
2025-03-03 23:49:23,450 - INFO - [TRAIN] Epoch: 8/30 | Batch: 451/452 (100.0%) | Loss: 0.8426 | Batch time: 0.08s
2025-03-03 23:49:23,559 - INFO - [VAL] Epoch: 8/30 | Batch: 0/97 (1.0%) | Loss: 0.0225 | Batch time: 0.05s
2025-03-03 23:49:23,973 - INFO - [VAL] Epoch: 8/30 | Batch: 9/97 (10.3%) | Loss: 0.0387 | Batch time: 0.05s
2025-03-03 23:49:24,406 - INFO - [VAL] Epoch: 8/30 | Batch: 18/97 (19.6%) | Loss: 0.2140 | Batch time: 0.05s
2025-03-03 23:49:24,852 - INFO - [VAL] Epoch: 8/30 | Batch: 27/97 (28.9%) | Loss: 0.0893 | Batch time: 0.05s
2025-03-03 23:49:25,308 - INFO - [VAL] Epoch: 8/30 | Batch: 36/97 (38.1%) | Loss: 0.0739 | Batch time: 0.05s
2025-03-03 23:49:25,768 - INFO - [VAL] Epoch: 8/30 | Batch: 45/97 (47.4%) | Loss: 0.1304 | Batch time: 0.05s
2025-03-03 23:49:26,242 - INFO - [VAL] Epoch: 8/30 | Batch: 54/97 (56.7%) | Loss: 0.0569 | Batch time: 0.05s
2025-03-03 23:49:26,732 - INFO - [VAL] Epoch: 8/30 | Batch: 63/97 (66.0%) | Loss: 0.0556 | Batch time: 0.05s
2025-03-03 23:49:27,258 - INFO - [VAL] Epoch: 8/30 | Batch: 72/97 (75.3%) | Loss: 0.3299 | Batch time: 0.06s
2025-03-03 23:49:27,752 - INFO - [VAL] Epoch: 8/30 | Batch: 81/97 (84.5%) | Loss: 0.0562 | Batch time: 0.05s
2025-03-03 23:49:28,194 - INFO - [VAL] Epoch: 8/30 | Batch: 90/97 (93.8%) | Loss: 0.0464 | Batch time: 0.05s
2025-03-03 23:49:28,484 - INFO - [VAL] Epoch: 8/30 | Batch: 96/97 (100.0%) | Loss: 0.2672 | Batch time: 0.05s
2025-03-03 23:49:29,219 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 8)
2025-03-03 23:49:29,219 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:49:29,219 - INFO - Epoch 8/30 completed in 84.51s
2025-03-03 23:49:29,219 - INFO - Training   - Loss: 0.4781, Accuracy: 0.8447, F1: 0.8461
2025-03-03 23:49:29,219 - INFO - Validation - Loss: 0.1481, Accuracy: 0.9422, F1: 0.9422
2025-03-03 23:49:29,219 - INFO - Validation F1 improved from 0.9000 to 0.9422
2025-03-03 23:49:29,219 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:49:29,219 - INFO - Epoch 9/30
2025-03-03 23:49:29,219 - INFO - ----------------------------------------
2025-03-03 23:49:29,664 - INFO - [TRAIN] Epoch: 9/30 | Batch: 0/452 (0.2%) | Loss: 0.5197 | Batch time: 0.23s
2025-03-03 23:49:37,580 - INFO - [TRAIN] Epoch: 9/30 | Batch: 45/452 (10.2%) | Loss: 0.7045 | Batch time: 0.18s
2025-03-03 23:49:45,769 - INFO - [TRAIN] Epoch: 9/30 | Batch: 90/452 (20.1%) | Loss: 0.1839 | Batch time: 0.17s
2025-03-03 23:49:53,681 - INFO - [TRAIN] Epoch: 9/30 | Batch: 135/452 (30.1%) | Loss: 0.3315 | Batch time: 0.18s
2025-03-03 23:50:01,604 - INFO - [TRAIN] Epoch: 9/30 | Batch: 180/452 (40.0%) | Loss: 0.4470 | Batch time: 0.18s
2025-03-03 23:50:09,505 - INFO - [TRAIN] Epoch: 9/30 | Batch: 225/452 (50.0%) | Loss: 0.3454 | Batch time: 0.17s
2025-03-03 23:50:17,459 - INFO - [TRAIN] Epoch: 9/30 | Batch: 270/452 (60.0%) | Loss: 0.2048 | Batch time: 0.18s
2025-03-03 23:50:25,523 - INFO - [TRAIN] Epoch: 9/30 | Batch: 315/452 (69.9%) | Loss: 0.3637 | Batch time: 0.19s
2025-03-03 23:50:33,652 - INFO - [TRAIN] Epoch: 9/30 | Batch: 360/452 (79.9%) | Loss: 0.6973 | Batch time: 0.18s
2025-03-03 23:50:41,576 - INFO - [TRAIN] Epoch: 9/30 | Batch: 405/452 (89.8%) | Loss: 0.4262 | Batch time: 0.17s
2025-03-03 23:50:49,475 - INFO - [TRAIN] Epoch: 9/30 | Batch: 450/452 (99.8%) | Loss: 0.3438 | Batch time: 0.18s
2025-03-03 23:50:49,562 - INFO - [TRAIN] Epoch: 9/30 | Batch: 451/452 (100.0%) | Loss: 0.7282 | Batch time: 0.09s
2025-03-03 23:50:49,698 - INFO - [VAL] Epoch: 9/30 | Batch: 0/97 (1.0%) | Loss: 0.0179 | Batch time: 0.05s
2025-03-03 23:50:50,111 - INFO - [VAL] Epoch: 9/30 | Batch: 9/97 (10.3%) | Loss: 0.0361 | Batch time: 0.05s
2025-03-03 23:50:50,542 - INFO - [VAL] Epoch: 9/30 | Batch: 18/97 (19.6%) | Loss: 0.1534 | Batch time: 0.05s
2025-03-03 23:50:50,999 - INFO - [VAL] Epoch: 9/30 | Batch: 27/97 (28.9%) | Loss: 0.0656 | Batch time: 0.05s
2025-03-03 23:50:51,456 - INFO - [VAL] Epoch: 9/30 | Batch: 36/97 (38.1%) | Loss: 0.0246 | Batch time: 0.05s
2025-03-03 23:50:51,911 - INFO - [VAL] Epoch: 9/30 | Batch: 45/97 (47.4%) | Loss: 0.1324 | Batch time: 0.05s
2025-03-03 23:50:52,389 - INFO - [VAL] Epoch: 9/30 | Batch: 54/97 (56.7%) | Loss: 0.0280 | Batch time: 0.05s
2025-03-03 23:50:52,862 - INFO - [VAL] Epoch: 9/30 | Batch: 63/97 (66.0%) | Loss: 0.0528 | Batch time: 0.05s
2025-03-03 23:50:53,317 - INFO - [VAL] Epoch: 9/30 | Batch: 72/97 (75.3%) | Loss: 0.1871 | Batch time: 0.05s
2025-03-03 23:50:53,754 - INFO - [VAL] Epoch: 9/30 | Batch: 81/97 (84.5%) | Loss: 0.0214 | Batch time: 0.05s
2025-03-03 23:50:54,186 - INFO - [VAL] Epoch: 9/30 | Batch: 90/97 (93.8%) | Loss: 0.0307 | Batch time: 0.05s
2025-03-03 23:50:54,466 - INFO - [VAL] Epoch: 9/30 | Batch: 96/97 (100.0%) | Loss: 0.1484 | Batch time: 0.04s
2025-03-03 23:50:55,189 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 9)
2025-03-03 23:50:55,189 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:50:55,189 - INFO - Epoch 9/30 completed in 85.97s
2025-03-03 23:50:55,189 - INFO - Training   - Loss: 0.3884, Accuracy: 0.8695, F1: 0.8700
2025-03-03 23:50:55,189 - INFO - Validation - Loss: 0.1082, Accuracy: 0.9525, F1: 0.9526
2025-03-03 23:50:55,189 - INFO - Validation F1 improved from 0.9422 to 0.9526
2025-03-03 23:50:55,189 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:50:55,189 - INFO - Epoch 10/30
2025-03-03 23:50:55,189 - INFO - ----------------------------------------
2025-03-03 23:50:55,574 - INFO - [TRAIN] Epoch: 10/30 | Batch: 0/452 (0.2%) | Loss: 0.3516 | Batch time: 0.19s
2025-03-03 23:51:03,365 - INFO - [TRAIN] Epoch: 10/30 | Batch: 45/452 (10.2%) | Loss: 0.3267 | Batch time: 0.18s
2025-03-03 23:51:11,429 - INFO - [TRAIN] Epoch: 10/30 | Batch: 90/452 (20.1%) | Loss: 0.2742 | Batch time: 0.18s
2025-03-03 23:51:19,438 - INFO - [TRAIN] Epoch: 10/30 | Batch: 135/452 (30.1%) | Loss: 0.2663 | Batch time: 0.17s
2025-03-03 23:51:27,361 - INFO - [TRAIN] Epoch: 10/30 | Batch: 180/452 (40.0%) | Loss: 0.2366 | Batch time: 0.18s
2025-03-03 23:51:35,285 - INFO - [TRAIN] Epoch: 10/30 | Batch: 225/452 (50.0%) | Loss: 0.1746 | Batch time: 0.17s
2025-03-03 23:51:43,212 - INFO - [TRAIN] Epoch: 10/30 | Batch: 270/452 (60.0%) | Loss: 0.1414 | Batch time: 0.18s
2025-03-03 23:51:51,101 - INFO - [TRAIN] Epoch: 10/30 | Batch: 315/452 (69.9%) | Loss: 0.4504 | Batch time: 0.18s
2025-03-03 23:51:58,975 - INFO - [TRAIN] Epoch: 10/30 | Batch: 360/452 (79.9%) | Loss: 0.4633 | Batch time: 0.17s
2025-03-03 23:52:06,889 - INFO - [TRAIN] Epoch: 10/30 | Batch: 405/452 (89.8%) | Loss: 0.4852 | Batch time: 0.17s
2025-03-03 23:52:14,649 - INFO - [TRAIN] Epoch: 10/30 | Batch: 450/452 (99.8%) | Loss: 0.3081 | Batch time: 0.17s
2025-03-03 23:52:14,734 - INFO - [TRAIN] Epoch: 10/30 | Batch: 451/452 (100.0%) | Loss: 0.2571 | Batch time: 0.08s
2025-03-03 23:52:14,852 - INFO - [VAL] Epoch: 10/30 | Batch: 0/97 (1.0%) | Loss: 0.0134 | Batch time: 0.05s
2025-03-03 23:52:15,260 - INFO - [VAL] Epoch: 10/30 | Batch: 9/97 (10.3%) | Loss: 0.0243 | Batch time: 0.05s
2025-03-03 23:52:15,688 - INFO - [VAL] Epoch: 10/30 | Batch: 18/97 (19.6%) | Loss: 0.1296 | Batch time: 0.05s
2025-03-03 23:52:16,132 - INFO - [VAL] Epoch: 10/30 | Batch: 27/97 (28.9%) | Loss: 0.0377 | Batch time: 0.05s
2025-03-03 23:52:16,582 - INFO - [VAL] Epoch: 10/30 | Batch: 36/97 (38.1%) | Loss: 0.0501 | Batch time: 0.05s
2025-03-03 23:52:17,030 - INFO - [VAL] Epoch: 10/30 | Batch: 45/97 (47.4%) | Loss: 0.0765 | Batch time: 0.05s
2025-03-03 23:52:17,478 - INFO - [VAL] Epoch: 10/30 | Batch: 54/97 (56.7%) | Loss: 0.0339 | Batch time: 0.05s
2025-03-03 23:52:17,922 - INFO - [VAL] Epoch: 10/30 | Batch: 63/97 (66.0%) | Loss: 0.0620 | Batch time: 0.05s
2025-03-03 23:52:18,359 - INFO - [VAL] Epoch: 10/30 | Batch: 72/97 (75.3%) | Loss: 0.1462 | Batch time: 0.05s
2025-03-03 23:52:18,791 - INFO - [VAL] Epoch: 10/30 | Batch: 81/97 (84.5%) | Loss: 0.0240 | Batch time: 0.05s
2025-03-03 23:52:19,215 - INFO - [VAL] Epoch: 10/30 | Batch: 90/97 (93.8%) | Loss: 0.0229 | Batch time: 0.05s
2025-03-03 23:52:19,497 - INFO - [VAL] Epoch: 10/30 | Batch: 96/97 (100.0%) | Loss: 0.1908 | Batch time: 0.05s
2025-03-03 23:52:20,206 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 10)
2025-03-03 23:52:20,206 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:52:20,206 - INFO - Epoch 10/30 completed in 85.02s
2025-03-03 23:52:20,206 - INFO - Training   - Loss: 0.3783, Accuracy: 0.8770, F1: 0.8773
2025-03-03 23:52:20,206 - INFO - Validation - Loss: 0.0977, Accuracy: 0.9587, F1: 0.9587
2025-03-03 23:52:20,206 - INFO - Validation F1 improved from 0.9526 to 0.9587
2025-03-03 23:52:20,206 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:52:20,674 - INFO - Checkpoint saved: checkpoint_epoch_10.pth (Epoch 10)
2025-03-03 23:52:20,674 - INFO - Epoch 11/30
2025-03-03 23:52:20,674 - INFO - ----------------------------------------
2025-03-03 23:52:21,125 - INFO - [TRAIN] Epoch: 11/30 | Batch: 0/452 (0.2%) | Loss: 0.2085 | Batch time: 0.23s
2025-03-03 23:52:29,110 - INFO - [TRAIN] Epoch: 11/30 | Batch: 45/452 (10.2%) | Loss: 0.2823 | Batch time: 0.18s
2025-03-03 23:52:37,860 - INFO - [TRAIN] Epoch: 11/30 | Batch: 90/452 (20.1%) | Loss: 0.6525 | Batch time: 0.18s
2025-03-03 23:52:45,929 - INFO - [TRAIN] Epoch: 11/30 | Batch: 135/452 (30.1%) | Loss: 0.3382 | Batch time: 0.17s
2025-03-03 23:52:53,811 - INFO - [TRAIN] Epoch: 11/30 | Batch: 180/452 (40.0%) | Loss: 0.2015 | Batch time: 0.17s
2025-03-03 23:53:01,869 - INFO - [TRAIN] Epoch: 11/30 | Batch: 225/452 (50.0%) | Loss: 0.3879 | Batch time: 0.18s
2025-03-03 23:53:09,846 - INFO - [TRAIN] Epoch: 11/30 | Batch: 270/452 (60.0%) | Loss: 0.2931 | Batch time: 0.18s
2025-03-03 23:53:17,999 - INFO - [TRAIN] Epoch: 11/30 | Batch: 315/452 (69.9%) | Loss: 0.2825 | Batch time: 0.18s
2025-03-03 23:53:25,943 - INFO - [TRAIN] Epoch: 11/30 | Batch: 360/452 (79.9%) | Loss: 0.2517 | Batch time: 0.17s
2025-03-03 23:53:33,887 - INFO - [TRAIN] Epoch: 11/30 | Batch: 405/452 (89.8%) | Loss: 0.3288 | Batch time: 0.18s
2025-03-03 23:53:41,649 - INFO - [TRAIN] Epoch: 11/30 | Batch: 450/452 (99.8%) | Loss: 0.2301 | Batch time: 0.17s
2025-03-03 23:53:41,738 - INFO - [TRAIN] Epoch: 11/30 | Batch: 451/452 (100.0%) | Loss: 1.0972 | Batch time: 0.09s
2025-03-03 23:53:41,859 - INFO - [VAL] Epoch: 11/30 | Batch: 0/97 (1.0%) | Loss: 0.0101 | Batch time: 0.05s
2025-03-03 23:53:42,285 - INFO - [VAL] Epoch: 11/30 | Batch: 9/97 (10.3%) | Loss: 0.0260 | Batch time: 0.05s
2025-03-03 23:53:42,735 - INFO - [VAL] Epoch: 11/30 | Batch: 18/97 (19.6%) | Loss: 0.0942 | Batch time: 0.05s
2025-03-03 23:53:43,205 - INFO - [VAL] Epoch: 11/30 | Batch: 27/97 (28.9%) | Loss: 0.0333 | Batch time: 0.05s
2025-03-03 23:53:43,675 - INFO - [VAL] Epoch: 11/30 | Batch: 36/97 (38.1%) | Loss: 0.0143 | Batch time: 0.05s
2025-03-03 23:53:44,133 - INFO - [VAL] Epoch: 11/30 | Batch: 45/97 (47.4%) | Loss: 0.0581 | Batch time: 0.05s
2025-03-03 23:53:44,580 - INFO - [VAL] Epoch: 11/30 | Batch: 54/97 (56.7%) | Loss: 0.0337 | Batch time: 0.05s
2025-03-03 23:53:45,024 - INFO - [VAL] Epoch: 11/30 | Batch: 63/97 (66.0%) | Loss: 0.0573 | Batch time: 0.05s
2025-03-03 23:53:45,466 - INFO - [VAL] Epoch: 11/30 | Batch: 72/97 (75.3%) | Loss: 0.1251 | Batch time: 0.05s
2025-03-03 23:53:45,901 - INFO - [VAL] Epoch: 11/30 | Batch: 81/97 (84.5%) | Loss: 0.0184 | Batch time: 0.05s
2025-03-03 23:53:46,334 - INFO - [VAL] Epoch: 11/30 | Batch: 90/97 (93.8%) | Loss: 0.0209 | Batch time: 0.05s
2025-03-03 23:53:46,621 - INFO - [VAL] Epoch: 11/30 | Batch: 96/97 (100.0%) | Loss: 0.1210 | Batch time: 0.05s
2025-03-03 23:53:47,347 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 11)
2025-03-03 23:53:47,347 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:53:47,347 - INFO - Epoch 11/30 completed in 86.67s
2025-03-03 23:53:47,347 - INFO - Training   - Loss: 0.3636, Accuracy: 0.8769, F1: 0.8774
2025-03-03 23:53:47,347 - INFO - Validation - Loss: 0.0869, Accuracy: 0.9641, F1: 0.9643
2025-03-03 23:53:47,347 - INFO - Validation F1 improved from 0.9587 to 0.9643
2025-03-03 23:53:47,347 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:53:47,347 - INFO - Epoch 12/30
2025-03-03 23:53:47,347 - INFO - ----------------------------------------
2025-03-03 23:53:47,742 - INFO - [TRAIN] Epoch: 12/30 | Batch: 0/452 (0.2%) | Loss: 0.2291 | Batch time: 0.20s
2025-03-03 23:53:55,565 - INFO - [TRAIN] Epoch: 12/30 | Batch: 45/452 (10.2%) | Loss: 0.3672 | Batch time: 0.17s
2025-03-03 23:54:03,528 - INFO - [TRAIN] Epoch: 12/30 | Batch: 90/452 (20.1%) | Loss: 0.4490 | Batch time: 0.17s
2025-03-03 23:54:11,476 - INFO - [TRAIN] Epoch: 12/30 | Batch: 135/452 (30.1%) | Loss: 0.1147 | Batch time: 0.18s
2025-03-03 23:54:19,392 - INFO - [TRAIN] Epoch: 12/30 | Batch: 180/452 (40.0%) | Loss: 0.4023 | Batch time: 0.18s
2025-03-03 23:54:27,612 - INFO - [TRAIN] Epoch: 12/30 | Batch: 225/452 (50.0%) | Loss: 0.1107 | Batch time: 0.17s
2025-03-03 23:54:35,648 - INFO - [TRAIN] Epoch: 12/30 | Batch: 270/452 (60.0%) | Loss: 0.3677 | Batch time: 0.18s
2025-03-03 23:54:43,657 - INFO - [TRAIN] Epoch: 12/30 | Batch: 315/452 (69.9%) | Loss: 0.2594 | Batch time: 0.17s
2025-03-03 23:54:51,873 - INFO - [TRAIN] Epoch: 12/30 | Batch: 360/452 (79.9%) | Loss: 0.7231 | Batch time: 0.18s
2025-03-03 23:55:00,092 - INFO - [TRAIN] Epoch: 12/30 | Batch: 405/452 (89.8%) | Loss: 0.5809 | Batch time: 0.17s
2025-03-03 23:55:07,847 - INFO - [TRAIN] Epoch: 12/30 | Batch: 450/452 (99.8%) | Loss: 0.6060 | Batch time: 0.17s
2025-03-03 23:55:07,931 - INFO - [TRAIN] Epoch: 12/30 | Batch: 451/452 (100.0%) | Loss: 0.6329 | Batch time: 0.08s
2025-03-03 23:55:08,044 - INFO - [VAL] Epoch: 12/30 | Batch: 0/97 (1.0%) | Loss: 0.0084 | Batch time: 0.05s
2025-03-03 23:55:08,458 - INFO - [VAL] Epoch: 12/30 | Batch: 9/97 (10.3%) | Loss: 0.0139 | Batch time: 0.05s
2025-03-03 23:55:08,892 - INFO - [VAL] Epoch: 12/30 | Batch: 18/97 (19.6%) | Loss: 0.1064 | Batch time: 0.05s
2025-03-03 23:55:09,354 - INFO - [VAL] Epoch: 12/30 | Batch: 27/97 (28.9%) | Loss: 0.0303 | Batch time: 0.05s
2025-03-03 23:55:09,805 - INFO - [VAL] Epoch: 12/30 | Batch: 36/97 (38.1%) | Loss: 0.0279 | Batch time: 0.05s
2025-03-03 23:55:10,259 - INFO - [VAL] Epoch: 12/30 | Batch: 45/97 (47.4%) | Loss: 0.1004 | Batch time: 0.05s
2025-03-03 23:55:10,710 - INFO - [VAL] Epoch: 12/30 | Batch: 54/97 (56.7%) | Loss: 0.0094 | Batch time: 0.05s
2025-03-03 23:55:11,158 - INFO - [VAL] Epoch: 12/30 | Batch: 63/97 (66.0%) | Loss: 0.0432 | Batch time: 0.05s
2025-03-03 23:55:11,601 - INFO - [VAL] Epoch: 12/30 | Batch: 72/97 (75.3%) | Loss: 0.1215 | Batch time: 0.05s
2025-03-03 23:55:12,038 - INFO - [VAL] Epoch: 12/30 | Batch: 81/97 (84.5%) | Loss: 0.0226 | Batch time: 0.05s
2025-03-03 23:55:12,467 - INFO - [VAL] Epoch: 12/30 | Batch: 90/97 (93.8%) | Loss: 0.0179 | Batch time: 0.05s
2025-03-03 23:55:12,751 - INFO - [VAL] Epoch: 12/30 | Batch: 96/97 (100.0%) | Loss: 0.0751 | Batch time: 0.05s
2025-03-03 23:55:13,557 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 12)
2025-03-03 23:55:13,558 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:55:13,558 - INFO - Epoch 12/30 completed in 86.21s
2025-03-03 23:55:13,558 - INFO - Training   - Loss: 0.3455, Accuracy: 0.8815, F1: 0.8819
2025-03-03 23:55:13,558 - INFO - Validation - Loss: 0.0852, Accuracy: 0.9658, F1: 0.9659
2025-03-03 23:55:13,558 - INFO - Validation F1 improved from 0.9643 to 0.9659
2025-03-03 23:55:13,558 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:55:13,558 - INFO - Epoch 13/30
2025-03-03 23:55:13,558 - INFO - ----------------------------------------
2025-03-03 23:55:13,975 - INFO - [TRAIN] Epoch: 13/30 | Batch: 0/452 (0.2%) | Loss: 0.0939 | Batch time: 0.20s
2025-03-03 23:55:21,753 - INFO - [TRAIN] Epoch: 13/30 | Batch: 45/452 (10.2%) | Loss: 0.0771 | Batch time: 0.18s
2025-03-03 23:55:29,742 - INFO - [TRAIN] Epoch: 13/30 | Batch: 90/452 (20.1%) | Loss: 0.0956 | Batch time: 0.18s
2025-03-03 23:55:37,690 - INFO - [TRAIN] Epoch: 13/30 | Batch: 135/452 (30.1%) | Loss: 0.2828 | Batch time: 0.17s
2025-03-03 23:55:45,655 - INFO - [TRAIN] Epoch: 13/30 | Batch: 180/452 (40.0%) | Loss: 0.4437 | Batch time: 0.18s
2025-03-03 23:55:53,569 - INFO - [TRAIN] Epoch: 13/30 | Batch: 225/452 (50.0%) | Loss: 0.2142 | Batch time: 0.18s
2025-03-03 23:56:01,625 - INFO - [TRAIN] Epoch: 13/30 | Batch: 270/452 (60.0%) | Loss: 0.1374 | Batch time: 0.17s
2025-03-03 23:56:09,495 - INFO - [TRAIN] Epoch: 13/30 | Batch: 315/452 (69.9%) | Loss: 0.3586 | Batch time: 0.17s
2025-03-03 23:56:17,412 - INFO - [TRAIN] Epoch: 13/30 | Batch: 360/452 (79.9%) | Loss: 0.2127 | Batch time: 0.18s
2025-03-03 23:56:25,413 - INFO - [TRAIN] Epoch: 13/30 | Batch: 405/452 (89.8%) | Loss: 0.5172 | Batch time: 0.18s
2025-03-03 23:56:33,274 - INFO - [TRAIN] Epoch: 13/30 | Batch: 450/452 (99.8%) | Loss: 0.4238 | Batch time: 0.17s
2025-03-03 23:56:33,360 - INFO - [TRAIN] Epoch: 13/30 | Batch: 451/452 (100.0%) | Loss: 0.1001 | Batch time: 0.09s
2025-03-03 23:56:33,470 - INFO - [VAL] Epoch: 13/30 | Batch: 0/97 (1.0%) | Loss: 0.0164 | Batch time: 0.05s
2025-03-03 23:56:33,882 - INFO - [VAL] Epoch: 13/30 | Batch: 9/97 (10.3%) | Loss: 0.0129 | Batch time: 0.05s
2025-03-03 23:56:34,323 - INFO - [VAL] Epoch: 13/30 | Batch: 18/97 (19.6%) | Loss: 0.1649 | Batch time: 0.05s
2025-03-03 23:56:34,782 - INFO - [VAL] Epoch: 13/30 | Batch: 27/97 (28.9%) | Loss: 0.0126 | Batch time: 0.05s
2025-03-03 23:56:35,240 - INFO - [VAL] Epoch: 13/30 | Batch: 36/97 (38.1%) | Loss: 0.0263 | Batch time: 0.05s
2025-03-03 23:56:35,694 - INFO - [VAL] Epoch: 13/30 | Batch: 45/97 (47.4%) | Loss: 0.0915 | Batch time: 0.05s
2025-03-03 23:56:36,150 - INFO - [VAL] Epoch: 13/30 | Batch: 54/97 (56.7%) | Loss: 0.0047 | Batch time: 0.05s
2025-03-03 23:56:36,596 - INFO - [VAL] Epoch: 13/30 | Batch: 63/97 (66.0%) | Loss: 0.0388 | Batch time: 0.05s
2025-03-03 23:56:37,037 - INFO - [VAL] Epoch: 13/30 | Batch: 72/97 (75.3%) | Loss: 0.1735 | Batch time: 0.05s
2025-03-03 23:56:37,478 - INFO - [VAL] Epoch: 13/30 | Batch: 81/97 (84.5%) | Loss: 0.0139 | Batch time: 0.05s
2025-03-03 23:56:37,910 - INFO - [VAL] Epoch: 13/30 | Batch: 90/97 (93.8%) | Loss: 0.0155 | Batch time: 0.05s
2025-03-03 23:56:38,191 - INFO - [VAL] Epoch: 13/30 | Batch: 96/97 (100.0%) | Loss: 0.0826 | Batch time: 0.04s
2025-03-03 23:56:38,910 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 13)
2025-03-03 23:56:38,910 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:56:38,910 - INFO - Epoch 13/30 completed in 85.35s
2025-03-03 23:56:38,910 - INFO - Training   - Loss: 0.3267, Accuracy: 0.8901, F1: 0.8907
2025-03-03 23:56:38,910 - INFO - Validation - Loss: 0.0815, Accuracy: 0.9677, F1: 0.9677
2025-03-03 23:56:38,910 - INFO - Validation F1 improved from 0.9659 to 0.9677
2025-03-03 23:56:38,910 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:56:38,910 - INFO - Epoch 14/30
2025-03-03 23:56:38,910 - INFO - ----------------------------------------
2025-03-03 23:56:39,294 - INFO - [TRAIN] Epoch: 14/30 | Batch: 0/452 (0.2%) | Loss: 0.5413 | Batch time: 0.18s
2025-03-03 23:56:47,062 - INFO - [TRAIN] Epoch: 14/30 | Batch: 45/452 (10.2%) | Loss: 0.3231 | Batch time: 0.18s
2025-03-03 23:56:55,013 - INFO - [TRAIN] Epoch: 14/30 | Batch: 90/452 (20.1%) | Loss: 0.1799 | Batch time: 0.18s
2025-03-03 23:57:03,033 - INFO - [TRAIN] Epoch: 14/30 | Batch: 135/452 (30.1%) | Loss: 0.3169 | Batch time: 0.18s
2025-03-03 23:57:11,067 - INFO - [TRAIN] Epoch: 14/30 | Batch: 180/452 (40.0%) | Loss: 0.4139 | Batch time: 0.17s
2025-03-03 23:57:19,106 - INFO - [TRAIN] Epoch: 14/30 | Batch: 225/452 (50.0%) | Loss: 0.3849 | Batch time: 0.18s
2025-03-03 23:57:27,100 - INFO - [TRAIN] Epoch: 14/30 | Batch: 270/452 (60.0%) | Loss: 0.1473 | Batch time: 0.18s
2025-03-03 23:57:34,995 - INFO - [TRAIN] Epoch: 14/30 | Batch: 315/452 (69.9%) | Loss: 0.2016 | Batch time: 0.18s
2025-03-03 23:57:43,075 - INFO - [TRAIN] Epoch: 14/30 | Batch: 360/452 (79.9%) | Loss: 0.4632 | Batch time: 0.18s
2025-03-03 23:57:51,014 - INFO - [TRAIN] Epoch: 14/30 | Batch: 405/452 (89.8%) | Loss: 0.4296 | Batch time: 0.17s
2025-03-03 23:57:58,922 - INFO - [TRAIN] Epoch: 14/30 | Batch: 450/452 (99.8%) | Loss: 0.4062 | Batch time: 0.17s
2025-03-03 23:57:59,010 - INFO - [TRAIN] Epoch: 14/30 | Batch: 451/452 (100.0%) | Loss: 0.4070 | Batch time: 0.09s
2025-03-03 23:57:59,122 - INFO - [VAL] Epoch: 14/30 | Batch: 0/97 (1.0%) | Loss: 0.0089 | Batch time: 0.05s
2025-03-03 23:57:59,534 - INFO - [VAL] Epoch: 14/30 | Batch: 9/97 (10.3%) | Loss: 0.0190 | Batch time: 0.05s
2025-03-03 23:57:59,985 - INFO - [VAL] Epoch: 14/30 | Batch: 18/97 (19.6%) | Loss: 0.1947 | Batch time: 0.05s
2025-03-03 23:58:00,442 - INFO - [VAL] Epoch: 14/30 | Batch: 27/97 (28.9%) | Loss: 0.0311 | Batch time: 0.05s
2025-03-03 23:58:00,894 - INFO - [VAL] Epoch: 14/30 | Batch: 36/97 (38.1%) | Loss: 0.0411 | Batch time: 0.05s
2025-03-03 23:58:01,359 - INFO - [VAL] Epoch: 14/30 | Batch: 45/97 (47.4%) | Loss: 0.0338 | Batch time: 0.05s
2025-03-03 23:58:01,807 - INFO - [VAL] Epoch: 14/30 | Batch: 54/97 (56.7%) | Loss: 0.0080 | Batch time: 0.05s
2025-03-03 23:58:02,250 - INFO - [VAL] Epoch: 14/30 | Batch: 63/97 (66.0%) | Loss: 0.0477 | Batch time: 0.05s
2025-03-03 23:58:02,694 - INFO - [VAL] Epoch: 14/30 | Batch: 72/97 (75.3%) | Loss: 0.0712 | Batch time: 0.05s
2025-03-03 23:58:03,121 - INFO - [VAL] Epoch: 14/30 | Batch: 81/97 (84.5%) | Loss: 0.0228 | Batch time: 0.05s
2025-03-03 23:58:03,543 - INFO - [VAL] Epoch: 14/30 | Batch: 90/97 (93.8%) | Loss: 0.0255 | Batch time: 0.05s
2025-03-03 23:58:03,827 - INFO - [VAL] Epoch: 14/30 | Batch: 96/97 (100.0%) | Loss: 0.1346 | Batch time: 0.04s
2025-03-03 23:58:03,830 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:58:03,830 - INFO - Epoch 14/30 completed in 84.92s
2025-03-03 23:58:03,830 - INFO - Training   - Loss: 0.3254, Accuracy: 0.8935, F1: 0.8941
2025-03-03 23:58:03,830 - INFO - Validation - Loss: 0.0821, Accuracy: 0.9667, F1: 0.9668
2025-03-03 23:58:03,830 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:58:03,830 - INFO - Epoch 15/30
2025-03-03 23:58:03,830 - INFO - ----------------------------------------
2025-03-03 23:58:04,228 - INFO - [TRAIN] Epoch: 15/30 | Batch: 0/452 (0.2%) | Loss: 0.3096 | Batch time: 0.20s
2025-03-03 23:58:12,312 - INFO - [TRAIN] Epoch: 15/30 | Batch: 45/452 (10.2%) | Loss: 0.3387 | Batch time: 0.18s
2025-03-03 23:58:20,479 - INFO - [TRAIN] Epoch: 15/30 | Batch: 90/452 (20.1%) | Loss: 0.2207 | Batch time: 0.18s
2025-03-03 23:58:28,429 - INFO - [TRAIN] Epoch: 15/30 | Batch: 135/452 (30.1%) | Loss: 0.4135 | Batch time: 0.17s
2025-03-03 23:58:36,384 - INFO - [TRAIN] Epoch: 15/30 | Batch: 180/452 (40.0%) | Loss: 0.4662 | Batch time: 0.18s
2025-03-03 23:58:44,623 - INFO - [TRAIN] Epoch: 15/30 | Batch: 225/452 (50.0%) | Loss: 0.4054 | Batch time: 0.18s
2025-03-03 23:58:52,803 - INFO - [TRAIN] Epoch: 15/30 | Batch: 270/452 (60.0%) | Loss: 0.2294 | Batch time: 0.18s
2025-03-03 23:59:00,714 - INFO - [TRAIN] Epoch: 15/30 | Batch: 315/452 (69.9%) | Loss: 0.4505 | Batch time: 0.18s
2025-03-03 23:59:08,767 - INFO - [TRAIN] Epoch: 15/30 | Batch: 360/452 (79.9%) | Loss: 0.5760 | Batch time: 0.19s
2025-03-03 23:59:16,729 - INFO - [TRAIN] Epoch: 15/30 | Batch: 405/452 (89.8%) | Loss: 0.2971 | Batch time: 0.17s
2025-03-03 23:59:24,936 - INFO - [TRAIN] Epoch: 15/30 | Batch: 450/452 (99.8%) | Loss: 0.1198 | Batch time: 0.17s
2025-03-03 23:59:25,024 - INFO - [TRAIN] Epoch: 15/30 | Batch: 451/452 (100.0%) | Loss: 0.5267 | Batch time: 0.09s
2025-03-03 23:59:25,142 - INFO - [VAL] Epoch: 15/30 | Batch: 0/97 (1.0%) | Loss: 0.0087 | Batch time: 0.05s
2025-03-03 23:59:25,551 - INFO - [VAL] Epoch: 15/30 | Batch: 9/97 (10.3%) | Loss: 0.0096 | Batch time: 0.05s
2025-03-03 23:59:25,979 - INFO - [VAL] Epoch: 15/30 | Batch: 18/97 (19.6%) | Loss: 0.1393 | Batch time: 0.05s
2025-03-03 23:59:26,418 - INFO - [VAL] Epoch: 15/30 | Batch: 27/97 (28.9%) | Loss: 0.0115 | Batch time: 0.05s
2025-03-03 23:59:26,863 - INFO - [VAL] Epoch: 15/30 | Batch: 36/97 (38.1%) | Loss: 0.0281 | Batch time: 0.05s
2025-03-03 23:59:27,308 - INFO - [VAL] Epoch: 15/30 | Batch: 45/97 (47.4%) | Loss: 0.0355 | Batch time: 0.05s
2025-03-03 23:59:27,757 - INFO - [VAL] Epoch: 15/30 | Batch: 54/97 (56.7%) | Loss: 0.0069 | Batch time: 0.05s
2025-03-03 23:59:28,207 - INFO - [VAL] Epoch: 15/30 | Batch: 63/97 (66.0%) | Loss: 0.0462 | Batch time: 0.05s
2025-03-03 23:59:28,666 - INFO - [VAL] Epoch: 15/30 | Batch: 72/97 (75.3%) | Loss: 0.0813 | Batch time: 0.05s
2025-03-03 23:59:29,125 - INFO - [VAL] Epoch: 15/30 | Batch: 81/97 (84.5%) | Loss: 0.0162 | Batch time: 0.05s
2025-03-03 23:59:29,561 - INFO - [VAL] Epoch: 15/30 | Batch: 90/97 (93.8%) | Loss: 0.0155 | Batch time: 0.05s
2025-03-03 23:59:29,853 - INFO - [VAL] Epoch: 15/30 | Batch: 96/97 (100.0%) | Loss: 0.0347 | Batch time: 0.05s
2025-03-03 23:59:30,588 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 15)
2025-03-03 23:59:30,588 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:59:30,588 - INFO - Epoch 15/30 completed in 86.76s
2025-03-03 23:59:30,588 - INFO - Training   - Loss: 0.3075, Accuracy: 0.8992, F1: 0.8999
2025-03-03 23:59:30,588 - INFO - Validation - Loss: 0.0648, Accuracy: 0.9735, F1: 0.9735
2025-03-03 23:59:30,588 - INFO - Validation F1 improved from 0.9677 to 0.9735
2025-03-03 23:59:30,588 - INFO - --------------------------------------------------------------------------------
2025-03-03 23:59:31,097 - INFO - Checkpoint saved: checkpoint_epoch_15.pth (Epoch 15)
2025-03-03 23:59:31,099 - INFO - Epoch 16/30
2025-03-03 23:59:31,100 - INFO - ----------------------------------------
2025-03-03 23:59:31,603 - INFO - [TRAIN] Epoch: 16/30 | Batch: 0/452 (0.2%) | Loss: 0.6306 | Batch time: 0.25s
2025-03-03 23:59:39,697 - INFO - [TRAIN] Epoch: 16/30 | Batch: 45/452 (10.2%) | Loss: 0.1481 | Batch time: 0.18s
2025-03-03 23:59:47,862 - INFO - [TRAIN] Epoch: 16/30 | Batch: 90/452 (20.1%) | Loss: 0.3608 | Batch time: 0.18s
2025-03-03 23:59:56,031 - INFO - [TRAIN] Epoch: 16/30 | Batch: 135/452 (30.1%) | Loss: 0.2490 | Batch time: 0.18s
2025-03-04 00:00:04,202 - INFO - [TRAIN] Epoch: 16/30 | Batch: 180/452 (40.0%) | Loss: 0.1607 | Batch time: 0.18s
2025-03-04 00:00:12,317 - INFO - [TRAIN] Epoch: 16/30 | Batch: 225/452 (50.0%) | Loss: 0.2887 | Batch time: 0.18s
2025-03-04 00:00:20,191 - INFO - [TRAIN] Epoch: 16/30 | Batch: 270/452 (60.0%) | Loss: 0.3958 | Batch time: 0.17s
2025-03-04 00:00:28,323 - INFO - [TRAIN] Epoch: 16/30 | Batch: 315/452 (69.9%) | Loss: 0.2970 | Batch time: 0.18s
2025-03-04 00:00:36,453 - INFO - [TRAIN] Epoch: 16/30 | Batch: 360/452 (79.9%) | Loss: 0.4529 | Batch time: 0.18s
2025-03-04 00:00:44,608 - INFO - [TRAIN] Epoch: 16/30 | Batch: 405/452 (89.8%) | Loss: 0.3185 | Batch time: 0.19s
2025-03-04 00:00:52,531 - INFO - [TRAIN] Epoch: 16/30 | Batch: 450/452 (99.8%) | Loss: 0.0723 | Batch time: 0.18s
2025-03-04 00:00:52,621 - INFO - [TRAIN] Epoch: 16/30 | Batch: 451/452 (100.0%) | Loss: 0.6457 | Batch time: 0.09s
2025-03-04 00:00:52,734 - INFO - [VAL] Epoch: 16/30 | Batch: 0/97 (1.0%) | Loss: 0.0106 | Batch time: 0.05s
2025-03-04 00:00:53,167 - INFO - [VAL] Epoch: 16/30 | Batch: 9/97 (10.3%) | Loss: 0.0082 | Batch time: 0.05s
2025-03-04 00:00:53,619 - INFO - [VAL] Epoch: 16/30 | Batch: 18/97 (19.6%) | Loss: 0.1044 | Batch time: 0.05s
2025-03-04 00:00:54,112 - INFO - [VAL] Epoch: 16/30 | Batch: 27/97 (28.9%) | Loss: 0.0131 | Batch time: 0.06s
2025-03-04 00:00:54,619 - INFO - [VAL] Epoch: 16/30 | Batch: 36/97 (38.1%) | Loss: 0.0159 | Batch time: 0.05s
2025-03-04 00:00:55,090 - INFO - [VAL] Epoch: 16/30 | Batch: 45/97 (47.4%) | Loss: 0.0276 | Batch time: 0.05s
2025-03-04 00:00:55,605 - INFO - [VAL] Epoch: 16/30 | Batch: 54/97 (56.7%) | Loss: 0.0073 | Batch time: 0.06s
2025-03-04 00:00:56,084 - INFO - [VAL] Epoch: 16/30 | Batch: 63/97 (66.0%) | Loss: 0.0501 | Batch time: 0.05s
2025-03-04 00:00:56,540 - INFO - [VAL] Epoch: 16/30 | Batch: 72/97 (75.3%) | Loss: 0.0454 | Batch time: 0.05s
2025-03-04 00:00:56,980 - INFO - [VAL] Epoch: 16/30 | Batch: 81/97 (84.5%) | Loss: 0.0098 | Batch time: 0.05s
2025-03-04 00:00:57,408 - INFO - [VAL] Epoch: 16/30 | Batch: 90/97 (93.8%) | Loss: 0.0127 | Batch time: 0.05s
2025-03-04 00:00:57,691 - INFO - [VAL] Epoch: 16/30 | Batch: 96/97 (100.0%) | Loss: 0.0281 | Batch time: 0.05s
2025-03-04 00:00:58,433 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 16)
2025-03-04 00:00:58,434 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:00:58,434 - INFO - Epoch 16/30 completed in 87.33s
2025-03-04 00:00:58,434 - INFO - Training   - Loss: 0.2917, Accuracy: 0.9011, F1: 0.9013
2025-03-04 00:00:58,434 - INFO - Validation - Loss: 0.0608, Accuracy: 0.9758, F1: 0.9758
2025-03-04 00:00:58,434 - INFO - Validation F1 improved from 0.9735 to 0.9758
2025-03-04 00:00:58,434 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:00:58,434 - INFO - Epoch 17/30
2025-03-04 00:00:58,434 - INFO - ----------------------------------------
2025-03-04 00:00:58,830 - INFO - [TRAIN] Epoch: 17/30 | Batch: 0/452 (0.2%) | Loss: 0.2382 | Batch time: 0.18s
2025-03-04 00:01:06,699 - INFO - [TRAIN] Epoch: 17/30 | Batch: 45/452 (10.2%) | Loss: 0.5112 | Batch time: 0.18s
2025-03-04 00:01:14,783 - INFO - [TRAIN] Epoch: 17/30 | Batch: 90/452 (20.1%) | Loss: 0.4616 | Batch time: 0.18s
2025-03-04 00:01:22,820 - INFO - [TRAIN] Epoch: 17/30 | Batch: 135/452 (30.1%) | Loss: 0.4312 | Batch time: 0.18s
2025-03-04 00:01:30,869 - INFO - [TRAIN] Epoch: 17/30 | Batch: 180/452 (40.0%) | Loss: 0.1921 | Batch time: 0.19s
2025-03-04 00:01:38,918 - INFO - [TRAIN] Epoch: 17/30 | Batch: 225/452 (50.0%) | Loss: 0.3167 | Batch time: 0.18s
2025-03-04 00:01:46,900 - INFO - [TRAIN] Epoch: 17/30 | Batch: 270/452 (60.0%) | Loss: 0.1560 | Batch time: 0.18s
2025-03-04 00:01:54,911 - INFO - [TRAIN] Epoch: 17/30 | Batch: 315/452 (69.9%) | Loss: 0.2752 | Batch time: 0.18s
2025-03-04 00:02:02,906 - INFO - [TRAIN] Epoch: 17/30 | Batch: 360/452 (79.9%) | Loss: 0.2874 | Batch time: 0.18s
2025-03-04 00:02:10,860 - INFO - [TRAIN] Epoch: 17/30 | Batch: 405/452 (89.8%) | Loss: 0.4505 | Batch time: 0.18s
2025-03-04 00:02:18,745 - INFO - [TRAIN] Epoch: 17/30 | Batch: 450/452 (99.8%) | Loss: 0.4172 | Batch time: 0.17s
2025-03-04 00:02:18,830 - INFO - [TRAIN] Epoch: 17/30 | Batch: 451/452 (100.0%) | Loss: 0.1603 | Batch time: 0.08s
2025-03-04 00:02:18,940 - INFO - [VAL] Epoch: 17/30 | Batch: 0/97 (1.0%) | Loss: 0.0073 | Batch time: 0.05s
2025-03-04 00:02:19,361 - INFO - [VAL] Epoch: 17/30 | Batch: 9/97 (10.3%) | Loss: 0.0076 | Batch time: 0.05s
2025-03-04 00:02:19,799 - INFO - [VAL] Epoch: 17/30 | Batch: 18/97 (19.6%) | Loss: 0.0676 | Batch time: 0.05s
2025-03-04 00:02:20,266 - INFO - [VAL] Epoch: 17/30 | Batch: 27/97 (28.9%) | Loss: 0.0096 | Batch time: 0.05s
2025-03-04 00:02:20,728 - INFO - [VAL] Epoch: 17/30 | Batch: 36/97 (38.1%) | Loss: 0.0108 | Batch time: 0.05s
2025-03-04 00:02:21,192 - INFO - [VAL] Epoch: 17/30 | Batch: 45/97 (47.4%) | Loss: 0.0412 | Batch time: 0.05s
2025-03-04 00:02:21,666 - INFO - [VAL] Epoch: 17/30 | Batch: 54/97 (56.7%) | Loss: 0.0061 | Batch time: 0.05s
2025-03-04 00:02:22,127 - INFO - [VAL] Epoch: 17/30 | Batch: 63/97 (66.0%) | Loss: 0.0480 | Batch time: 0.05s
2025-03-04 00:02:22,574 - INFO - [VAL] Epoch: 17/30 | Batch: 72/97 (75.3%) | Loss: 0.0594 | Batch time: 0.05s
2025-03-04 00:02:23,025 - INFO - [VAL] Epoch: 17/30 | Batch: 81/97 (84.5%) | Loss: 0.0086 | Batch time: 0.05s
2025-03-04 00:02:23,457 - INFO - [VAL] Epoch: 17/30 | Batch: 90/97 (93.8%) | Loss: 0.0137 | Batch time: 0.05s
2025-03-04 00:02:23,743 - INFO - [VAL] Epoch: 17/30 | Batch: 96/97 (100.0%) | Loss: 0.0318 | Batch time: 0.04s
2025-03-04 00:02:23,746 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:02:23,746 - INFO - Epoch 17/30 completed in 85.31s
2025-03-04 00:02:23,746 - INFO - Training   - Loss: 0.2874, Accuracy: 0.9018, F1: 0.9023
2025-03-04 00:02:23,746 - INFO - Validation - Loss: 0.0621, Accuracy: 0.9745, F1: 0.9746
2025-03-04 00:02:23,746 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:02:23,746 - INFO - Epoch 18/30
2025-03-04 00:02:23,746 - INFO - ----------------------------------------
2025-03-04 00:02:24,133 - INFO - [TRAIN] Epoch: 18/30 | Batch: 0/452 (0.2%) | Loss: 0.1592 | Batch time: 0.19s
2025-03-04 00:02:32,244 - INFO - [TRAIN] Epoch: 18/30 | Batch: 45/452 (10.2%) | Loss: 0.3057 | Batch time: 0.18s
2025-03-04 00:02:40,186 - INFO - [TRAIN] Epoch: 18/30 | Batch: 90/452 (20.1%) | Loss: 0.0655 | Batch time: 0.18s
2025-03-04 00:02:48,203 - INFO - [TRAIN] Epoch: 18/30 | Batch: 135/452 (30.1%) | Loss: 0.1238 | Batch time: 0.17s
2025-03-04 00:02:56,393 - INFO - [TRAIN] Epoch: 18/30 | Batch: 180/452 (40.0%) | Loss: 0.2607 | Batch time: 0.18s
2025-03-04 00:03:04,321 - INFO - [TRAIN] Epoch: 18/30 | Batch: 225/452 (50.0%) | Loss: 0.2452 | Batch time: 0.18s
2025-03-04 00:03:12,278 - INFO - [TRAIN] Epoch: 18/30 | Batch: 270/452 (60.0%) | Loss: 0.1925 | Batch time: 0.18s
2025-03-04 00:03:20,248 - INFO - [TRAIN] Epoch: 18/30 | Batch: 315/452 (69.9%) | Loss: 0.3820 | Batch time: 0.17s
2025-03-04 00:03:28,159 - INFO - [TRAIN] Epoch: 18/30 | Batch: 360/452 (79.9%) | Loss: 0.3168 | Batch time: 0.18s
2025-03-04 00:03:36,136 - INFO - [TRAIN] Epoch: 18/30 | Batch: 405/452 (89.8%) | Loss: 0.3370 | Batch time: 0.18s
2025-03-04 00:03:44,114 - INFO - [TRAIN] Epoch: 18/30 | Batch: 450/452 (99.8%) | Loss: 0.1954 | Batch time: 0.17s
2025-03-04 00:03:44,199 - INFO - [TRAIN] Epoch: 18/30 | Batch: 451/452 (100.0%) | Loss: 0.2480 | Batch time: 0.08s
2025-03-04 00:03:44,341 - INFO - [VAL] Epoch: 18/30 | Batch: 0/97 (1.0%) | Loss: 0.0076 | Batch time: 0.05s
2025-03-04 00:03:44,761 - INFO - [VAL] Epoch: 18/30 | Batch: 9/97 (10.3%) | Loss: 0.0055 | Batch time: 0.05s
2025-03-04 00:03:45,210 - INFO - [VAL] Epoch: 18/30 | Batch: 18/97 (19.6%) | Loss: 0.0985 | Batch time: 0.05s
2025-03-04 00:03:45,674 - INFO - [VAL] Epoch: 18/30 | Batch: 27/97 (28.9%) | Loss: 0.0117 | Batch time: 0.05s
2025-03-04 00:03:46,138 - INFO - [VAL] Epoch: 18/30 | Batch: 36/97 (38.1%) | Loss: 0.0149 | Batch time: 0.05s
2025-03-04 00:03:46,597 - INFO - [VAL] Epoch: 18/30 | Batch: 45/97 (47.4%) | Loss: 0.0277 | Batch time: 0.05s
2025-03-04 00:03:47,048 - INFO - [VAL] Epoch: 18/30 | Batch: 54/97 (56.7%) | Loss: 0.0052 | Batch time: 0.05s
2025-03-04 00:03:47,502 - INFO - [VAL] Epoch: 18/30 | Batch: 63/97 (66.0%) | Loss: 0.0582 | Batch time: 0.05s
2025-03-04 00:03:47,946 - INFO - [VAL] Epoch: 18/30 | Batch: 72/97 (75.3%) | Loss: 0.0421 | Batch time: 0.05s
2025-03-04 00:03:48,386 - INFO - [VAL] Epoch: 18/30 | Batch: 81/97 (84.5%) | Loss: 0.0099 | Batch time: 0.05s
2025-03-04 00:03:48,821 - INFO - [VAL] Epoch: 18/30 | Batch: 90/97 (93.8%) | Loss: 0.0121 | Batch time: 0.05s
2025-03-04 00:03:49,105 - INFO - [VAL] Epoch: 18/30 | Batch: 96/97 (100.0%) | Loss: 0.0259 | Batch time: 0.05s
2025-03-04 00:03:49,109 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:03:49,109 - INFO - Epoch 18/30 completed in 85.36s
2025-03-04 00:03:49,109 - INFO - Training   - Loss: 0.2686, Accuracy: 0.9082, F1: 0.9087
2025-03-04 00:03:49,109 - INFO - Validation - Loss: 0.0619, Accuracy: 0.9751, F1: 0.9752
2025-03-04 00:03:49,109 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:03:49,109 - INFO - Epoch 19/30
2025-03-04 00:03:49,109 - INFO - ----------------------------------------
2025-03-04 00:03:49,488 - INFO - [TRAIN] Epoch: 19/30 | Batch: 0/452 (0.2%) | Loss: 0.2094 | Batch time: 0.19s
2025-03-04 00:03:57,419 - INFO - [TRAIN] Epoch: 19/30 | Batch: 45/452 (10.2%) | Loss: 0.2591 | Batch time: 0.18s
2025-03-04 00:04:05,387 - INFO - [TRAIN] Epoch: 19/30 | Batch: 90/452 (20.1%) | Loss: 0.3047 | Batch time: 0.17s
2025-03-04 00:04:13,334 - INFO - [TRAIN] Epoch: 19/30 | Batch: 135/452 (30.1%) | Loss: 0.2244 | Batch time: 0.17s
2025-03-04 00:04:21,195 - INFO - [TRAIN] Epoch: 19/30 | Batch: 180/452 (40.0%) | Loss: 0.3661 | Batch time: 0.17s
2025-03-04 00:04:29,118 - INFO - [TRAIN] Epoch: 19/30 | Batch: 225/452 (50.0%) | Loss: 0.3973 | Batch time: 0.17s
2025-03-04 00:04:36,998 - INFO - [TRAIN] Epoch: 19/30 | Batch: 270/452 (60.0%) | Loss: 0.2280 | Batch time: 0.17s
2025-03-04 00:04:44,944 - INFO - [TRAIN] Epoch: 19/30 | Batch: 315/452 (69.9%) | Loss: 0.1784 | Batch time: 0.18s
2025-03-04 00:04:52,974 - INFO - [TRAIN] Epoch: 19/30 | Batch: 360/452 (79.9%) | Loss: 0.1758 | Batch time: 0.18s
2025-03-04 00:05:00,923 - INFO - [TRAIN] Epoch: 19/30 | Batch: 405/452 (89.8%) | Loss: 0.1227 | Batch time: 0.18s
2025-03-04 00:05:08,644 - INFO - [TRAIN] Epoch: 19/30 | Batch: 450/452 (99.8%) | Loss: 0.1449 | Batch time: 0.17s
2025-03-04 00:05:08,730 - INFO - [TRAIN] Epoch: 19/30 | Batch: 451/452 (100.0%) | Loss: 0.7924 | Batch time: 0.08s
2025-03-04 00:05:08,853 - INFO - [VAL] Epoch: 19/30 | Batch: 0/97 (1.0%) | Loss: 0.0068 | Batch time: 0.06s
2025-03-04 00:05:09,261 - INFO - [VAL] Epoch: 19/30 | Batch: 9/97 (10.3%) | Loss: 0.0141 | Batch time: 0.05s
2025-03-04 00:05:09,691 - INFO - [VAL] Epoch: 19/30 | Batch: 18/97 (19.6%) | Loss: 0.0888 | Batch time: 0.05s
2025-03-04 00:05:10,138 - INFO - [VAL] Epoch: 19/30 | Batch: 27/97 (28.9%) | Loss: 0.0092 | Batch time: 0.05s
2025-03-04 00:05:10,587 - INFO - [VAL] Epoch: 19/30 | Batch: 36/97 (38.1%) | Loss: 0.0229 | Batch time: 0.05s
2025-03-04 00:05:11,038 - INFO - [VAL] Epoch: 19/30 | Batch: 45/97 (47.4%) | Loss: 0.0261 | Batch time: 0.05s
2025-03-04 00:05:11,488 - INFO - [VAL] Epoch: 19/30 | Batch: 54/97 (56.7%) | Loss: 0.0066 | Batch time: 0.05s
2025-03-04 00:05:11,933 - INFO - [VAL] Epoch: 19/30 | Batch: 63/97 (66.0%) | Loss: 0.0518 | Batch time: 0.05s
2025-03-04 00:05:12,378 - INFO - [VAL] Epoch: 19/30 | Batch: 72/97 (75.3%) | Loss: 0.0451 | Batch time: 0.05s
2025-03-04 00:05:12,814 - INFO - [VAL] Epoch: 19/30 | Batch: 81/97 (84.5%) | Loss: 0.0102 | Batch time: 0.05s
2025-03-04 00:05:13,244 - INFO - [VAL] Epoch: 19/30 | Batch: 90/97 (93.8%) | Loss: 0.0139 | Batch time: 0.05s
2025-03-04 00:05:13,529 - INFO - [VAL] Epoch: 19/30 | Batch: 96/97 (100.0%) | Loss: 0.0286 | Batch time: 0.05s
2025-03-04 00:05:13,533 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:05:13,533 - INFO - Epoch 19/30 completed in 84.42s
2025-03-04 00:05:13,533 - INFO - Training   - Loss: 0.2869, Accuracy: 0.9027, F1: 0.9032
2025-03-04 00:05:13,533 - INFO - Validation - Loss: 0.0615, Accuracy: 0.9742, F1: 0.9742
2025-03-04 00:05:13,533 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:05:13,533 - INFO - Epoch 20/30
2025-03-04 00:05:13,533 - INFO - ----------------------------------------
2025-03-04 00:05:13,920 - INFO - [TRAIN] Epoch: 20/30 | Batch: 0/452 (0.2%) | Loss: 0.3579 | Batch time: 0.19s
2025-03-04 00:05:22,078 - INFO - [TRAIN] Epoch: 20/30 | Batch: 45/452 (10.2%) | Loss: 0.2206 | Batch time: 0.18s
2025-03-04 00:05:29,916 - INFO - [TRAIN] Epoch: 20/30 | Batch: 90/452 (20.1%) | Loss: 0.2296 | Batch time: 0.17s
2025-03-04 00:05:37,775 - INFO - [TRAIN] Epoch: 20/30 | Batch: 135/452 (30.1%) | Loss: 0.1714 | Batch time: 0.17s
2025-03-04 00:05:45,658 - INFO - [TRAIN] Epoch: 20/30 | Batch: 180/452 (40.0%) | Loss: 0.2784 | Batch time: 0.17s
2025-03-04 00:05:53,603 - INFO - [TRAIN] Epoch: 20/30 | Batch: 225/452 (50.0%) | Loss: 0.2728 | Batch time: 0.17s
2025-03-04 00:06:01,587 - INFO - [TRAIN] Epoch: 20/30 | Batch: 270/452 (60.0%) | Loss: 0.0640 | Batch time: 0.17s
2025-03-04 00:06:09,471 - INFO - [TRAIN] Epoch: 20/30 | Batch: 315/452 (69.9%) | Loss: 0.1946 | Batch time: 0.17s
2025-03-04 00:06:17,392 - INFO - [TRAIN] Epoch: 20/30 | Batch: 360/452 (79.9%) | Loss: 0.1319 | Batch time: 0.17s
2025-03-04 00:06:25,463 - INFO - [TRAIN] Epoch: 20/30 | Batch: 405/452 (89.8%) | Loss: 0.1800 | Batch time: 0.18s
2025-03-04 00:06:33,385 - INFO - [TRAIN] Epoch: 20/30 | Batch: 450/452 (99.8%) | Loss: 0.1256 | Batch time: 0.17s
2025-03-04 00:06:33,473 - INFO - [TRAIN] Epoch: 20/30 | Batch: 451/452 (100.0%) | Loss: 0.3189 | Batch time: 0.09s
2025-03-04 00:06:33,601 - INFO - [VAL] Epoch: 20/30 | Batch: 0/97 (1.0%) | Loss: 0.0105 | Batch time: 0.06s
2025-03-04 00:06:34,026 - INFO - [VAL] Epoch: 20/30 | Batch: 9/97 (10.3%) | Loss: 0.0056 | Batch time: 0.05s
2025-03-04 00:06:34,477 - INFO - [VAL] Epoch: 20/30 | Batch: 18/97 (19.6%) | Loss: 0.0903 | Batch time: 0.05s
2025-03-04 00:06:34,934 - INFO - [VAL] Epoch: 20/30 | Batch: 27/97 (28.9%) | Loss: 0.0075 | Batch time: 0.05s
2025-03-04 00:06:35,384 - INFO - [VAL] Epoch: 20/30 | Batch: 36/97 (38.1%) | Loss: 0.0218 | Batch time: 0.05s
2025-03-04 00:06:35,828 - INFO - [VAL] Epoch: 20/30 | Batch: 45/97 (47.4%) | Loss: 0.0289 | Batch time: 0.05s
2025-03-04 00:06:36,267 - INFO - [VAL] Epoch: 20/30 | Batch: 54/97 (56.7%) | Loss: 0.0053 | Batch time: 0.05s
2025-03-04 00:06:36,705 - INFO - [VAL] Epoch: 20/30 | Batch: 63/97 (66.0%) | Loss: 0.0412 | Batch time: 0.05s
2025-03-04 00:06:37,143 - INFO - [VAL] Epoch: 20/30 | Batch: 72/97 (75.3%) | Loss: 0.0456 | Batch time: 0.05s
2025-03-04 00:06:37,574 - INFO - [VAL] Epoch: 20/30 | Batch: 81/97 (84.5%) | Loss: 0.0094 | Batch time: 0.05s
2025-03-04 00:06:38,005 - INFO - [VAL] Epoch: 20/30 | Batch: 90/97 (93.8%) | Loss: 0.0151 | Batch time: 0.05s
2025-03-04 00:06:38,286 - INFO - [VAL] Epoch: 20/30 | Batch: 96/97 (100.0%) | Loss: 0.0252 | Batch time: 0.04s
2025-03-04 00:06:39,014 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 20)
2025-03-04 00:06:39,014 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:06:39,014 - INFO - Epoch 20/30 completed in 85.48s
2025-03-04 00:06:39,014 - INFO - Training   - Loss: 0.2786, Accuracy: 0.9053, F1: 0.9057
2025-03-04 00:06:39,014 - INFO - Validation - Loss: 0.0607, Accuracy: 0.9764, F1: 0.9764
2025-03-04 00:06:39,014 - INFO - Validation F1 improved from 0.9758 to 0.9764
2025-03-04 00:06:39,014 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:06:39,526 - INFO - Checkpoint saved: checkpoint_epoch_20.pth (Epoch 20)
2025-03-04 00:06:39,526 - INFO - Epoch 21/30
2025-03-04 00:06:39,526 - INFO - ----------------------------------------
2025-03-04 00:06:39,935 - INFO - [TRAIN] Epoch: 21/30 | Batch: 0/452 (0.2%) | Loss: 0.1122 | Batch time: 0.22s
2025-03-04 00:06:47,896 - INFO - [TRAIN] Epoch: 21/30 | Batch: 45/452 (10.2%) | Loss: 0.2444 | Batch time: 0.18s
2025-03-04 00:06:55,950 - INFO - [TRAIN] Epoch: 21/30 | Batch: 90/452 (20.1%) | Loss: 0.2912 | Batch time: 0.17s
2025-03-04 00:07:03,961 - INFO - [TRAIN] Epoch: 21/30 | Batch: 135/452 (30.1%) | Loss: 0.2238 | Batch time: 0.18s
2025-03-04 00:07:11,903 - INFO - [TRAIN] Epoch: 21/30 | Batch: 180/452 (40.0%) | Loss: 0.3535 | Batch time: 0.18s
2025-03-04 00:07:19,792 - INFO - [TRAIN] Epoch: 21/30 | Batch: 225/452 (50.0%) | Loss: 0.1959 | Batch time: 0.18s
2025-03-04 00:07:27,759 - INFO - [TRAIN] Epoch: 21/30 | Batch: 270/452 (60.0%) | Loss: 0.2782 | Batch time: 0.17s
2025-03-04 00:07:35,673 - INFO - [TRAIN] Epoch: 21/30 | Batch: 315/452 (69.9%) | Loss: 0.4197 | Batch time: 0.18s
2025-03-04 00:07:43,737 - INFO - [TRAIN] Epoch: 21/30 | Batch: 360/452 (79.9%) | Loss: 0.2596 | Batch time: 0.18s
2025-03-04 00:07:51,766 - INFO - [TRAIN] Epoch: 21/30 | Batch: 405/452 (89.8%) | Loss: 0.1828 | Batch time: 0.18s
2025-03-04 00:07:59,510 - INFO - [TRAIN] Epoch: 21/30 | Batch: 450/452 (99.8%) | Loss: 0.2687 | Batch time: 0.17s
2025-03-04 00:07:59,594 - INFO - [TRAIN] Epoch: 21/30 | Batch: 451/452 (100.0%) | Loss: 1.0078 | Batch time: 0.08s
2025-03-04 00:07:59,704 - INFO - [VAL] Epoch: 21/30 | Batch: 0/97 (1.0%) | Loss: 0.0034 | Batch time: 0.05s
2025-03-04 00:08:00,108 - INFO - [VAL] Epoch: 21/30 | Batch: 9/97 (10.3%) | Loss: 0.0073 | Batch time: 0.05s
2025-03-04 00:08:00,527 - INFO - [VAL] Epoch: 21/30 | Batch: 18/97 (19.6%) | Loss: 0.1004 | Batch time: 0.05s
2025-03-04 00:08:00,961 - INFO - [VAL] Epoch: 21/30 | Batch: 27/97 (28.9%) | Loss: 0.0117 | Batch time: 0.05s
2025-03-04 00:08:01,402 - INFO - [VAL] Epoch: 21/30 | Batch: 36/97 (38.1%) | Loss: 0.0146 | Batch time: 0.05s
2025-03-04 00:08:01,843 - INFO - [VAL] Epoch: 21/30 | Batch: 45/97 (47.4%) | Loss: 0.0264 | Batch time: 0.05s
2025-03-04 00:08:02,282 - INFO - [VAL] Epoch: 21/30 | Batch: 54/97 (56.7%) | Loss: 0.0046 | Batch time: 0.05s
2025-03-04 00:08:02,722 - INFO - [VAL] Epoch: 21/30 | Batch: 63/97 (66.0%) | Loss: 0.0546 | Batch time: 0.05s
2025-03-04 00:08:03,163 - INFO - [VAL] Epoch: 21/30 | Batch: 72/97 (75.3%) | Loss: 0.0625 | Batch time: 0.05s
2025-03-04 00:08:03,598 - INFO - [VAL] Epoch: 21/30 | Batch: 81/97 (84.5%) | Loss: 0.0077 | Batch time: 0.05s
2025-03-04 00:08:04,031 - INFO - [VAL] Epoch: 21/30 | Batch: 90/97 (93.8%) | Loss: 0.0138 | Batch time: 0.05s
2025-03-04 00:08:04,313 - INFO - [VAL] Epoch: 21/30 | Batch: 96/97 (100.0%) | Loss: 0.0217 | Batch time: 0.04s
2025-03-04 00:08:04,317 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:08:04,317 - INFO - Epoch 21/30 completed in 84.79s
2025-03-04 00:08:04,317 - INFO - Training   - Loss: 0.2719, Accuracy: 0.9088, F1: 0.9091
2025-03-04 00:08:04,317 - INFO - Validation - Loss: 0.0633, Accuracy: 0.9745, F1: 0.9745
2025-03-04 00:08:04,317 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:08:04,317 - INFO - Epoch 22/30
2025-03-04 00:08:04,317 - INFO - ----------------------------------------
2025-03-04 00:08:04,730 - INFO - [TRAIN] Epoch: 22/30 | Batch: 0/452 (0.2%) | Loss: 0.2874 | Batch time: 0.18s
2025-03-04 00:08:12,780 - INFO - [TRAIN] Epoch: 22/30 | Batch: 45/452 (10.2%) | Loss: 0.5129 | Batch time: 0.17s
2025-03-04 00:08:20,811 - INFO - [TRAIN] Epoch: 22/30 | Batch: 90/452 (20.1%) | Loss: 0.2504 | Batch time: 0.18s
2025-03-04 00:08:28,722 - INFO - [TRAIN] Epoch: 22/30 | Batch: 135/452 (30.1%) | Loss: 0.1185 | Batch time: 0.18s
2025-03-04 00:08:36,809 - INFO - [TRAIN] Epoch: 22/30 | Batch: 180/452 (40.0%) | Loss: 0.2562 | Batch time: 0.18s
2025-03-04 00:08:44,775 - INFO - [TRAIN] Epoch: 22/30 | Batch: 225/452 (50.0%) | Loss: 0.2160 | Batch time: 0.17s
2025-03-04 00:08:52,866 - INFO - [TRAIN] Epoch: 22/30 | Batch: 270/452 (60.0%) | Loss: 0.1951 | Batch time: 0.18s
2025-03-04 00:09:00,999 - INFO - [TRAIN] Epoch: 22/30 | Batch: 315/452 (69.9%) | Loss: 0.4071 | Batch time: 0.19s
2025-03-04 00:09:09,065 - INFO - [TRAIN] Epoch: 22/30 | Batch: 360/452 (79.9%) | Loss: 0.1689 | Batch time: 0.18s
2025-03-04 00:09:17,069 - INFO - [TRAIN] Epoch: 22/30 | Batch: 405/452 (89.8%) | Loss: 0.1033 | Batch time: 0.17s
2025-03-04 00:09:24,847 - INFO - [TRAIN] Epoch: 22/30 | Batch: 450/452 (99.8%) | Loss: 0.4918 | Batch time: 0.17s
2025-03-04 00:09:24,932 - INFO - [TRAIN] Epoch: 22/30 | Batch: 451/452 (100.0%) | Loss: 0.7932 | Batch time: 0.08s
2025-03-04 00:09:25,041 - INFO - [VAL] Epoch: 22/30 | Batch: 0/97 (1.0%) | Loss: 0.0033 | Batch time: 0.05s
2025-03-04 00:09:25,451 - INFO - [VAL] Epoch: 22/30 | Batch: 9/97 (10.3%) | Loss: 0.0077 | Batch time: 0.05s
2025-03-04 00:09:25,873 - INFO - [VAL] Epoch: 22/30 | Batch: 18/97 (19.6%) | Loss: 0.0758 | Batch time: 0.05s
2025-03-04 00:09:26,314 - INFO - [VAL] Epoch: 22/30 | Batch: 27/97 (28.9%) | Loss: 0.0148 | Batch time: 0.05s
2025-03-04 00:09:26,759 - INFO - [VAL] Epoch: 22/30 | Batch: 36/97 (38.1%) | Loss: 0.0202 | Batch time: 0.05s
2025-03-04 00:09:27,209 - INFO - [VAL] Epoch: 22/30 | Batch: 45/97 (47.4%) | Loss: 0.0292 | Batch time: 0.05s
2025-03-04 00:09:27,657 - INFO - [VAL] Epoch: 22/30 | Batch: 54/97 (56.7%) | Loss: 0.0051 | Batch time: 0.05s
2025-03-04 00:09:28,104 - INFO - [VAL] Epoch: 22/30 | Batch: 63/97 (66.0%) | Loss: 0.0535 | Batch time: 0.05s
2025-03-04 00:09:28,551 - INFO - [VAL] Epoch: 22/30 | Batch: 72/97 (75.3%) | Loss: 0.0440 | Batch time: 0.05s
2025-03-04 00:09:29,001 - INFO - [VAL] Epoch: 22/30 | Batch: 81/97 (84.5%) | Loss: 0.0122 | Batch time: 0.05s
2025-03-04 00:09:29,445 - INFO - [VAL] Epoch: 22/30 | Batch: 90/97 (93.8%) | Loss: 0.0237 | Batch time: 0.05s
2025-03-04 00:09:29,743 - INFO - [VAL] Epoch: 22/30 | Batch: 96/97 (100.0%) | Loss: 0.0320 | Batch time: 0.05s
2025-03-04 00:09:29,746 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:09:29,746 - INFO - Epoch 22/30 completed in 85.43s
2025-03-04 00:09:29,746 - INFO - Training   - Loss: 0.2657, Accuracy: 0.9075, F1: 0.9079
2025-03-04 00:09:29,746 - INFO - Validation - Loss: 0.0649, Accuracy: 0.9706, F1: 0.9707
2025-03-04 00:09:29,746 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:09:29,747 - INFO - Epoch 23/30
2025-03-04 00:09:29,747 - INFO - ----------------------------------------
2025-03-04 00:09:30,150 - INFO - [TRAIN] Epoch: 23/30 | Batch: 0/452 (0.2%) | Loss: 0.2705 | Batch time: 0.19s
2025-03-04 00:09:38,321 - INFO - [TRAIN] Epoch: 23/30 | Batch: 45/452 (10.2%) | Loss: 0.1925 | Batch time: 0.18s
2025-03-04 00:09:46,358 - INFO - [TRAIN] Epoch: 23/30 | Batch: 90/452 (20.1%) | Loss: 0.3199 | Batch time: 0.17s
2025-03-04 00:09:54,232 - INFO - [TRAIN] Epoch: 23/30 | Batch: 135/452 (30.1%) | Loss: 0.2095 | Batch time: 0.17s
2025-03-04 00:10:02,136 - INFO - [TRAIN] Epoch: 23/30 | Batch: 180/452 (40.0%) | Loss: 0.3786 | Batch time: 0.17s
2025-03-04 00:10:10,041 - INFO - [TRAIN] Epoch: 23/30 | Batch: 225/452 (50.0%) | Loss: 0.1746 | Batch time: 0.18s
2025-03-04 00:10:17,935 - INFO - [TRAIN] Epoch: 23/30 | Batch: 270/452 (60.0%) | Loss: 0.3121 | Batch time: 0.17s
2025-03-04 00:10:26,423 - INFO - [TRAIN] Epoch: 23/30 | Batch: 315/452 (69.9%) | Loss: 0.5268 | Batch time: 0.19s
2025-03-04 00:10:34,539 - INFO - [TRAIN] Epoch: 23/30 | Batch: 360/452 (79.9%) | Loss: 0.1117 | Batch time: 0.17s
2025-03-04 00:10:42,457 - INFO - [TRAIN] Epoch: 23/30 | Batch: 405/452 (89.8%) | Loss: 0.4181 | Batch time: 0.17s
2025-03-04 00:10:50,242 - INFO - [TRAIN] Epoch: 23/30 | Batch: 450/452 (99.8%) | Loss: 0.1502 | Batch time: 0.17s
2025-03-04 00:10:50,329 - INFO - [TRAIN] Epoch: 23/30 | Batch: 451/452 (100.0%) | Loss: 0.7865 | Batch time: 0.09s
2025-03-04 00:10:50,438 - INFO - [VAL] Epoch: 23/30 | Batch: 0/97 (1.0%) | Loss: 0.0034 | Batch time: 0.05s
2025-03-04 00:10:50,862 - INFO - [VAL] Epoch: 23/30 | Batch: 9/97 (10.3%) | Loss: 0.0091 | Batch time: 0.05s
2025-03-04 00:10:51,303 - INFO - [VAL] Epoch: 23/30 | Batch: 18/97 (19.6%) | Loss: 0.0913 | Batch time: 0.05s
2025-03-04 00:10:51,761 - INFO - [VAL] Epoch: 23/30 | Batch: 27/97 (28.9%) | Loss: 0.0081 | Batch time: 0.05s
2025-03-04 00:10:52,224 - INFO - [VAL] Epoch: 23/30 | Batch: 36/97 (38.1%) | Loss: 0.0142 | Batch time: 0.05s
2025-03-04 00:10:52,680 - INFO - [VAL] Epoch: 23/30 | Batch: 45/97 (47.4%) | Loss: 0.0211 | Batch time: 0.05s
2025-03-04 00:10:53,129 - INFO - [VAL] Epoch: 23/30 | Batch: 54/97 (56.7%) | Loss: 0.0061 | Batch time: 0.05s
2025-03-04 00:10:53,569 - INFO - [VAL] Epoch: 23/30 | Batch: 63/97 (66.0%) | Loss: 0.0506 | Batch time: 0.05s
2025-03-04 00:10:54,006 - INFO - [VAL] Epoch: 23/30 | Batch: 72/97 (75.3%) | Loss: 0.0504 | Batch time: 0.05s
2025-03-04 00:10:54,437 - INFO - [VAL] Epoch: 23/30 | Batch: 81/97 (84.5%) | Loss: 0.0067 | Batch time: 0.05s
2025-03-04 00:10:54,863 - INFO - [VAL] Epoch: 23/30 | Batch: 90/97 (93.8%) | Loss: 0.0145 | Batch time: 0.05s
2025-03-04 00:10:55,139 - INFO - [VAL] Epoch: 23/30 | Batch: 96/97 (100.0%) | Loss: 0.0284 | Batch time: 0.04s
2025-03-04 00:10:55,142 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:10:55,142 - INFO - Epoch 23/30 completed in 85.40s
2025-03-04 00:10:55,142 - INFO - Training   - Loss: 0.2785, Accuracy: 0.9046, F1: 0.9050
2025-03-04 00:10:55,142 - INFO - Validation - Loss: 0.0575, Accuracy: 0.9755, F1: 0.9755
2025-03-04 00:10:55,142 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:10:55,143 - INFO - Epoch 24/30
2025-03-04 00:10:55,143 - INFO - ----------------------------------------
2025-03-04 00:10:55,524 - INFO - [TRAIN] Epoch: 24/30 | Batch: 0/452 (0.2%) | Loss: 0.2638 | Batch time: 0.18s
2025-03-04 00:11:03,477 - INFO - [TRAIN] Epoch: 24/30 | Batch: 45/452 (10.2%) | Loss: 0.4636 | Batch time: 0.17s
2025-03-04 00:11:11,315 - INFO - [TRAIN] Epoch: 24/30 | Batch: 90/452 (20.1%) | Loss: 0.3089 | Batch time: 0.17s
2025-03-04 00:11:19,159 - INFO - [TRAIN] Epoch: 24/30 | Batch: 135/452 (30.1%) | Loss: 0.2356 | Batch time: 0.18s
2025-03-04 00:11:27,119 - INFO - [TRAIN] Epoch: 24/30 | Batch: 180/452 (40.0%) | Loss: 0.3492 | Batch time: 0.17s
2025-03-04 00:11:34,960 - INFO - [TRAIN] Epoch: 24/30 | Batch: 225/452 (50.0%) | Loss: 0.4459 | Batch time: 0.17s
2025-03-04 00:11:42,901 - INFO - [TRAIN] Epoch: 24/30 | Batch: 270/452 (60.0%) | Loss: 0.1249 | Batch time: 0.17s
2025-03-04 00:11:50,801 - INFO - [TRAIN] Epoch: 24/30 | Batch: 315/452 (69.9%) | Loss: 0.2928 | Batch time: 0.17s
2025-03-04 00:11:58,744 - INFO - [TRAIN] Epoch: 24/30 | Batch: 360/452 (79.9%) | Loss: 0.0623 | Batch time: 0.18s
2025-03-04 00:12:06,724 - INFO - [TRAIN] Epoch: 24/30 | Batch: 405/452 (89.8%) | Loss: 0.1940 | Batch time: 0.17s
2025-03-04 00:12:14,581 - INFO - [TRAIN] Epoch: 24/30 | Batch: 450/452 (99.8%) | Loss: 0.5898 | Batch time: 0.17s
2025-03-04 00:12:14,666 - INFO - [TRAIN] Epoch: 24/30 | Batch: 451/452 (100.0%) | Loss: 0.6219 | Batch time: 0.08s
2025-03-04 00:12:14,773 - INFO - [VAL] Epoch: 24/30 | Batch: 0/97 (1.0%) | Loss: 0.0040 | Batch time: 0.05s
2025-03-04 00:12:15,181 - INFO - [VAL] Epoch: 24/30 | Batch: 9/97 (10.3%) | Loss: 0.0067 | Batch time: 0.05s
2025-03-04 00:12:15,609 - INFO - [VAL] Epoch: 24/30 | Batch: 18/97 (19.6%) | Loss: 0.0894 | Batch time: 0.05s
2025-03-04 00:12:16,057 - INFO - [VAL] Epoch: 24/30 | Batch: 27/97 (28.9%) | Loss: 0.0103 | Batch time: 0.05s
2025-03-04 00:12:16,501 - INFO - [VAL] Epoch: 24/30 | Batch: 36/97 (38.1%) | Loss: 0.0204 | Batch time: 0.05s
2025-03-04 00:12:16,959 - INFO - [VAL] Epoch: 24/30 | Batch: 45/97 (47.4%) | Loss: 0.0295 | Batch time: 0.05s
2025-03-04 00:12:17,418 - INFO - [VAL] Epoch: 24/30 | Batch: 54/97 (56.7%) | Loss: 0.0046 | Batch time: 0.05s
2025-03-04 00:12:17,875 - INFO - [VAL] Epoch: 24/30 | Batch: 63/97 (66.0%) | Loss: 0.0537 | Batch time: 0.05s
2025-03-04 00:12:18,329 - INFO - [VAL] Epoch: 24/30 | Batch: 72/97 (75.3%) | Loss: 0.0372 | Batch time: 0.05s
2025-03-04 00:12:18,773 - INFO - [VAL] Epoch: 24/30 | Batch: 81/97 (84.5%) | Loss: 0.0113 | Batch time: 0.05s
2025-03-04 00:12:19,208 - INFO - [VAL] Epoch: 24/30 | Batch: 90/97 (93.8%) | Loss: 0.0262 | Batch time: 0.05s
2025-03-04 00:12:19,513 - INFO - [VAL] Epoch: 24/30 | Batch: 96/97 (100.0%) | Loss: 0.0355 | Batch time: 0.04s
2025-03-04 00:12:19,516 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:12:19,516 - INFO - Epoch 24/30 completed in 84.37s
2025-03-04 00:12:19,517 - INFO - Training   - Loss: 0.2673, Accuracy: 0.9110, F1: 0.9112
2025-03-04 00:12:19,517 - INFO - Validation - Loss: 0.0624, Accuracy: 0.9729, F1: 0.9729
2025-03-04 00:12:19,517 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:12:19,517 - INFO - Epoch 25/30
2025-03-04 00:12:19,517 - INFO - ----------------------------------------
2025-03-04 00:12:19,899 - INFO - [TRAIN] Epoch: 25/30 | Batch: 0/452 (0.2%) | Loss: 0.1232 | Batch time: 0.18s
2025-03-04 00:12:27,967 - INFO - [TRAIN] Epoch: 25/30 | Batch: 45/452 (10.2%) | Loss: 0.3118 | Batch time: 0.18s
2025-03-04 00:12:35,891 - INFO - [TRAIN] Epoch: 25/30 | Batch: 90/452 (20.1%) | Loss: 0.1368 | Batch time: 0.18s
2025-03-04 00:12:43,870 - INFO - [TRAIN] Epoch: 25/30 | Batch: 135/452 (30.1%) | Loss: 0.1388 | Batch time: 0.18s
2025-03-04 00:12:51,816 - INFO - [TRAIN] Epoch: 25/30 | Batch: 180/452 (40.0%) | Loss: 0.2535 | Batch time: 0.17s
2025-03-04 00:12:59,867 - INFO - [TRAIN] Epoch: 25/30 | Batch: 225/452 (50.0%) | Loss: 0.2135 | Batch time: 0.18s
2025-03-04 00:13:07,872 - INFO - [TRAIN] Epoch: 25/30 | Batch: 270/452 (60.0%) | Loss: 0.1343 | Batch time: 0.18s
2025-03-04 00:13:15,815 - INFO - [TRAIN] Epoch: 25/30 | Batch: 315/452 (69.9%) | Loss: 0.3088 | Batch time: 0.18s
2025-03-04 00:13:23,742 - INFO - [TRAIN] Epoch: 25/30 | Batch: 360/452 (79.9%) | Loss: 0.2770 | Batch time: 0.18s
2025-03-04 00:13:31,680 - INFO - [TRAIN] Epoch: 25/30 | Batch: 405/452 (89.8%) | Loss: 0.3159 | Batch time: 0.18s
2025-03-04 00:13:39,598 - INFO - [TRAIN] Epoch: 25/30 | Batch: 450/452 (99.8%) | Loss: 0.0797 | Batch time: 0.17s
2025-03-04 00:13:39,684 - INFO - [TRAIN] Epoch: 25/30 | Batch: 451/452 (100.0%) | Loss: 0.3398 | Batch time: 0.08s
2025-03-04 00:13:39,795 - INFO - [VAL] Epoch: 25/30 | Batch: 0/97 (1.0%) | Loss: 0.0034 | Batch time: 0.05s
2025-03-04 00:13:40,212 - INFO - [VAL] Epoch: 25/30 | Batch: 9/97 (10.3%) | Loss: 0.0079 | Batch time: 0.05s
2025-03-04 00:13:40,648 - INFO - [VAL] Epoch: 25/30 | Batch: 18/97 (19.6%) | Loss: 0.0815 | Batch time: 0.05s
2025-03-04 00:13:41,099 - INFO - [VAL] Epoch: 25/30 | Batch: 27/97 (28.9%) | Loss: 0.0076 | Batch time: 0.05s
2025-03-04 00:13:41,552 - INFO - [VAL] Epoch: 25/30 | Batch: 36/97 (38.1%) | Loss: 0.0150 | Batch time: 0.05s
2025-03-04 00:13:42,007 - INFO - [VAL] Epoch: 25/30 | Batch: 45/97 (47.4%) | Loss: 0.0227 | Batch time: 0.05s
2025-03-04 00:13:42,460 - INFO - [VAL] Epoch: 25/30 | Batch: 54/97 (56.7%) | Loss: 0.0045 | Batch time: 0.05s
2025-03-04 00:13:42,907 - INFO - [VAL] Epoch: 25/30 | Batch: 63/97 (66.0%) | Loss: 0.0522 | Batch time: 0.05s
2025-03-04 00:13:43,349 - INFO - [VAL] Epoch: 25/30 | Batch: 72/97 (75.3%) | Loss: 0.0496 | Batch time: 0.05s
2025-03-04 00:13:43,782 - INFO - [VAL] Epoch: 25/30 | Batch: 81/97 (84.5%) | Loss: 0.0066 | Batch time: 0.05s
2025-03-04 00:13:44,220 - INFO - [VAL] Epoch: 25/30 | Batch: 90/97 (93.8%) | Loss: 0.0219 | Batch time: 0.05s
2025-03-04 00:13:44,513 - INFO - [VAL] Epoch: 25/30 | Batch: 96/97 (100.0%) | Loss: 0.0243 | Batch time: 0.04s
2025-03-04 00:13:44,517 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:13:44,517 - INFO - Epoch 25/30 completed in 85.00s
2025-03-04 00:13:44,517 - INFO - Training   - Loss: 0.2726, Accuracy: 0.9078, F1: 0.9082
2025-03-04 00:13:44,517 - INFO - Validation - Loss: 0.0603, Accuracy: 0.9748, F1: 0.9749
2025-03-04 00:13:44,517 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:13:45,207 - INFO - Checkpoint saved: checkpoint_epoch_25.pth (Epoch 25)
2025-03-04 00:13:45,208 - INFO - Epoch 26/30
2025-03-04 00:13:45,208 - INFO - ----------------------------------------
2025-03-04 00:13:45,683 - INFO - [TRAIN] Epoch: 26/30 | Batch: 0/452 (0.2%) | Loss: 0.1205 | Batch time: 0.22s
2025-03-04 00:13:54,139 - INFO - [TRAIN] Epoch: 26/30 | Batch: 45/452 (10.2%) | Loss: 0.2518 | Batch time: 0.18s
2025-03-04 00:14:02,231 - INFO - [TRAIN] Epoch: 26/30 | Batch: 90/452 (20.1%) | Loss: 0.2742 | Batch time: 0.18s
2025-03-04 00:14:10,466 - INFO - [TRAIN] Epoch: 26/30 | Batch: 135/452 (30.1%) | Loss: 0.1988 | Batch time: 0.18s
2025-03-04 00:14:18,613 - INFO - [TRAIN] Epoch: 26/30 | Batch: 180/452 (40.0%) | Loss: 0.2818 | Batch time: 0.19s
2025-03-04 00:14:26,871 - INFO - [TRAIN] Epoch: 26/30 | Batch: 225/452 (50.0%) | Loss: 0.2545 | Batch time: 0.18s
2025-03-04 00:14:35,088 - INFO - [TRAIN] Epoch: 26/30 | Batch: 270/452 (60.0%) | Loss: 0.2923 | Batch time: 0.18s
2025-03-04 00:14:43,423 - INFO - [TRAIN] Epoch: 26/30 | Batch: 315/452 (69.9%) | Loss: 0.1960 | Batch time: 0.18s
2025-03-04 00:14:51,699 - INFO - [TRAIN] Epoch: 26/30 | Batch: 360/452 (79.9%) | Loss: 0.0289 | Batch time: 0.19s
2025-03-04 00:15:00,008 - INFO - [TRAIN] Epoch: 26/30 | Batch: 405/452 (89.8%) | Loss: 0.5277 | Batch time: 0.18s
2025-03-04 00:15:08,220 - INFO - [TRAIN] Epoch: 26/30 | Batch: 450/452 (99.8%) | Loss: 0.3142 | Batch time: 0.18s
2025-03-04 00:15:08,308 - INFO - [TRAIN] Epoch: 26/30 | Batch: 451/452 (100.0%) | Loss: 0.2918 | Batch time: 0.09s
2025-03-04 00:15:08,428 - INFO - [VAL] Epoch: 26/30 | Batch: 0/97 (1.0%) | Loss: 0.0037 | Batch time: 0.05s
2025-03-04 00:15:08,852 - INFO - [VAL] Epoch: 26/30 | Batch: 9/97 (10.3%) | Loss: 0.0049 | Batch time: 0.05s
2025-03-04 00:15:09,297 - INFO - [VAL] Epoch: 26/30 | Batch: 18/97 (19.6%) | Loss: 0.0922 | Batch time: 0.05s
2025-03-04 00:15:09,771 - INFO - [VAL] Epoch: 26/30 | Batch: 27/97 (28.9%) | Loss: 0.0116 | Batch time: 0.05s
2025-03-04 00:15:10,229 - INFO - [VAL] Epoch: 26/30 | Batch: 36/97 (38.1%) | Loss: 0.0115 | Batch time: 0.05s
2025-03-04 00:15:10,689 - INFO - [VAL] Epoch: 26/30 | Batch: 45/97 (47.4%) | Loss: 0.0182 | Batch time: 0.05s
2025-03-04 00:15:11,143 - INFO - [VAL] Epoch: 26/30 | Batch: 54/97 (56.7%) | Loss: 0.0048 | Batch time: 0.05s
2025-03-04 00:15:11,593 - INFO - [VAL] Epoch: 26/30 | Batch: 63/97 (66.0%) | Loss: 0.0449 | Batch time: 0.05s
2025-03-04 00:15:12,040 - INFO - [VAL] Epoch: 26/30 | Batch: 72/97 (75.3%) | Loss: 0.0463 | Batch time: 0.05s
2025-03-04 00:15:12,478 - INFO - [VAL] Epoch: 26/30 | Batch: 81/97 (84.5%) | Loss: 0.0078 | Batch time: 0.05s
2025-03-04 00:15:12,911 - INFO - [VAL] Epoch: 26/30 | Batch: 90/97 (93.8%) | Loss: 0.0142 | Batch time: 0.05s
2025-03-04 00:15:13,199 - INFO - [VAL] Epoch: 26/30 | Batch: 96/97 (100.0%) | Loss: 0.0237 | Batch time: 0.05s
2025-03-04 00:15:13,203 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:15:13,203 - INFO - Epoch 26/30 completed in 88.00s
2025-03-04 00:15:13,203 - INFO - Training   - Loss: 0.2709, Accuracy: 0.9060, F1: 0.9063
2025-03-04 00:15:13,203 - INFO - Validation - Loss: 0.0606, Accuracy: 0.9745, F1: 0.9745
2025-03-04 00:15:13,203 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:15:13,203 - INFO - Epoch 27/30
2025-03-04 00:15:13,204 - INFO - ----------------------------------------
2025-03-04 00:15:13,611 - INFO - [TRAIN] Epoch: 27/30 | Batch: 0/452 (0.2%) | Loss: 0.2351 | Batch time: 0.19s
2025-03-04 00:15:21,894 - INFO - [TRAIN] Epoch: 27/30 | Batch: 45/452 (10.2%) | Loss: 0.4090 | Batch time: 0.18s
2025-03-04 00:15:30,137 - INFO - [TRAIN] Epoch: 27/30 | Batch: 90/452 (20.1%) | Loss: 0.1275 | Batch time: 0.18s
2025-03-04 00:15:38,183 - INFO - [TRAIN] Epoch: 27/30 | Batch: 135/452 (30.1%) | Loss: 0.0995 | Batch time: 0.19s
2025-03-04 00:15:46,330 - INFO - [TRAIN] Epoch: 27/30 | Batch: 180/452 (40.0%) | Loss: 0.2083 | Batch time: 0.18s
2025-03-04 00:15:54,534 - INFO - [TRAIN] Epoch: 27/30 | Batch: 225/452 (50.0%) | Loss: 0.0853 | Batch time: 0.18s
2025-03-04 00:16:02,766 - INFO - [TRAIN] Epoch: 27/30 | Batch: 270/452 (60.0%) | Loss: 0.0660 | Batch time: 0.18s
2025-03-04 00:16:10,780 - INFO - [TRAIN] Epoch: 27/30 | Batch: 315/452 (69.9%) | Loss: 0.0999 | Batch time: 0.18s
2025-03-04 00:16:18,939 - INFO - [TRAIN] Epoch: 27/30 | Batch: 360/452 (79.9%) | Loss: 0.5305 | Batch time: 0.18s
2025-03-04 00:16:27,095 - INFO - [TRAIN] Epoch: 27/30 | Batch: 405/452 (89.8%) | Loss: 0.0998 | Batch time: 0.18s
2025-03-04 00:16:35,076 - INFO - [TRAIN] Epoch: 27/30 | Batch: 450/452 (99.8%) | Loss: 0.1229 | Batch time: 0.17s
2025-03-04 00:16:35,162 - INFO - [TRAIN] Epoch: 27/30 | Batch: 451/452 (100.0%) | Loss: 0.7166 | Batch time: 0.08s
2025-03-04 00:16:35,284 - INFO - [VAL] Epoch: 27/30 | Batch: 0/97 (1.0%) | Loss: 0.0043 | Batch time: 0.05s
2025-03-04 00:16:35,696 - INFO - [VAL] Epoch: 27/30 | Batch: 9/97 (10.3%) | Loss: 0.0066 | Batch time: 0.05s
2025-03-04 00:16:36,135 - INFO - [VAL] Epoch: 27/30 | Batch: 18/97 (19.6%) | Loss: 0.0915 | Batch time: 0.05s
2025-03-04 00:16:36,593 - INFO - [VAL] Epoch: 27/30 | Batch: 27/97 (28.9%) | Loss: 0.0074 | Batch time: 0.05s
2025-03-04 00:16:37,056 - INFO - [VAL] Epoch: 27/30 | Batch: 36/97 (38.1%) | Loss: 0.0131 | Batch time: 0.05s
2025-03-04 00:16:37,517 - INFO - [VAL] Epoch: 27/30 | Batch: 45/97 (47.4%) | Loss: 0.0242 | Batch time: 0.05s
2025-03-04 00:16:37,973 - INFO - [VAL] Epoch: 27/30 | Batch: 54/97 (56.7%) | Loss: 0.0054 | Batch time: 0.05s
2025-03-04 00:16:38,422 - INFO - [VAL] Epoch: 27/30 | Batch: 63/97 (66.0%) | Loss: 0.0522 | Batch time: 0.05s
2025-03-04 00:16:38,868 - INFO - [VAL] Epoch: 27/30 | Batch: 72/97 (75.3%) | Loss: 0.0508 | Batch time: 0.05s
2025-03-04 00:16:39,310 - INFO - [VAL] Epoch: 27/30 | Batch: 81/97 (84.5%) | Loss: 0.0066 | Batch time: 0.05s
2025-03-04 00:16:39,746 - INFO - [VAL] Epoch: 27/30 | Batch: 90/97 (93.8%) | Loss: 0.0152 | Batch time: 0.05s
2025-03-04 00:16:40,039 - INFO - [VAL] Epoch: 27/30 | Batch: 96/97 (100.0%) | Loss: 0.0282 | Batch time: 0.05s
2025-03-04 00:16:40,043 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:16:40,043 - INFO - Epoch 27/30 completed in 86.84s
2025-03-04 00:16:40,043 - INFO - Training   - Loss: 0.2752, Accuracy: 0.9043, F1: 0.9047
2025-03-04 00:16:40,043 - INFO - Validation - Loss: 0.0580, Accuracy: 0.9758, F1: 0.9758
2025-03-04 00:16:40,043 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:16:40,043 - INFO - Epoch 28/30
2025-03-04 00:16:40,043 - INFO - ----------------------------------------
2025-03-04 00:16:40,441 - INFO - [TRAIN] Epoch: 28/30 | Batch: 0/452 (0.2%) | Loss: 0.3046 | Batch time: 0.20s
2025-03-04 00:16:48,612 - INFO - [TRAIN] Epoch: 28/30 | Batch: 45/452 (10.2%) | Loss: 0.1565 | Batch time: 0.18s
2025-03-04 00:16:56,657 - INFO - [TRAIN] Epoch: 28/30 | Batch: 90/452 (20.1%) | Loss: 0.3291 | Batch time: 0.19s
2025-03-04 00:17:05,381 - INFO - [TRAIN] Epoch: 28/30 | Batch: 135/452 (30.1%) | Loss: 0.2065 | Batch time: 0.22s
2025-03-04 00:17:13,749 - INFO - [TRAIN] Epoch: 28/30 | Batch: 180/452 (40.0%) | Loss: 0.4626 | Batch time: 0.18s
2025-03-04 00:17:21,788 - INFO - [TRAIN] Epoch: 28/30 | Batch: 225/452 (50.0%) | Loss: 0.4502 | Batch time: 0.18s
2025-03-04 00:17:30,045 - INFO - [TRAIN] Epoch: 28/30 | Batch: 270/452 (60.0%) | Loss: 0.2164 | Batch time: 0.18s
2025-03-04 00:17:38,077 - INFO - [TRAIN] Epoch: 28/30 | Batch: 315/452 (69.9%) | Loss: 0.2797 | Batch time: 0.18s
2025-03-04 00:17:46,218 - INFO - [TRAIN] Epoch: 28/30 | Batch: 360/452 (79.9%) | Loss: 0.4330 | Batch time: 0.19s
2025-03-04 00:17:54,313 - INFO - [TRAIN] Epoch: 28/30 | Batch: 405/452 (89.8%) | Loss: 0.3982 | Batch time: 0.18s
2025-03-04 00:18:02,407 - INFO - [TRAIN] Epoch: 28/30 | Batch: 450/452 (99.8%) | Loss: 0.1628 | Batch time: 0.17s
2025-03-04 00:18:02,495 - INFO - [TRAIN] Epoch: 28/30 | Batch: 451/452 (100.0%) | Loss: 0.2628 | Batch time: 0.09s
2025-03-04 00:18:02,636 - INFO - [VAL] Epoch: 28/30 | Batch: 0/97 (1.0%) | Loss: 0.0055 | Batch time: 0.05s
2025-03-04 00:18:03,063 - INFO - [VAL] Epoch: 28/30 | Batch: 9/97 (10.3%) | Loss: 0.0077 | Batch time: 0.05s
2025-03-04 00:18:03,523 - INFO - [VAL] Epoch: 28/30 | Batch: 18/97 (19.6%) | Loss: 0.0852 | Batch time: 0.06s
2025-03-04 00:18:03,997 - INFO - [VAL] Epoch: 28/30 | Batch: 27/97 (28.9%) | Loss: 0.0075 | Batch time: 0.05s
2025-03-04 00:18:04,467 - INFO - [VAL] Epoch: 28/30 | Batch: 36/97 (38.1%) | Loss: 0.0149 | Batch time: 0.05s
2025-03-04 00:18:04,928 - INFO - [VAL] Epoch: 28/30 | Batch: 45/97 (47.4%) | Loss: 0.0167 | Batch time: 0.05s
2025-03-04 00:18:05,378 - INFO - [VAL] Epoch: 28/30 | Batch: 54/97 (56.7%) | Loss: 0.0047 | Batch time: 0.05s
2025-03-04 00:18:05,822 - INFO - [VAL] Epoch: 28/30 | Batch: 63/97 (66.0%) | Loss: 0.0443 | Batch time: 0.05s
2025-03-04 00:18:06,265 - INFO - [VAL] Epoch: 28/30 | Batch: 72/97 (75.3%) | Loss: 0.0437 | Batch time: 0.05s
2025-03-04 00:18:06,700 - INFO - [VAL] Epoch: 28/30 | Batch: 81/97 (84.5%) | Loss: 0.0080 | Batch time: 0.05s
2025-03-04 00:18:07,134 - INFO - [VAL] Epoch: 28/30 | Batch: 90/97 (93.8%) | Loss: 0.0132 | Batch time: 0.05s
2025-03-04 00:18:07,421 - INFO - [VAL] Epoch: 28/30 | Batch: 96/97 (100.0%) | Loss: 0.0239 | Batch time: 0.05s
2025-03-04 00:18:07,424 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:18:07,424 - INFO - Epoch 28/30 completed in 87.38s
2025-03-04 00:18:07,425 - INFO - Training   - Loss: 0.2769, Accuracy: 0.9048, F1: 0.9053
2025-03-04 00:18:07,425 - INFO - Validation - Loss: 0.0602, Accuracy: 0.9758, F1: 0.9758
2025-03-04 00:18:07,425 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:18:07,425 - INFO - Epoch 29/30
2025-03-04 00:18:07,425 - INFO - ----------------------------------------
2025-03-04 00:18:07,805 - INFO - [TRAIN] Epoch: 29/30 | Batch: 0/452 (0.2%) | Loss: 0.1395 | Batch time: 0.19s
2025-03-04 00:18:16,025 - INFO - [TRAIN] Epoch: 29/30 | Batch: 45/452 (10.2%) | Loss: 0.2107 | Batch time: 0.18s
2025-03-04 00:18:24,182 - INFO - [TRAIN] Epoch: 29/30 | Batch: 90/452 (20.1%) | Loss: 0.2509 | Batch time: 0.18s
2025-03-04 00:18:32,242 - INFO - [TRAIN] Epoch: 29/30 | Batch: 135/452 (30.1%) | Loss: 0.5006 | Batch time: 0.18s
2025-03-04 00:18:40,314 - INFO - [TRAIN] Epoch: 29/30 | Batch: 180/452 (40.0%) | Loss: 0.2473 | Batch time: 0.18s
2025-03-04 00:18:48,308 - INFO - [TRAIN] Epoch: 29/30 | Batch: 225/452 (50.0%) | Loss: 0.2480 | Batch time: 0.18s
2025-03-04 00:18:56,256 - INFO - [TRAIN] Epoch: 29/30 | Batch: 270/452 (60.0%) | Loss: 0.2233 | Batch time: 0.18s
2025-03-04 00:19:04,166 - INFO - [TRAIN] Epoch: 29/30 | Batch: 315/452 (69.9%) | Loss: 0.2291 | Batch time: 0.17s
2025-03-04 00:19:12,081 - INFO - [TRAIN] Epoch: 29/30 | Batch: 360/452 (79.9%) | Loss: 0.1278 | Batch time: 0.18s
2025-03-04 00:19:20,028 - INFO - [TRAIN] Epoch: 29/30 | Batch: 405/452 (89.8%) | Loss: 0.2094 | Batch time: 0.18s
2025-03-04 00:19:27,920 - INFO - [TRAIN] Epoch: 29/30 | Batch: 450/452 (99.8%) | Loss: 0.1226 | Batch time: 0.18s
2025-03-04 00:19:28,010 - INFO - [TRAIN] Epoch: 29/30 | Batch: 451/452 (100.0%) | Loss: 0.5765 | Batch time: 0.09s
2025-03-04 00:19:28,136 - INFO - [VAL] Epoch: 29/30 | Batch: 0/97 (1.0%) | Loss: 0.0043 | Batch time: 0.06s
2025-03-04 00:19:28,558 - INFO - [VAL] Epoch: 29/30 | Batch: 9/97 (10.3%) | Loss: 0.0070 | Batch time: 0.05s
2025-03-04 00:19:29,005 - INFO - [VAL] Epoch: 29/30 | Batch: 18/97 (19.6%) | Loss: 0.0977 | Batch time: 0.05s
2025-03-04 00:19:29,464 - INFO - [VAL] Epoch: 29/30 | Batch: 27/97 (28.9%) | Loss: 0.0067 | Batch time: 0.05s
2025-03-04 00:19:29,921 - INFO - [VAL] Epoch: 29/30 | Batch: 36/97 (38.1%) | Loss: 0.0152 | Batch time: 0.05s
2025-03-04 00:19:30,380 - INFO - [VAL] Epoch: 29/30 | Batch: 45/97 (47.4%) | Loss: 0.0253 | Batch time: 0.05s
2025-03-04 00:19:30,854 - INFO - [VAL] Epoch: 29/30 | Batch: 54/97 (56.7%) | Loss: 0.0051 | Batch time: 0.05s
2025-03-04 00:19:31,321 - INFO - [VAL] Epoch: 29/30 | Batch: 63/97 (66.0%) | Loss: 0.0464 | Batch time: 0.05s
2025-03-04 00:19:31,783 - INFO - [VAL] Epoch: 29/30 | Batch: 72/97 (75.3%) | Loss: 0.0362 | Batch time: 0.05s
2025-03-04 00:19:32,239 - INFO - [VAL] Epoch: 29/30 | Batch: 81/97 (84.5%) | Loss: 0.0081 | Batch time: 0.05s
2025-03-04 00:19:32,688 - INFO - [VAL] Epoch: 29/30 | Batch: 90/97 (93.8%) | Loss: 0.0142 | Batch time: 0.05s
2025-03-04 00:19:32,987 - INFO - [VAL] Epoch: 29/30 | Batch: 96/97 (100.0%) | Loss: 0.0184 | Batch time: 0.05s
2025-03-04 00:19:33,829 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 29)
2025-03-04 00:19:33,829 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:19:33,829 - INFO - Epoch 29/30 completed in 86.40s
2025-03-04 00:19:33,829 - INFO - Training   - Loss: 0.2643, Accuracy: 0.9129, F1: 0.9130
2025-03-04 00:19:33,829 - INFO - Validation - Loss: 0.0575, Accuracy: 0.9771, F1: 0.9771
2025-03-04 00:19:33,829 - INFO - Validation F1 improved from 0.9764 to 0.9771
2025-03-04 00:19:33,829 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:19:33,829 - INFO - Epoch 30/30
2025-03-04 00:19:33,829 - INFO - ----------------------------------------
2025-03-04 00:19:34,299 - INFO - [TRAIN] Epoch: 30/30 | Batch: 0/452 (0.2%) | Loss: 0.1423 | Batch time: 0.21s
2025-03-04 00:19:42,175 - INFO - [TRAIN] Epoch: 30/30 | Batch: 45/452 (10.2%) | Loss: 0.1452 | Batch time: 0.18s
2025-03-04 00:19:50,268 - INFO - [TRAIN] Epoch: 30/30 | Batch: 90/452 (20.1%) | Loss: 0.0337 | Batch time: 0.18s
2025-03-04 00:19:58,163 - INFO - [TRAIN] Epoch: 30/30 | Batch: 135/452 (30.1%) | Loss: 0.1587 | Batch time: 0.18s
2025-03-04 00:20:06,062 - INFO - [TRAIN] Epoch: 30/30 | Batch: 180/452 (40.0%) | Loss: 0.2833 | Batch time: 0.18s
2025-03-04 00:20:14,032 - INFO - [TRAIN] Epoch: 30/30 | Batch: 225/452 (50.0%) | Loss: 0.5047 | Batch time: 0.18s
2025-03-04 00:20:21,925 - INFO - [TRAIN] Epoch: 30/30 | Batch: 270/452 (60.0%) | Loss: 0.2409 | Batch time: 0.17s
2025-03-04 00:20:29,946 - INFO - [TRAIN] Epoch: 30/30 | Batch: 315/452 (69.9%) | Loss: 0.3344 | Batch time: 0.17s
2025-03-04 00:20:37,826 - INFO - [TRAIN] Epoch: 30/30 | Batch: 360/452 (79.9%) | Loss: 0.2937 | Batch time: 0.18s
2025-03-04 00:20:45,886 - INFO - [TRAIN] Epoch: 30/30 | Batch: 405/452 (89.8%) | Loss: 0.1022 | Batch time: 0.18s
2025-03-04 00:20:53,794 - INFO - [TRAIN] Epoch: 30/30 | Batch: 450/452 (99.8%) | Loss: 0.3480 | Batch time: 0.17s
2025-03-04 00:20:53,880 - INFO - [TRAIN] Epoch: 30/30 | Batch: 451/452 (100.0%) | Loss: 0.2758 | Batch time: 0.09s
2025-03-04 00:20:53,990 - INFO - [VAL] Epoch: 30/30 | Batch: 0/97 (1.0%) | Loss: 0.0036 | Batch time: 0.05s
2025-03-04 00:20:54,408 - INFO - [VAL] Epoch: 30/30 | Batch: 9/97 (10.3%) | Loss: 0.0093 | Batch time: 0.05s
2025-03-04 00:20:54,844 - INFO - [VAL] Epoch: 30/30 | Batch: 18/97 (19.6%) | Loss: 0.0895 | Batch time: 0.05s
2025-03-04 00:20:55,303 - INFO - [VAL] Epoch: 30/30 | Batch: 27/97 (28.9%) | Loss: 0.0066 | Batch time: 0.05s
2025-03-04 00:20:55,757 - INFO - [VAL] Epoch: 30/30 | Batch: 36/97 (38.1%) | Loss: 0.0139 | Batch time: 0.05s
2025-03-04 00:20:56,211 - INFO - [VAL] Epoch: 30/30 | Batch: 45/97 (47.4%) | Loss: 0.0244 | Batch time: 0.05s
2025-03-04 00:20:56,662 - INFO - [VAL] Epoch: 30/30 | Batch: 54/97 (56.7%) | Loss: 0.0046 | Batch time: 0.05s
2025-03-04 00:20:57,110 - INFO - [VAL] Epoch: 30/30 | Batch: 63/97 (66.0%) | Loss: 0.0475 | Batch time: 0.05s
2025-03-04 00:20:57,562 - INFO - [VAL] Epoch: 30/30 | Batch: 72/97 (75.3%) | Loss: 0.0420 | Batch time: 0.05s
2025-03-04 00:20:58,002 - INFO - [VAL] Epoch: 30/30 | Batch: 81/97 (84.5%) | Loss: 0.0071 | Batch time: 0.05s
2025-03-04 00:20:58,437 - INFO - [VAL] Epoch: 30/30 | Batch: 90/97 (93.8%) | Loss: 0.0149 | Batch time: 0.05s
2025-03-04 00:20:58,722 - INFO - [VAL] Epoch: 30/30 | Batch: 96/97 (100.0%) | Loss: 0.0186 | Batch time: 0.05s
2025-03-04 00:20:58,726 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:20:58,726 - INFO - Epoch 30/30 completed in 84.90s
2025-03-04 00:20:58,726 - INFO - Training   - Loss: 0.2625, Accuracy: 0.9116, F1: 0.9119
2025-03-04 00:20:58,726 - INFO - Validation - Loss: 0.0624, Accuracy: 0.9742, F1: 0.9742
2025-03-04 00:20:58,726 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:20:59,238 - INFO - Checkpoint saved: checkpoint_epoch_30.pth (Epoch 30)
2025-03-04 00:20:59,238 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:20:59,238 - INFO - Training completed in 0h 43m 33.12s
2025-03-04 00:20:59,238 - INFO - Best validation F1: 0.9771 (Epoch 29)
2025-03-04 00:20:59,238 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:20:59,972 - INFO - Final model saved to models/resnet_attention_v1/models/resnet_attention_v1_final.pth
2025-03-04 00:21:00,069 - INFO - Model registered in models/model_registry.json
2025-03-04 00:21:00,069 - INFO - Generating visualizations...
2025-03-04 00:21:00,069 - INFO - Generating standard visualizations and GradCAM
2025-03-04 00:21:43,135 - INFO - t-SNE visualization saved to models/resnet_attention_v1/visualizations
2025-03-04 00:21:43,135 - INFO - Training and visualization finished!

2025-03-02 21:12:58,198 - INFO - Starting experiment: resnet_attention
2025-03-02 21:12:58,198 - INFO - Command line arguments: Namespace(data_dir='data/raw', output_dir='models/resnet_attention_v1', model='resnet_attention', img_size=224, batch_size=24, num_workers=16, epochs=30, lr=0.0005, weight_decay=1e-05, pretrained=True, freeze_backbone=False, no_cuda=False, no_mps=False, use_mps=True, use_amp=False, memory_efficient=True, cache_dataset=True, mps_graph=True, mps_fallback=True, pin_memory=True, optimize_for_m_series=True, patience=30, keep_top_k=3, version=None, find_lr=False, experiment_name='resnet_attention', resnet_version=50)
2025-03-02 21:12:58,198 - INFO - Processing dataset...
2025-03-02 21:12:58,281 - INFO - Class distribution:
2025-03-02 21:12:58,282 - INFO -   Tomato_healthy: 1591 images
2025-03-02 21:12:58,282 - INFO -   Potato___Early_blight: 1000 images
2025-03-02 21:12:58,282 - INFO -   Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Early_blight: 1000 images
2025-03-02 21:12:58,282 - INFO -   Tomato__Target_Spot: 1404 images
2025-03-02 21:12:58,282 - INFO -   Potato___Late_blight: 1000 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Leaf_Mold: 952 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Septoria_leaf_spot: 1771 images
2025-03-02 21:12:58,282 - INFO -   Tomato__Tomato_mosaic_virus: 373 images
2025-03-02 21:12:58,282 - INFO -   Pepper__bell___Bacterial_spot: 997 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Bacterial_spot: 2127 images
2025-03-02 21:12:58,282 - INFO -   Tomato_Late_blight: 1909 images
2025-03-02 21:12:58,282 - INFO -   Pepper__bell___healthy: 1478 images
2025-03-02 21:12:58,282 - INFO -   Potato___healthy: 152 images
2025-03-02 21:12:58,282 - INFO - Creating model: resnet_attention with 15 classes
2025-03-02 21:12:58,575 - INFO - Model architecture:
ResNetWithAttention(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (5): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (6): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (7): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (attention): ResidualAttention(
    (avg_pool): AdaptiveAvgPool2d(output_size=1)
    (fc): Sequential(
      (0): Linear(in_features=2048, out_features=128, bias=False)
      (1): ReLU(inplace=True)
      (2): Linear(in_features=128, out_features=2048, bias=False)
      (3): Sigmoid()
    )
  )
  (avg_pool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=2048, out_features=15, bias=True)
  )
)
2025-03-02 21:12:58,576 - INFO - Using class weights: [0.5015516  0.7979687  0.24874336 0.7979687  0.5683538  0.7979687
 0.8382024  0.47611496 0.4505752  2.1393263  0.8003698  0.3751616
 0.4180035  0.5398976  5.249794  ]
2025-03-02 21:12:58,576 - INFO - Training all parameters (full model)
2025-03-02 21:12:58,577 - INFO - Starting training for 30 epochs
2025-03-02 21:12:58,577 - INFO - Using Automatic Mixed Precision: False
2025-03-02 21:12:58,577 - INFO - Early stopping patience: 30
2025-03-02 21:12:58,577 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:12:58,577 - INFO - Starting training: resnet_attention
2025-03-02 21:12:58,577 - INFO - Total epochs: 30
2025-03-02 21:12:58,577 - INFO - Training batches per epoch: 602
2025-03-02 21:12:58,577 - INFO - Validation batches per epoch: 129
2025-03-02 21:12:58,577 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:12:58,577 - INFO - Training model: resnet_attention_v1
2025-03-02 21:12:58,577 - INFO - Epoch 1/30
2025-03-02 21:12:58,577 - INFO - ----------------------------------------
2025-03-02 21:13:26,887 - INFO - [TRAIN] Epoch: 1/30 | Batch: 0/602 (0.2%) | Loss: 2.6608 | Batch time: 0.82s
2025-03-02 21:13:34,320 - INFO - [TRAIN] Epoch: 1/30 | Batch: 60/602 (10.1%) | Loss: 1.8515 | Batch time: 0.13s
2025-03-02 21:13:41,728 - INFO - [TRAIN] Epoch: 1/30 | Batch: 120/602 (20.1%) | Loss: 1.3165 | Batch time: 0.12s
2025-03-02 21:13:49,050 - INFO - [TRAIN] Epoch: 1/30 | Batch: 180/602 (30.1%) | Loss: 1.3255 | Batch time: 0.12s
2025-03-02 21:13:56,328 - INFO - [TRAIN] Epoch: 1/30 | Batch: 240/602 (40.0%) | Loss: 1.0612 | Batch time: 0.12s
2025-03-02 21:14:03,585 - INFO - [TRAIN] Epoch: 1/30 | Batch: 300/602 (50.0%) | Loss: 1.4891 | Batch time: 0.12s
2025-03-02 21:14:10,831 - INFO - [TRAIN] Epoch: 1/30 | Batch: 360/602 (60.0%) | Loss: 1.2961 | Batch time: 0.12s
2025-03-02 21:14:18,099 - INFO - [TRAIN] Epoch: 1/30 | Batch: 420/602 (69.9%) | Loss: 0.7694 | Batch time: 0.12s
2025-03-02 21:14:25,352 - INFO - [TRAIN] Epoch: 1/30 | Batch: 480/602 (79.9%) | Loss: 0.7883 | Batch time: 0.12s
2025-03-02 21:14:32,623 - INFO - [TRAIN] Epoch: 1/30 | Batch: 540/602 (89.9%) | Loss: 0.6582 | Batch time: 0.12s
2025-03-02 21:14:39,936 - INFO - [TRAIN] Epoch: 1/30 | Batch: 600/602 (99.8%) | Loss: 0.6350 | Batch time: 0.12s
2025-03-02 21:14:40,281 - INFO - [TRAIN] Epoch: 1/30 | Batch: 601/602 (100.0%) | Loss: 1.2768 | Batch time: 0.34s
2025-03-02 21:15:08,120 - INFO - [VAL] Epoch: 1/30 | Batch: 0/129 (0.8%) | Loss: 1.5611 | Batch time: 0.29s
2025-03-02 21:15:08,493 - INFO - [VAL] Epoch: 1/30 | Batch: 12/129 (10.1%) | Loss: 0.9712 | Batch time: 0.03s
2025-03-02 21:15:08,866 - INFO - [VAL] Epoch: 1/30 | Batch: 24/129 (19.4%) | Loss: 1.2115 | Batch time: 0.03s
2025-03-02 21:15:09,238 - INFO - [VAL] Epoch: 1/30 | Batch: 36/129 (28.7%) | Loss: 1.2306 | Batch time: 0.03s
2025-03-02 21:15:09,613 - INFO - [VAL] Epoch: 1/30 | Batch: 48/129 (38.0%) | Loss: 0.7458 | Batch time: 0.03s
2025-03-02 21:15:09,997 - INFO - [VAL] Epoch: 1/30 | Batch: 60/129 (47.3%) | Loss: 2.2011 | Batch time: 0.03s
2025-03-02 21:15:10,388 - INFO - [VAL] Epoch: 1/30 | Batch: 72/129 (56.6%) | Loss: 1.3236 | Batch time: 0.03s
2025-03-02 21:15:10,781 - INFO - [VAL] Epoch: 1/30 | Batch: 84/129 (65.9%) | Loss: 1.3090 | Batch time: 0.03s
2025-03-02 21:15:11,173 - INFO - [VAL] Epoch: 1/30 | Batch: 96/129 (75.2%) | Loss: 1.3570 | Batch time: 0.03s
2025-03-02 21:15:11,564 - INFO - [VAL] Epoch: 1/30 | Batch: 108/129 (84.5%) | Loss: 1.5213 | Batch time: 0.03s
2025-03-02 21:15:11,951 - INFO - [VAL] Epoch: 1/30 | Batch: 120/129 (93.8%) | Loss: 0.9276 | Batch time: 0.03s
2025-03-02 21:15:12,208 - INFO - [VAL] Epoch: 1/30 | Batch: 128/129 (100.0%) | Loss: 1.0691 | Batch time: 0.03s
2025-03-02 21:15:13,124 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 1)
2025-03-02 21:15:13,125 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:15:13,125 - INFO - Epoch 1/30 completed in 134.55s
2025-03-02 21:15:13,125 - INFO - Training   - Loss: 1.2862, Accuracy: 0.5914, F1: 0.5980
2025-03-02 21:15:13,125 - INFO - Validation - Loss: 1.2676, Accuracy: 0.6818, F1: 0.6878
2025-03-02 21:15:13,125 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:15:13,125 - INFO - Epoch 2/30
2025-03-02 21:15:13,125 - INFO - ----------------------------------------
2025-03-02 21:15:13,472 - INFO - [TRAIN] Epoch: 2/30 | Batch: 0/602 (0.2%) | Loss: 1.2071 | Batch time: 0.17s
2025-03-02 21:15:20,541 - INFO - [TRAIN] Epoch: 2/30 | Batch: 60/602 (10.1%) | Loss: 0.8865 | Batch time: 0.12s
2025-03-02 21:15:28,137 - INFO - [TRAIN] Epoch: 2/30 | Batch: 120/602 (20.1%) | Loss: 0.6087 | Batch time: 0.13s
2025-03-02 21:15:35,865 - INFO - [TRAIN] Epoch: 2/30 | Batch: 180/602 (30.1%) | Loss: 0.8680 | Batch time: 0.13s
2025-03-02 21:15:43,444 - INFO - [TRAIN] Epoch: 2/30 | Batch: 240/602 (40.0%) | Loss: 0.7793 | Batch time: 0.13s
2025-03-02 21:15:51,030 - INFO - [TRAIN] Epoch: 2/30 | Batch: 300/602 (50.0%) | Loss: 0.5909 | Batch time: 0.13s
2025-03-02 21:15:58,789 - INFO - [TRAIN] Epoch: 2/30 | Batch: 360/602 (60.0%) | Loss: 0.7079 | Batch time: 0.12s
2025-03-02 21:16:06,178 - INFO - [TRAIN] Epoch: 2/30 | Batch: 420/602 (69.9%) | Loss: 0.8014 | Batch time: 0.12s
2025-03-02 21:16:13,646 - INFO - [TRAIN] Epoch: 2/30 | Batch: 480/602 (79.9%) | Loss: 1.5151 | Batch time: 0.12s
2025-03-02 21:16:20,979 - INFO - [TRAIN] Epoch: 2/30 | Batch: 540/602 (89.9%) | Loss: 1.0864 | Batch time: 0.12s
2025-03-02 21:16:28,274 - INFO - [TRAIN] Epoch: 2/30 | Batch: 600/602 (99.8%) | Loss: 0.7982 | Batch time: 0.12s
2025-03-02 21:16:28,386 - INFO - [TRAIN] Epoch: 2/30 | Batch: 601/602 (100.0%) | Loss: 0.4707 | Batch time: 0.11s
2025-03-02 21:16:28,469 - INFO - [VAL] Epoch: 2/30 | Batch: 0/129 (0.8%) | Loss: 0.1833 | Batch time: 0.03s
2025-03-02 21:16:28,847 - INFO - [VAL] Epoch: 2/30 | Batch: 12/129 (10.1%) | Loss: 0.1756 | Batch time: 0.03s
2025-03-02 21:16:29,230 - INFO - [VAL] Epoch: 2/30 | Batch: 24/129 (19.4%) | Loss: 0.4885 | Batch time: 0.03s
2025-03-02 21:16:29,619 - INFO - [VAL] Epoch: 2/30 | Batch: 36/129 (28.7%) | Loss: 0.3892 | Batch time: 0.03s
2025-03-02 21:16:30,014 - INFO - [VAL] Epoch: 2/30 | Batch: 48/129 (38.0%) | Loss: 0.2042 | Batch time: 0.03s
2025-03-02 21:16:30,408 - INFO - [VAL] Epoch: 2/30 | Batch: 60/129 (47.3%) | Loss: 0.3735 | Batch time: 0.03s
2025-03-02 21:16:30,803 - INFO - [VAL] Epoch: 2/30 | Batch: 72/129 (56.6%) | Loss: 0.1630 | Batch time: 0.03s
2025-03-02 21:16:31,199 - INFO - [VAL] Epoch: 2/30 | Batch: 84/129 (65.9%) | Loss: 0.0447 | Batch time: 0.03s
2025-03-02 21:16:31,593 - INFO - [VAL] Epoch: 2/30 | Batch: 96/129 (75.2%) | Loss: 0.3026 | Batch time: 0.03s
2025-03-02 21:16:31,988 - INFO - [VAL] Epoch: 2/30 | Batch: 108/129 (84.5%) | Loss: 0.1250 | Batch time: 0.03s
2025-03-02 21:16:32,379 - INFO - [VAL] Epoch: 2/30 | Batch: 120/129 (93.8%) | Loss: 0.2904 | Batch time: 0.03s
2025-03-02 21:16:32,637 - INFO - [VAL] Epoch: 2/30 | Batch: 128/129 (100.0%) | Loss: 0.2168 | Batch time: 0.03s
2025-03-02 21:16:33,266 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 2)
2025-03-02 21:16:33,266 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:16:33,266 - INFO - Epoch 2/30 completed in 80.14s
2025-03-02 21:16:33,266 - INFO - Training   - Loss: 0.8202, Accuracy: 0.7333, F1: 0.7364
2025-03-02 21:16:33,266 - INFO - Validation - Loss: 0.2787, Accuracy: 0.8966, F1: 0.8970
2025-03-02 21:16:33,266 - INFO - Validation F1 improved from 0.6878 to 0.8970
2025-03-02 21:16:33,266 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:16:33,266 - INFO - Epoch 3/30
2025-03-02 21:16:33,266 - INFO - ----------------------------------------
2025-03-02 21:16:33,562 - INFO - [TRAIN] Epoch: 3/30 | Batch: 0/602 (0.2%) | Loss: 0.4765 | Batch time: 0.15s
2025-03-02 21:16:40,778 - INFO - [TRAIN] Epoch: 3/30 | Batch: 60/602 (10.1%) | Loss: 0.4451 | Batch time: 0.12s
2025-03-02 21:16:48,149 - INFO - [TRAIN] Epoch: 3/30 | Batch: 120/602 (20.1%) | Loss: 1.2833 | Batch time: 0.12s
2025-03-02 21:16:55,586 - INFO - [TRAIN] Epoch: 3/30 | Batch: 180/602 (30.1%) | Loss: 0.4898 | Batch time: 0.12s
2025-03-02 21:17:03,081 - INFO - [TRAIN] Epoch: 3/30 | Batch: 240/602 (40.0%) | Loss: 0.7623 | Batch time: 0.13s
2025-03-02 21:17:10,637 - INFO - [TRAIN] Epoch: 3/30 | Batch: 300/602 (50.0%) | Loss: 0.3101 | Batch time: 0.13s
2025-03-02 21:17:18,293 - INFO - [TRAIN] Epoch: 3/30 | Batch: 360/602 (60.0%) | Loss: 0.7086 | Batch time: 0.13s
2025-03-02 21:17:25,943 - INFO - [TRAIN] Epoch: 3/30 | Batch: 420/602 (69.9%) | Loss: 0.7875 | Batch time: 0.13s
2025-03-02 21:17:33,661 - INFO - [TRAIN] Epoch: 3/30 | Batch: 480/602 (79.9%) | Loss: 0.4590 | Batch time: 0.13s
2025-03-02 21:17:41,394 - INFO - [TRAIN] Epoch: 3/30 | Batch: 540/602 (89.9%) | Loss: 0.3809 | Batch time: 0.13s
2025-03-02 21:17:49,151 - INFO - [TRAIN] Epoch: 3/30 | Batch: 600/602 (99.8%) | Loss: 0.9317 | Batch time: 0.13s
2025-03-02 21:17:49,270 - INFO - [TRAIN] Epoch: 3/30 | Batch: 601/602 (100.0%) | Loss: 0.3243 | Batch time: 0.12s
2025-03-02 21:17:49,354 - INFO - [VAL] Epoch: 3/30 | Batch: 0/129 (0.8%) | Loss: 0.1972 | Batch time: 0.03s
2025-03-02 21:17:49,751 - INFO - [VAL] Epoch: 3/30 | Batch: 12/129 (10.1%) | Loss: 0.0975 | Batch time: 0.03s
2025-03-02 21:17:50,162 - INFO - [VAL] Epoch: 3/30 | Batch: 24/129 (19.4%) | Loss: 0.2133 | Batch time: 0.03s
2025-03-02 21:17:50,582 - INFO - [VAL] Epoch: 3/30 | Batch: 36/129 (28.7%) | Loss: 0.3915 | Batch time: 0.03s
2025-03-02 21:17:51,007 - INFO - [VAL] Epoch: 3/30 | Batch: 48/129 (38.0%) | Loss: 0.1297 | Batch time: 0.04s
2025-03-02 21:17:51,436 - INFO - [VAL] Epoch: 3/30 | Batch: 60/129 (47.3%) | Loss: 0.4058 | Batch time: 0.04s
2025-03-02 21:17:51,864 - INFO - [VAL] Epoch: 3/30 | Batch: 72/129 (56.6%) | Loss: 0.2504 | Batch time: 0.04s
2025-03-02 21:17:52,291 - INFO - [VAL] Epoch: 3/30 | Batch: 84/129 (65.9%) | Loss: 0.1261 | Batch time: 0.04s
2025-03-02 21:17:52,717 - INFO - [VAL] Epoch: 3/30 | Batch: 96/129 (75.2%) | Loss: 0.4721 | Batch time: 0.04s
2025-03-02 21:17:53,145 - INFO - [VAL] Epoch: 3/30 | Batch: 108/129 (84.5%) | Loss: 0.1221 | Batch time: 0.04s
2025-03-02 21:17:53,566 - INFO - [VAL] Epoch: 3/30 | Batch: 120/129 (93.8%) | Loss: 0.1001 | Batch time: 0.03s
2025-03-02 21:17:53,845 - INFO - [VAL] Epoch: 3/30 | Batch: 128/129 (100.0%) | Loss: 0.5414 | Batch time: 0.03s
2025-03-02 21:17:53,848 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:17:53,848 - INFO - Epoch 3/30 completed in 80.58s
2025-03-02 21:17:53,848 - INFO - Training   - Loss: 0.6767, Accuracy: 0.7777, F1: 0.7799
2025-03-02 21:17:53,848 - INFO - Validation - Loss: 0.3154, Accuracy: 0.8924, F1: 0.8956
2025-03-02 21:17:53,848 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:17:53,848 - INFO - Epoch 4/30
2025-03-02 21:17:53,848 - INFO - ----------------------------------------
2025-03-02 21:17:54,138 - INFO - [TRAIN] Epoch: 4/30 | Batch: 0/602 (0.2%) | Loss: 0.6876 | Batch time: 0.15s
2025-03-02 21:18:01,928 - INFO - [TRAIN] Epoch: 4/30 | Batch: 60/602 (10.1%) | Loss: 0.2920 | Batch time: 0.13s
2025-03-02 21:18:09,836 - INFO - [TRAIN] Epoch: 4/30 | Batch: 120/602 (20.1%) | Loss: 0.6506 | Batch time: 0.13s
2025-03-02 21:18:17,854 - INFO - [TRAIN] Epoch: 4/30 | Batch: 180/602 (30.1%) | Loss: 0.6089 | Batch time: 0.13s
2025-03-02 21:18:25,918 - INFO - [TRAIN] Epoch: 4/30 | Batch: 240/602 (40.0%) | Loss: 0.6723 | Batch time: 0.13s
2025-03-02 21:18:34,040 - INFO - [TRAIN] Epoch: 4/30 | Batch: 300/602 (50.0%) | Loss: 0.8221 | Batch time: 0.13s
2025-03-02 21:18:42,079 - INFO - [TRAIN] Epoch: 4/30 | Batch: 360/602 (60.0%) | Loss: 0.6747 | Batch time: 0.13s
2025-03-02 21:18:50,118 - INFO - [TRAIN] Epoch: 4/30 | Batch: 420/602 (69.9%) | Loss: 1.4836 | Batch time: 0.13s
2025-03-02 21:18:58,168 - INFO - [TRAIN] Epoch: 4/30 | Batch: 480/602 (79.9%) | Loss: 0.5554 | Batch time: 0.13s
2025-03-02 21:19:06,224 - INFO - [TRAIN] Epoch: 4/30 | Batch: 540/602 (89.9%) | Loss: 0.5961 | Batch time: 0.13s
2025-03-02 21:19:14,215 - INFO - [TRAIN] Epoch: 4/30 | Batch: 600/602 (99.8%) | Loss: 0.7968 | Batch time: 0.13s
2025-03-02 21:19:14,334 - INFO - [TRAIN] Epoch: 4/30 | Batch: 601/602 (100.0%) | Loss: 0.5266 | Batch time: 0.12s
2025-03-02 21:19:14,427 - INFO - [VAL] Epoch: 4/30 | Batch: 0/129 (0.8%) | Loss: 0.1343 | Batch time: 0.04s
2025-03-02 21:19:14,839 - INFO - [VAL] Epoch: 4/30 | Batch: 12/129 (10.1%) | Loss: 0.1097 | Batch time: 0.03s
2025-03-02 21:19:15,269 - INFO - [VAL] Epoch: 4/30 | Batch: 24/129 (19.4%) | Loss: 0.1659 | Batch time: 0.04s
2025-03-02 21:19:15,710 - INFO - [VAL] Epoch: 4/30 | Batch: 36/129 (28.7%) | Loss: 0.0862 | Batch time: 0.04s
2025-03-02 21:19:16,156 - INFO - [VAL] Epoch: 4/30 | Batch: 48/129 (38.0%) | Loss: 0.1280 | Batch time: 0.04s
2025-03-02 21:19:16,602 - INFO - [VAL] Epoch: 4/30 | Batch: 60/129 (47.3%) | Loss: 0.1511 | Batch time: 0.04s
2025-03-02 21:19:17,047 - INFO - [VAL] Epoch: 4/30 | Batch: 72/129 (56.6%) | Loss: 0.1180 | Batch time: 0.04s
2025-03-02 21:19:17,491 - INFO - [VAL] Epoch: 4/30 | Batch: 84/129 (65.9%) | Loss: 0.1158 | Batch time: 0.04s
2025-03-02 21:19:17,932 - INFO - [VAL] Epoch: 4/30 | Batch: 96/129 (75.2%) | Loss: 0.3988 | Batch time: 0.04s
2025-03-02 21:19:18,374 - INFO - [VAL] Epoch: 4/30 | Batch: 108/129 (84.5%) | Loss: 0.1070 | Batch time: 0.04s
2025-03-02 21:19:18,809 - INFO - [VAL] Epoch: 4/30 | Batch: 120/129 (93.8%) | Loss: 0.0733 | Batch time: 0.04s
2025-03-02 21:19:19,095 - INFO - [VAL] Epoch: 4/30 | Batch: 128/129 (100.0%) | Loss: 0.2131 | Batch time: 0.04s
2025-03-02 21:19:19,711 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 4)
2025-03-02 21:19:19,711 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:19:19,711 - INFO - Epoch 4/30 completed in 85.86s
2025-03-02 21:19:19,711 - INFO - Training   - Loss: 0.6429, Accuracy: 0.7894, F1: 0.7910
2025-03-02 21:19:19,711 - INFO - Validation - Loss: 0.2569, Accuracy: 0.9083, F1: 0.9105
2025-03-02 21:19:19,711 - INFO - Validation F1 improved from 0.8970 to 0.9105
2025-03-02 21:19:19,711 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:19:19,711 - INFO - Epoch 5/30
2025-03-02 21:19:19,711 - INFO - ----------------------------------------
2025-03-02 21:19:20,013 - INFO - [TRAIN] Epoch: 5/30 | Batch: 0/602 (0.2%) | Loss: 0.6953 | Batch time: 0.15s
2025-03-02 21:19:27,936 - INFO - [TRAIN] Epoch: 5/30 | Batch: 60/602 (10.1%) | Loss: 0.5843 | Batch time: 0.13s
2025-03-02 21:19:35,974 - INFO - [TRAIN] Epoch: 5/30 | Batch: 120/602 (20.1%) | Loss: 0.2143 | Batch time: 0.13s
2025-03-02 21:19:44,003 - INFO - [TRAIN] Epoch: 5/30 | Batch: 180/602 (30.1%) | Loss: 0.4762 | Batch time: 0.13s
2025-03-02 21:19:52,020 - INFO - [TRAIN] Epoch: 5/30 | Batch: 240/602 (40.0%) | Loss: 0.7030 | Batch time: 0.13s
2025-03-02 21:20:00,020 - INFO - [TRAIN] Epoch: 5/30 | Batch: 300/602 (50.0%) | Loss: 0.4025 | Batch time: 0.13s
2025-03-02 21:20:08,013 - INFO - [TRAIN] Epoch: 5/30 | Batch: 360/602 (60.0%) | Loss: 0.3656 | Batch time: 0.13s
2025-03-02 21:20:16,033 - INFO - [TRAIN] Epoch: 5/30 | Batch: 420/602 (69.9%) | Loss: 0.5152 | Batch time: 0.13s
2025-03-02 21:20:24,005 - INFO - [TRAIN] Epoch: 5/30 | Batch: 480/602 (79.9%) | Loss: 0.5889 | Batch time: 0.13s
2025-03-02 21:20:31,971 - INFO - [TRAIN] Epoch: 5/30 | Batch: 540/602 (89.9%) | Loss: 0.4311 | Batch time: 0.13s
2025-03-02 21:20:39,914 - INFO - [TRAIN] Epoch: 5/30 | Batch: 600/602 (99.8%) | Loss: 0.3984 | Batch time: 0.13s
2025-03-02 21:20:40,034 - INFO - [TRAIN] Epoch: 5/30 | Batch: 601/602 (100.0%) | Loss: 0.8889 | Batch time: 0.12s
2025-03-02 21:20:40,120 - INFO - [VAL] Epoch: 5/30 | Batch: 0/129 (0.8%) | Loss: 0.2320 | Batch time: 0.04s
2025-03-02 21:20:40,526 - INFO - [VAL] Epoch: 5/30 | Batch: 12/129 (10.1%) | Loss: 0.2575 | Batch time: 0.03s
2025-03-02 21:20:40,945 - INFO - [VAL] Epoch: 5/30 | Batch: 24/129 (19.4%) | Loss: 0.3067 | Batch time: 0.04s
2025-03-02 21:20:41,374 - INFO - [VAL] Epoch: 5/30 | Batch: 36/129 (28.7%) | Loss: 0.2488 | Batch time: 0.04s
2025-03-02 21:20:41,809 - INFO - [VAL] Epoch: 5/30 | Batch: 48/129 (38.0%) | Loss: 0.1392 | Batch time: 0.04s
2025-03-02 21:20:42,246 - INFO - [VAL] Epoch: 5/30 | Batch: 60/129 (47.3%) | Loss: 0.2167 | Batch time: 0.04s
2025-03-02 21:20:42,681 - INFO - [VAL] Epoch: 5/30 | Batch: 72/129 (56.6%) | Loss: 0.1940 | Batch time: 0.04s
2025-03-02 21:20:43,120 - INFO - [VAL] Epoch: 5/30 | Batch: 84/129 (65.9%) | Loss: 0.1729 | Batch time: 0.04s
2025-03-02 21:20:43,559 - INFO - [VAL] Epoch: 5/30 | Batch: 96/129 (75.2%) | Loss: 0.4176 | Batch time: 0.04s
2025-03-02 21:20:43,998 - INFO - [VAL] Epoch: 5/30 | Batch: 108/129 (84.5%) | Loss: 0.0323 | Batch time: 0.04s
2025-03-02 21:20:44,429 - INFO - [VAL] Epoch: 5/30 | Batch: 120/129 (93.8%) | Loss: 0.0833 | Batch time: 0.04s
2025-03-02 21:20:44,714 - INFO - [VAL] Epoch: 5/30 | Batch: 128/129 (100.0%) | Loss: 0.3291 | Batch time: 0.03s
2025-03-02 21:20:44,718 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:20:44,718 - INFO - Epoch 5/30 completed in 85.01s
2025-03-02 21:20:44,718 - INFO - Training   - Loss: 0.5764, Accuracy: 0.8110, F1: 0.8125
2025-03-02 21:20:44,718 - INFO - Validation - Loss: 0.2709, Accuracy: 0.8989, F1: 0.9041
2025-03-02 21:20:44,718 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:20:45,161 - INFO - Checkpoint saved: checkpoint_epoch_5.pth (Epoch 5)
2025-03-02 21:20:45,161 - INFO - Epoch 6/30
2025-03-02 21:20:45,161 - INFO - ----------------------------------------
2025-03-02 21:20:45,453 - INFO - [TRAIN] Epoch: 6/30 | Batch: 0/602 (0.2%) | Loss: 0.6682 | Batch time: 0.15s
2025-03-02 21:20:53,393 - INFO - [TRAIN] Epoch: 6/30 | Batch: 60/602 (10.1%) | Loss: 0.6836 | Batch time: 0.14s
2025-03-02 21:21:01,347 - INFO - [TRAIN] Epoch: 6/30 | Batch: 120/602 (20.1%) | Loss: 0.3195 | Batch time: 0.13s
2025-03-02 21:21:09,274 - INFO - [TRAIN] Epoch: 6/30 | Batch: 180/602 (30.1%) | Loss: 0.7646 | Batch time: 0.13s
2025-03-02 21:21:17,226 - INFO - [TRAIN] Epoch: 6/30 | Batch: 240/602 (40.0%) | Loss: 0.5824 | Batch time: 0.13s
2025-03-02 21:21:25,142 - INFO - [TRAIN] Epoch: 6/30 | Batch: 300/602 (50.0%) | Loss: 0.3622 | Batch time: 0.13s
2025-03-02 21:21:33,076 - INFO - [TRAIN] Epoch: 6/30 | Batch: 360/602 (60.0%) | Loss: 0.7179 | Batch time: 0.13s
2025-03-02 21:21:41,001 - INFO - [TRAIN] Epoch: 6/30 | Batch: 420/602 (69.9%) | Loss: 0.6242 | Batch time: 0.13s
2025-03-02 21:21:48,918 - INFO - [TRAIN] Epoch: 6/30 | Batch: 480/602 (79.9%) | Loss: 0.4015 | Batch time: 0.13s
2025-03-02 21:21:56,831 - INFO - [TRAIN] Epoch: 6/30 | Batch: 540/602 (89.9%) | Loss: 0.3932 | Batch time: 0.13s
2025-03-02 21:22:04,709 - INFO - [TRAIN] Epoch: 6/30 | Batch: 600/602 (99.8%) | Loss: 0.5050 | Batch time: 0.13s
2025-03-02 21:22:04,829 - INFO - [TRAIN] Epoch: 6/30 | Batch: 601/602 (100.0%) | Loss: 0.3466 | Batch time: 0.12s
2025-03-02 21:22:04,917 - INFO - [VAL] Epoch: 6/30 | Batch: 0/129 (0.8%) | Loss: 0.0604 | Batch time: 0.04s
2025-03-02 21:22:05,318 - INFO - [VAL] Epoch: 6/30 | Batch: 12/129 (10.1%) | Loss: 0.3685 | Batch time: 0.03s
2025-03-02 21:22:05,735 - INFO - [VAL] Epoch: 6/30 | Batch: 24/129 (19.4%) | Loss: 0.2189 | Batch time: 0.03s
2025-03-02 21:22:06,162 - INFO - [VAL] Epoch: 6/30 | Batch: 36/129 (28.7%) | Loss: 0.4593 | Batch time: 0.04s
2025-03-02 21:22:06,595 - INFO - [VAL] Epoch: 6/30 | Batch: 48/129 (38.0%) | Loss: 0.0793 | Batch time: 0.04s
2025-03-02 21:22:07,029 - INFO - [VAL] Epoch: 6/30 | Batch: 60/129 (47.3%) | Loss: 0.5054 | Batch time: 0.04s
2025-03-02 21:22:07,463 - INFO - [VAL] Epoch: 6/30 | Batch: 72/129 (56.6%) | Loss: 0.2481 | Batch time: 0.04s
2025-03-02 21:22:07,896 - INFO - [VAL] Epoch: 6/30 | Batch: 84/129 (65.9%) | Loss: 0.0424 | Batch time: 0.04s
2025-03-02 21:22:08,329 - INFO - [VAL] Epoch: 6/30 | Batch: 96/129 (75.2%) | Loss: 1.0628 | Batch time: 0.04s
2025-03-02 21:22:08,762 - INFO - [VAL] Epoch: 6/30 | Batch: 108/129 (84.5%) | Loss: 0.5333 | Batch time: 0.04s
2025-03-02 21:22:09,188 - INFO - [VAL] Epoch: 6/30 | Batch: 120/129 (93.8%) | Loss: 0.1259 | Batch time: 0.04s
2025-03-02 21:22:09,470 - INFO - [VAL] Epoch: 6/30 | Batch: 128/129 (100.0%) | Loss: 0.3547 | Batch time: 0.03s
2025-03-02 21:22:09,473 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:22:09,473 - INFO - Epoch 6/30 completed in 84.31s
2025-03-02 21:22:09,473 - INFO - Training   - Loss: 0.5267, Accuracy: 0.8274, F1: 0.8286
2025-03-02 21:22:09,473 - INFO - Validation - Loss: 0.4303, Accuracy: 0.8705, F1: 0.8761
2025-03-02 21:22:09,473 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:22:09,473 - INFO - Epoch 7/30
2025-03-02 21:22:09,473 - INFO - ----------------------------------------
2025-03-02 21:22:09,763 - INFO - [TRAIN] Epoch: 7/30 | Batch: 0/602 (0.2%) | Loss: 0.6053 | Batch time: 0.15s
2025-03-02 21:22:17,665 - INFO - [TRAIN] Epoch: 7/30 | Batch: 60/602 (10.1%) | Loss: 0.6422 | Batch time: 0.13s
2025-03-02 21:22:25,576 - INFO - [TRAIN] Epoch: 7/30 | Batch: 120/602 (20.1%) | Loss: 0.5844 | Batch time: 0.13s
2025-03-02 21:22:33,497 - INFO - [TRAIN] Epoch: 7/30 | Batch: 180/602 (30.1%) | Loss: 0.4373 | Batch time: 0.13s
2025-03-02 21:22:41,417 - INFO - [TRAIN] Epoch: 7/30 | Batch: 240/602 (40.0%) | Loss: 0.7454 | Batch time: 0.13s
2025-03-02 21:22:49,340 - INFO - [TRAIN] Epoch: 7/30 | Batch: 300/602 (50.0%) | Loss: 0.7029 | Batch time: 0.13s
2025-03-02 21:22:57,268 - INFO - [TRAIN] Epoch: 7/30 | Batch: 360/602 (60.0%) | Loss: 0.3628 | Batch time: 0.13s
2025-03-02 21:23:05,205 - INFO - [TRAIN] Epoch: 7/30 | Batch: 420/602 (69.9%) | Loss: 0.3409 | Batch time: 0.13s
2025-03-02 21:23:13,145 - INFO - [TRAIN] Epoch: 7/30 | Batch: 480/602 (79.9%) | Loss: 0.6493 | Batch time: 0.13s
2025-03-02 21:23:21,068 - INFO - [TRAIN] Epoch: 7/30 | Batch: 540/602 (89.9%) | Loss: 0.2647 | Batch time: 0.13s
2025-03-02 21:23:28,951 - INFO - [TRAIN] Epoch: 7/30 | Batch: 600/602 (99.8%) | Loss: 0.4821 | Batch time: 0.13s
2025-03-02 21:23:29,072 - INFO - [TRAIN] Epoch: 7/30 | Batch: 601/602 (100.0%) | Loss: 0.5236 | Batch time: 0.12s
2025-03-02 21:23:29,156 - INFO - [VAL] Epoch: 7/30 | Batch: 0/129 (0.8%) | Loss: 0.0567 | Batch time: 0.04s
2025-03-02 21:23:29,560 - INFO - [VAL] Epoch: 7/30 | Batch: 12/129 (10.1%) | Loss: 0.0986 | Batch time: 0.03s
2025-03-02 21:23:29,977 - INFO - [VAL] Epoch: 7/30 | Batch: 24/129 (19.4%) | Loss: 0.2395 | Batch time: 0.03s
2025-03-02 21:23:30,406 - INFO - [VAL] Epoch: 7/30 | Batch: 36/129 (28.7%) | Loss: 0.1337 | Batch time: 0.04s
2025-03-02 21:23:30,840 - INFO - [VAL] Epoch: 7/30 | Batch: 48/129 (38.0%) | Loss: 0.0476 | Batch time: 0.04s
2025-03-02 21:23:31,275 - INFO - [VAL] Epoch: 7/30 | Batch: 60/129 (47.3%) | Loss: 0.2804 | Batch time: 0.04s
2025-03-02 21:23:31,710 - INFO - [VAL] Epoch: 7/30 | Batch: 72/129 (56.6%) | Loss: 0.0599 | Batch time: 0.04s
2025-03-02 21:23:32,143 - INFO - [VAL] Epoch: 7/30 | Batch: 84/129 (65.9%) | Loss: 0.0637 | Batch time: 0.04s
2025-03-02 21:23:32,575 - INFO - [VAL] Epoch: 7/30 | Batch: 96/129 (75.2%) | Loss: 0.1391 | Batch time: 0.04s
2025-03-02 21:23:33,008 - INFO - [VAL] Epoch: 7/30 | Batch: 108/129 (84.5%) | Loss: 0.0795 | Batch time: 0.04s
2025-03-02 21:23:33,435 - INFO - [VAL] Epoch: 7/30 | Batch: 120/129 (93.8%) | Loss: 0.0848 | Batch time: 0.04s
2025-03-02 21:23:33,721 - INFO - [VAL] Epoch: 7/30 | Batch: 128/129 (100.0%) | Loss: 0.0596 | Batch time: 0.04s
2025-03-02 21:23:34,363 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 7)
2025-03-02 21:23:34,363 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:23:34,363 - INFO - Epoch 7/30 completed in 84.89s
2025-03-02 21:23:34,363 - INFO - Training   - Loss: 0.4801, Accuracy: 0.8425, F1: 0.8435
2025-03-02 21:23:34,363 - INFO - Validation - Loss: 0.1437, Accuracy: 0.9448, F1: 0.9446
2025-03-02 21:23:34,363 - INFO - Validation F1 improved from 0.9105 to 0.9446
2025-03-02 21:23:34,363 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:23:34,363 - INFO - Epoch 8/30
2025-03-02 21:23:34,363 - INFO - ----------------------------------------
2025-03-02 21:23:34,654 - INFO - [TRAIN] Epoch: 8/30 | Batch: 0/602 (0.2%) | Loss: 0.3494 | Batch time: 0.14s
2025-03-02 21:23:42,441 - INFO - [TRAIN] Epoch: 8/30 | Batch: 60/602 (10.1%) | Loss: 0.2631 | Batch time: 0.13s
2025-03-02 21:23:50,372 - INFO - [TRAIN] Epoch: 8/30 | Batch: 120/602 (20.1%) | Loss: 0.2649 | Batch time: 0.13s
2025-03-02 21:23:58,344 - INFO - [TRAIN] Epoch: 8/30 | Batch: 180/602 (30.1%) | Loss: 0.3425 | Batch time: 0.13s
2025-03-02 21:24:06,285 - INFO - [TRAIN] Epoch: 8/30 | Batch: 240/602 (40.0%) | Loss: 0.4479 | Batch time: 0.13s
2025-03-02 21:24:14,217 - INFO - [TRAIN] Epoch: 8/30 | Batch: 300/602 (50.0%) | Loss: 0.1411 | Batch time: 0.13s
2025-03-02 21:24:22,308 - INFO - [TRAIN] Epoch: 8/30 | Batch: 360/602 (60.0%) | Loss: 0.4734 | Batch time: 0.13s
2025-03-02 21:24:30,409 - INFO - [TRAIN] Epoch: 8/30 | Batch: 420/602 (69.9%) | Loss: 0.1555 | Batch time: 0.13s
2025-03-02 21:24:38,456 - INFO - [TRAIN] Epoch: 8/30 | Batch: 480/602 (79.9%) | Loss: 0.1728 | Batch time: 0.14s
2025-03-02 21:24:46,488 - INFO - [TRAIN] Epoch: 8/30 | Batch: 540/602 (89.9%) | Loss: 0.3839 | Batch time: 0.13s
2025-03-02 21:24:54,504 - INFO - [TRAIN] Epoch: 8/30 | Batch: 600/602 (99.8%) | Loss: 0.1833 | Batch time: 0.13s
2025-03-02 21:24:54,624 - INFO - [TRAIN] Epoch: 8/30 | Batch: 601/602 (100.0%) | Loss: 0.1169 | Batch time: 0.12s
2025-03-02 21:24:54,711 - INFO - [VAL] Epoch: 8/30 | Batch: 0/129 (0.8%) | Loss: 0.0058 | Batch time: 0.04s
2025-03-02 21:24:55,121 - INFO - [VAL] Epoch: 8/30 | Batch: 12/129 (10.1%) | Loss: 0.0149 | Batch time: 0.03s
2025-03-02 21:24:55,549 - INFO - [VAL] Epoch: 8/30 | Batch: 24/129 (19.4%) | Loss: 0.0358 | Batch time: 0.04s
2025-03-02 21:24:55,983 - INFO - [VAL] Epoch: 8/30 | Batch: 36/129 (28.7%) | Loss: 0.0423 | Batch time: 0.04s
2025-03-02 21:24:56,424 - INFO - [VAL] Epoch: 8/30 | Batch: 48/129 (38.0%) | Loss: 0.0082 | Batch time: 0.04s
2025-03-02 21:24:56,862 - INFO - [VAL] Epoch: 8/30 | Batch: 60/129 (47.3%) | Loss: 0.0691 | Batch time: 0.04s
2025-03-02 21:24:57,305 - INFO - [VAL] Epoch: 8/30 | Batch: 72/129 (56.6%) | Loss: 0.0107 | Batch time: 0.04s
2025-03-02 21:24:57,746 - INFO - [VAL] Epoch: 8/30 | Batch: 84/129 (65.9%) | Loss: 0.0150 | Batch time: 0.04s
2025-03-02 21:24:58,181 - INFO - [VAL] Epoch: 8/30 | Batch: 96/129 (75.2%) | Loss: 0.1109 | Batch time: 0.04s
2025-03-02 21:24:58,629 - INFO - [VAL] Epoch: 8/30 | Batch: 108/129 (84.5%) | Loss: 0.0084 | Batch time: 0.04s
2025-03-02 21:24:59,076 - INFO - [VAL] Epoch: 8/30 | Batch: 120/129 (93.8%) | Loss: 0.0246 | Batch time: 0.04s
2025-03-02 21:24:59,372 - INFO - [VAL] Epoch: 8/30 | Batch: 128/129 (100.0%) | Loss: 0.0330 | Batch time: 0.04s
2025-03-02 21:25:00,030 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 8)
2025-03-02 21:25:00,031 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:25:00,031 - INFO - Epoch 8/30 completed in 85.67s
2025-03-02 21:25:00,031 - INFO - Training   - Loss: 0.3491, Accuracy: 0.8848, F1: 0.8853
2025-03-02 21:25:00,031 - INFO - Validation - Loss: 0.0732, Accuracy: 0.9683, F1: 0.9685
2025-03-02 21:25:00,031 - INFO - Validation F1 improved from 0.9446 to 0.9685
2025-03-02 21:25:00,031 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:25:00,031 - INFO - Epoch 9/30
2025-03-02 21:25:00,031 - INFO - ----------------------------------------
2025-03-02 21:25:00,342 - INFO - [TRAIN] Epoch: 9/30 | Batch: 0/602 (0.2%) | Loss: 0.3478 | Batch time: 0.16s
2025-03-02 21:25:08,245 - INFO - [TRAIN] Epoch: 9/30 | Batch: 60/602 (10.1%) | Loss: 0.2720 | Batch time: 0.13s
2025-03-02 21:25:16,269 - INFO - [TRAIN] Epoch: 9/30 | Batch: 120/602 (20.1%) | Loss: 0.1805 | Batch time: 0.13s
2025-03-02 21:25:24,239 - INFO - [TRAIN] Epoch: 9/30 | Batch: 180/602 (30.1%) | Loss: 0.3731 | Batch time: 0.13s
2025-03-02 21:25:32,248 - INFO - [TRAIN] Epoch: 9/30 | Batch: 240/602 (40.0%) | Loss: 0.0912 | Batch time: 0.14s
2025-03-02 21:25:40,390 - INFO - [TRAIN] Epoch: 9/30 | Batch: 300/602 (50.0%) | Loss: 0.3148 | Batch time: 0.14s
2025-03-02 21:25:48,414 - INFO - [TRAIN] Epoch: 9/30 | Batch: 360/602 (60.0%) | Loss: 0.2488 | Batch time: 0.14s
2025-03-02 21:25:56,426 - INFO - [TRAIN] Epoch: 9/30 | Batch: 420/602 (69.9%) | Loss: 0.1604 | Batch time: 0.13s
2025-03-02 21:26:04,475 - INFO - [TRAIN] Epoch: 9/30 | Batch: 480/602 (79.9%) | Loss: 0.3919 | Batch time: 0.13s
2025-03-02 21:26:12,579 - INFO - [TRAIN] Epoch: 9/30 | Batch: 540/602 (89.9%) | Loss: 0.5717 | Batch time: 0.14s
2025-03-02 21:26:20,535 - INFO - [TRAIN] Epoch: 9/30 | Batch: 600/602 (99.8%) | Loss: 0.3758 | Batch time: 0.13s
2025-03-02 21:26:20,656 - INFO - [TRAIN] Epoch: 9/30 | Batch: 601/602 (100.0%) | Loss: 0.3490 | Batch time: 0.12s
2025-03-02 21:26:20,748 - INFO - [VAL] Epoch: 9/30 | Batch: 0/129 (0.8%) | Loss: 0.0092 | Batch time: 0.04s
2025-03-02 21:26:21,156 - INFO - [VAL] Epoch: 9/30 | Batch: 12/129 (10.1%) | Loss: 0.0117 | Batch time: 0.03s
2025-03-02 21:26:21,575 - INFO - [VAL] Epoch: 9/30 | Batch: 24/129 (19.4%) | Loss: 0.0893 | Batch time: 0.04s
2025-03-02 21:26:22,021 - INFO - [VAL] Epoch: 9/30 | Batch: 36/129 (28.7%) | Loss: 0.0452 | Batch time: 0.04s
2025-03-02 21:26:22,473 - INFO - [VAL] Epoch: 9/30 | Batch: 48/129 (38.0%) | Loss: 0.0401 | Batch time: 0.04s
2025-03-02 21:26:22,924 - INFO - [VAL] Epoch: 9/30 | Batch: 60/129 (47.3%) | Loss: 0.0114 | Batch time: 0.04s
2025-03-02 21:26:23,384 - INFO - [VAL] Epoch: 9/30 | Batch: 72/129 (56.6%) | Loss: 0.0067 | Batch time: 0.04s
2025-03-02 21:26:23,832 - INFO - [VAL] Epoch: 9/30 | Batch: 84/129 (65.9%) | Loss: 0.0124 | Batch time: 0.04s
2025-03-02 21:26:24,277 - INFO - [VAL] Epoch: 9/30 | Batch: 96/129 (75.2%) | Loss: 0.0306 | Batch time: 0.04s
2025-03-02 21:26:24,730 - INFO - [VAL] Epoch: 9/30 | Batch: 108/129 (84.5%) | Loss: 0.0072 | Batch time: 0.04s
2025-03-02 21:26:25,168 - INFO - [VAL] Epoch: 9/30 | Batch: 120/129 (93.8%) | Loss: 0.0216 | Batch time: 0.04s
2025-03-02 21:26:25,457 - INFO - [VAL] Epoch: 9/30 | Batch: 128/129 (100.0%) | Loss: 0.0253 | Batch time: 0.04s
2025-03-02 21:26:26,074 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 9)
2025-03-02 21:26:26,074 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:26:26,074 - INFO - Epoch 9/30 completed in 86.04s
2025-03-02 21:26:26,074 - INFO - Training   - Loss: 0.2867, Accuracy: 0.9035, F1: 0.9037
2025-03-02 21:26:26,074 - INFO - Validation - Loss: 0.0693, Accuracy: 0.9690, F1: 0.9691
2025-03-02 21:26:26,074 - INFO - Validation F1 improved from 0.9685 to 0.9691
2025-03-02 21:26:26,074 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:26:26,074 - INFO - Epoch 10/30
2025-03-02 21:26:26,074 - INFO - ----------------------------------------
2025-03-02 21:26:26,409 - INFO - [TRAIN] Epoch: 10/30 | Batch: 0/602 (0.2%) | Loss: 0.1481 | Batch time: 0.15s
2025-03-02 21:26:34,263 - INFO - [TRAIN] Epoch: 10/30 | Batch: 60/602 (10.1%) | Loss: 0.1989 | Batch time: 0.13s
2025-03-02 21:26:42,238 - INFO - [TRAIN] Epoch: 10/30 | Batch: 120/602 (20.1%) | Loss: 0.1617 | Batch time: 0.13s
2025-03-02 21:26:50,258 - INFO - [TRAIN] Epoch: 10/30 | Batch: 180/602 (30.1%) | Loss: 0.2808 | Batch time: 0.13s
2025-03-02 21:26:58,193 - INFO - [TRAIN] Epoch: 10/30 | Batch: 240/602 (40.0%) | Loss: 0.2036 | Batch time: 0.13s
2025-03-02 21:27:06,120 - INFO - [TRAIN] Epoch: 10/30 | Batch: 300/602 (50.0%) | Loss: 0.7289 | Batch time: 0.13s
2025-03-02 21:27:14,114 - INFO - [TRAIN] Epoch: 10/30 | Batch: 360/602 (60.0%) | Loss: 0.0920 | Batch time: 0.13s
2025-03-02 21:27:22,125 - INFO - [TRAIN] Epoch: 10/30 | Batch: 420/602 (69.9%) | Loss: 0.3086 | Batch time: 0.13s
2025-03-02 21:27:30,180 - INFO - [TRAIN] Epoch: 10/30 | Batch: 480/602 (79.9%) | Loss: 0.1624 | Batch time: 0.13s
2025-03-02 21:27:38,110 - INFO - [TRAIN] Epoch: 10/30 | Batch: 540/602 (89.9%) | Loss: 0.2990 | Batch time: 0.13s
2025-03-02 21:27:46,028 - INFO - [TRAIN] Epoch: 10/30 | Batch: 600/602 (99.8%) | Loss: 0.3983 | Batch time: 0.13s
2025-03-02 21:27:46,150 - INFO - [TRAIN] Epoch: 10/30 | Batch: 601/602 (100.0%) | Loss: 0.3224 | Batch time: 0.12s
2025-03-02 21:27:46,237 - INFO - [VAL] Epoch: 10/30 | Batch: 0/129 (0.8%) | Loss: 0.0058 | Batch time: 0.04s
2025-03-02 21:27:46,642 - INFO - [VAL] Epoch: 10/30 | Batch: 12/129 (10.1%) | Loss: 0.0095 | Batch time: 0.03s
2025-03-02 21:27:47,060 - INFO - [VAL] Epoch: 10/30 | Batch: 24/129 (19.4%) | Loss: 0.0654 | Batch time: 0.04s
2025-03-02 21:27:47,489 - INFO - [VAL] Epoch: 10/30 | Batch: 36/129 (28.7%) | Loss: 0.0296 | Batch time: 0.04s
2025-03-02 21:27:47,922 - INFO - [VAL] Epoch: 10/30 | Batch: 48/129 (38.0%) | Loss: 0.0182 | Batch time: 0.04s
2025-03-02 21:27:48,356 - INFO - [VAL] Epoch: 10/30 | Batch: 60/129 (47.3%) | Loss: 0.0134 | Batch time: 0.04s
2025-03-02 21:27:48,792 - INFO - [VAL] Epoch: 10/30 | Batch: 72/129 (56.6%) | Loss: 0.0051 | Batch time: 0.04s
2025-03-02 21:27:49,226 - INFO - [VAL] Epoch: 10/30 | Batch: 84/129 (65.9%) | Loss: 0.0190 | Batch time: 0.04s
2025-03-02 21:27:49,658 - INFO - [VAL] Epoch: 10/30 | Batch: 96/129 (75.2%) | Loss: 0.0117 | Batch time: 0.04s
2025-03-02 21:27:50,090 - INFO - [VAL] Epoch: 10/30 | Batch: 108/129 (84.5%) | Loss: 0.0132 | Batch time: 0.04s
2025-03-02 21:27:50,517 - INFO - [VAL] Epoch: 10/30 | Batch: 120/129 (93.8%) | Loss: 0.0219 | Batch time: 0.04s
2025-03-02 21:27:50,799 - INFO - [VAL] Epoch: 10/30 | Batch: 128/129 (100.0%) | Loss: 0.0278 | Batch time: 0.03s
2025-03-02 21:27:51,421 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 10)
2025-03-02 21:27:51,422 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:27:51,422 - INFO - Epoch 10/30 completed in 85.35s
2025-03-02 21:27:51,422 - INFO - Training   - Loss: 0.2603, Accuracy: 0.9121, F1: 0.9123
2025-03-02 21:27:51,422 - INFO - Validation - Loss: 0.0562, Accuracy: 0.9729, F1: 0.9730
2025-03-02 21:27:51,422 - INFO - Validation F1 improved from 0.9691 to 0.9730
2025-03-02 21:27:51,422 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:27:51,864 - INFO - Checkpoint saved: checkpoint_epoch_10.pth (Epoch 10)
2025-03-02 21:27:51,864 - INFO - Epoch 11/30
2025-03-02 21:27:51,864 - INFO - ----------------------------------------
2025-03-02 21:27:52,185 - INFO - [TRAIN] Epoch: 11/30 | Batch: 0/602 (0.2%) | Loss: 0.6194 | Batch time: 0.16s
2025-03-02 21:27:59,896 - INFO - [TRAIN] Epoch: 11/30 | Batch: 60/602 (10.1%) | Loss: 0.0927 | Batch time: 0.13s
2025-03-02 21:28:07,849 - INFO - [TRAIN] Epoch: 11/30 | Batch: 120/602 (20.1%) | Loss: 0.0994 | Batch time: 0.13s
2025-03-02 21:28:15,884 - INFO - [TRAIN] Epoch: 11/30 | Batch: 180/602 (30.1%) | Loss: 0.5280 | Batch time: 0.14s
2025-03-02 21:28:23,856 - INFO - [TRAIN] Epoch: 11/30 | Batch: 240/602 (40.0%) | Loss: 0.1922 | Batch time: 0.13s
2025-03-02 21:28:31,741 - INFO - [TRAIN] Epoch: 11/30 | Batch: 300/602 (50.0%) | Loss: 0.1298 | Batch time: 0.13s
2025-03-02 21:28:39,712 - INFO - [TRAIN] Epoch: 11/30 | Batch: 360/602 (60.0%) | Loss: 0.1570 | Batch time: 0.13s
2025-03-02 21:28:47,633 - INFO - [TRAIN] Epoch: 11/30 | Batch: 420/602 (69.9%) | Loss: 0.0811 | Batch time: 0.13s
2025-03-02 21:28:55,615 - INFO - [TRAIN] Epoch: 11/30 | Batch: 480/602 (79.9%) | Loss: 0.1085 | Batch time: 0.13s
2025-03-02 21:29:03,449 - INFO - [TRAIN] Epoch: 11/30 | Batch: 540/602 (89.9%) | Loss: 0.1458 | Batch time: 0.13s
2025-03-02 21:29:11,299 - INFO - [TRAIN] Epoch: 11/30 | Batch: 600/602 (99.8%) | Loss: 0.2279 | Batch time: 0.13s
2025-03-02 21:29:11,421 - INFO - [TRAIN] Epoch: 11/30 | Batch: 601/602 (100.0%) | Loss: 0.5666 | Batch time: 0.12s
2025-03-02 21:29:11,508 - INFO - [VAL] Epoch: 11/30 | Batch: 0/129 (0.8%) | Loss: 0.0032 | Batch time: 0.04s
2025-03-02 21:29:11,917 - INFO - [VAL] Epoch: 11/30 | Batch: 12/129 (10.1%) | Loss: 0.0059 | Batch time: 0.03s
2025-03-02 21:29:12,337 - INFO - [VAL] Epoch: 11/30 | Batch: 24/129 (19.4%) | Loss: 0.0287 | Batch time: 0.04s
2025-03-02 21:29:12,768 - INFO - [VAL] Epoch: 11/30 | Batch: 36/129 (28.7%) | Loss: 0.0068 | Batch time: 0.04s
2025-03-02 21:29:13,203 - INFO - [VAL] Epoch: 11/30 | Batch: 48/129 (38.0%) | Loss: 0.0225 | Batch time: 0.04s
2025-03-02 21:29:13,637 - INFO - [VAL] Epoch: 11/30 | Batch: 60/129 (47.3%) | Loss: 0.0423 | Batch time: 0.04s
2025-03-02 21:29:14,069 - INFO - [VAL] Epoch: 11/30 | Batch: 72/129 (56.6%) | Loss: 0.0046 | Batch time: 0.04s
2025-03-02 21:29:14,501 - INFO - [VAL] Epoch: 11/30 | Batch: 84/129 (65.9%) | Loss: 0.0049 | Batch time: 0.04s
2025-03-02 21:29:14,944 - INFO - [VAL] Epoch: 11/30 | Batch: 96/129 (75.2%) | Loss: 0.0275 | Batch time: 0.04s
2025-03-02 21:29:15,381 - INFO - [VAL] Epoch: 11/30 | Batch: 108/129 (84.5%) | Loss: 0.0095 | Batch time: 0.04s
2025-03-02 21:29:15,808 - INFO - [VAL] Epoch: 11/30 | Batch: 120/129 (93.8%) | Loss: 0.0210 | Batch time: 0.03s
2025-03-02 21:29:16,096 - INFO - [VAL] Epoch: 11/30 | Batch: 128/129 (100.0%) | Loss: 0.0345 | Batch time: 0.04s
2025-03-02 21:29:16,816 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 11)
2025-03-02 21:29:16,816 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:29:16,816 - INFO - Epoch 11/30 completed in 84.95s
2025-03-02 21:29:16,816 - INFO - Training   - Loss: 0.2585, Accuracy: 0.9109, F1: 0.9113
2025-03-02 21:29:16,816 - INFO - Validation - Loss: 0.0534, Accuracy: 0.9764, F1: 0.9765
2025-03-02 21:29:16,816 - INFO - Validation F1 improved from 0.9730 to 0.9765
2025-03-02 21:29:16,816 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:29:16,816 - INFO - Epoch 12/30
2025-03-02 21:29:16,816 - INFO - ----------------------------------------
2025-03-02 21:29:17,120 - INFO - [TRAIN] Epoch: 12/30 | Batch: 0/602 (0.2%) | Loss: 0.1516 | Batch time: 0.16s
2025-03-02 21:29:25,024 - INFO - [TRAIN] Epoch: 12/30 | Batch: 60/602 (10.1%) | Loss: 0.3086 | Batch time: 0.14s
2025-03-02 21:29:32,916 - INFO - [TRAIN] Epoch: 12/30 | Batch: 120/602 (20.1%) | Loss: 0.1138 | Batch time: 0.13s
2025-03-02 21:29:40,803 - INFO - [TRAIN] Epoch: 12/30 | Batch: 180/602 (30.1%) | Loss: 0.1259 | Batch time: 0.13s
2025-03-02 21:29:48,749 - INFO - [TRAIN] Epoch: 12/30 | Batch: 240/602 (40.0%) | Loss: 0.0865 | Batch time: 0.13s
2025-03-02 21:29:56,675 - INFO - [TRAIN] Epoch: 12/30 | Batch: 300/602 (50.0%) | Loss: 0.3124 | Batch time: 0.13s
2025-03-02 21:30:04,719 - INFO - [TRAIN] Epoch: 12/30 | Batch: 360/602 (60.0%) | Loss: 0.2726 | Batch time: 0.13s
2025-03-02 21:30:12,648 - INFO - [TRAIN] Epoch: 12/30 | Batch: 420/602 (69.9%) | Loss: 0.1721 | Batch time: 0.13s
2025-03-02 21:30:20,586 - INFO - [TRAIN] Epoch: 12/30 | Batch: 480/602 (79.9%) | Loss: 0.1646 | Batch time: 0.13s
2025-03-02 21:30:28,488 - INFO - [TRAIN] Epoch: 12/30 | Batch: 540/602 (89.9%) | Loss: 0.0729 | Batch time: 0.13s
2025-03-02 21:30:36,365 - INFO - [TRAIN] Epoch: 12/30 | Batch: 600/602 (99.8%) | Loss: 0.0843 | Batch time: 0.13s
2025-03-02 21:30:36,486 - INFO - [TRAIN] Epoch: 12/30 | Batch: 601/602 (100.0%) | Loss: 0.0954 | Batch time: 0.12s
2025-03-02 21:30:36,574 - INFO - [VAL] Epoch: 12/30 | Batch: 0/129 (0.8%) | Loss: 0.0042 | Batch time: 0.04s
2025-03-02 21:30:36,979 - INFO - [VAL] Epoch: 12/30 | Batch: 12/129 (10.1%) | Loss: 0.0037 | Batch time: 0.03s
2025-03-02 21:30:37,399 - INFO - [VAL] Epoch: 12/30 | Batch: 24/129 (19.4%) | Loss: 0.0395 | Batch time: 0.04s
2025-03-02 21:30:37,829 - INFO - [VAL] Epoch: 12/30 | Batch: 36/129 (28.7%) | Loss: 0.0123 | Batch time: 0.04s
2025-03-02 21:30:38,270 - INFO - [VAL] Epoch: 12/30 | Batch: 48/129 (38.0%) | Loss: 0.0397 | Batch time: 0.04s
2025-03-02 21:30:38,709 - INFO - [VAL] Epoch: 12/30 | Batch: 60/129 (47.3%) | Loss: 0.0109 | Batch time: 0.04s
2025-03-02 21:30:39,151 - INFO - [VAL] Epoch: 12/30 | Batch: 72/129 (56.6%) | Loss: 0.0035 | Batch time: 0.04s
2025-03-02 21:30:39,599 - INFO - [VAL] Epoch: 12/30 | Batch: 84/129 (65.9%) | Loss: 0.0135 | Batch time: 0.04s
2025-03-02 21:30:40,039 - INFO - [VAL] Epoch: 12/30 | Batch: 96/129 (75.2%) | Loss: 0.0109 | Batch time: 0.04s
2025-03-02 21:30:40,477 - INFO - [VAL] Epoch: 12/30 | Batch: 108/129 (84.5%) | Loss: 0.0030 | Batch time: 0.04s
2025-03-02 21:30:40,905 - INFO - [VAL] Epoch: 12/30 | Batch: 120/129 (93.8%) | Loss: 0.0168 | Batch time: 0.03s
2025-03-02 21:30:41,186 - INFO - [VAL] Epoch: 12/30 | Batch: 128/129 (100.0%) | Loss: 0.0179 | Batch time: 0.03s
2025-03-02 21:30:41,815 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 12)
2025-03-02 21:30:41,816 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:30:41,816 - INFO - Epoch 12/30 completed in 85.00s
2025-03-02 21:30:41,816 - INFO - Training   - Loss: 0.2393, Accuracy: 0.9187, F1: 0.9190
2025-03-02 21:30:41,816 - INFO - Validation - Loss: 0.0418, Accuracy: 0.9816, F1: 0.9816
2025-03-02 21:30:41,816 - INFO - Validation F1 improved from 0.9765 to 0.9816
2025-03-02 21:30:41,816 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:30:41,816 - INFO - Epoch 13/30
2025-03-02 21:30:41,816 - INFO - ----------------------------------------
2025-03-02 21:30:42,113 - INFO - [TRAIN] Epoch: 13/30 | Batch: 0/602 (0.2%) | Loss: 0.2541 | Batch time: 0.16s
2025-03-02 21:30:49,947 - INFO - [TRAIN] Epoch: 13/30 | Batch: 60/602 (10.1%) | Loss: 0.3344 | Batch time: 0.13s
2025-03-02 21:30:57,854 - INFO - [TRAIN] Epoch: 13/30 | Batch: 120/602 (20.1%) | Loss: 0.3607 | Batch time: 0.13s
2025-03-02 21:31:05,734 - INFO - [TRAIN] Epoch: 13/30 | Batch: 180/602 (30.1%) | Loss: 0.0760 | Batch time: 0.13s
2025-03-02 21:31:13,662 - INFO - [TRAIN] Epoch: 13/30 | Batch: 240/602 (40.0%) | Loss: 0.1185 | Batch time: 0.13s
2025-03-02 21:31:21,789 - INFO - [TRAIN] Epoch: 13/30 | Batch: 300/602 (50.0%) | Loss: 0.0390 | Batch time: 0.13s
2025-03-02 21:31:29,842 - INFO - [TRAIN] Epoch: 13/30 | Batch: 360/602 (60.0%) | Loss: 0.2641 | Batch time: 0.13s
2025-03-02 21:31:37,720 - INFO - [TRAIN] Epoch: 13/30 | Batch: 420/602 (69.9%) | Loss: 0.1151 | Batch time: 0.13s
2025-03-02 21:31:45,612 - INFO - [TRAIN] Epoch: 13/30 | Batch: 480/602 (79.9%) | Loss: 0.2415 | Batch time: 0.13s
2025-03-02 21:31:53,502 - INFO - [TRAIN] Epoch: 13/30 | Batch: 540/602 (89.9%) | Loss: 0.1983 | Batch time: 0.13s
2025-03-02 21:32:01,365 - INFO - [TRAIN] Epoch: 13/30 | Batch: 600/602 (99.8%) | Loss: 0.1089 | Batch time: 0.13s
2025-03-02 21:32:01,485 - INFO - [TRAIN] Epoch: 13/30 | Batch: 601/602 (100.0%) | Loss: 0.2503 | Batch time: 0.12s
2025-03-02 21:32:01,571 - INFO - [VAL] Epoch: 13/30 | Batch: 0/129 (0.8%) | Loss: 0.0021 | Batch time: 0.03s
2025-03-02 21:32:01,973 - INFO - [VAL] Epoch: 13/30 | Batch: 12/129 (10.1%) | Loss: 0.0027 | Batch time: 0.03s
2025-03-02 21:32:02,389 - INFO - [VAL] Epoch: 13/30 | Batch: 24/129 (19.4%) | Loss: 0.0201 | Batch time: 0.03s
2025-03-02 21:32:02,815 - INFO - [VAL] Epoch: 13/30 | Batch: 36/129 (28.7%) | Loss: 0.0113 | Batch time: 0.04s
2025-03-02 21:32:03,246 - INFO - [VAL] Epoch: 13/30 | Batch: 48/129 (38.0%) | Loss: 0.0259 | Batch time: 0.04s
2025-03-02 21:32:03,677 - INFO - [VAL] Epoch: 13/30 | Batch: 60/129 (47.3%) | Loss: 0.0100 | Batch time: 0.04s
2025-03-02 21:32:04,107 - INFO - [VAL] Epoch: 13/30 | Batch: 72/129 (56.6%) | Loss: 0.0038 | Batch time: 0.04s
2025-03-02 21:32:04,537 - INFO - [VAL] Epoch: 13/30 | Batch: 84/129 (65.9%) | Loss: 0.0091 | Batch time: 0.04s
2025-03-02 21:32:04,965 - INFO - [VAL] Epoch: 13/30 | Batch: 96/129 (75.2%) | Loss: 0.0089 | Batch time: 0.04s
2025-03-02 21:32:05,394 - INFO - [VAL] Epoch: 13/30 | Batch: 108/129 (84.5%) | Loss: 0.0052 | Batch time: 0.03s
2025-03-02 21:32:05,817 - INFO - [VAL] Epoch: 13/30 | Batch: 120/129 (93.8%) | Loss: 0.0086 | Batch time: 0.03s
2025-03-02 21:32:06,098 - INFO - [VAL] Epoch: 13/30 | Batch: 128/129 (100.0%) | Loss: 0.0035 | Batch time: 0.03s
2025-03-02 21:32:06,726 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 13)
2025-03-02 21:32:06,727 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:32:06,727 - INFO - Epoch 13/30 completed in 84.91s
2025-03-02 21:32:06,727 - INFO - Training   - Loss: 0.2281, Accuracy: 0.9223, F1: 0.9226
2025-03-02 21:32:06,727 - INFO - Validation - Loss: 0.0397, Accuracy: 0.9819, F1: 0.9819
2025-03-02 21:32:06,727 - INFO - Validation F1 improved from 0.9816 to 0.9819
2025-03-02 21:32:06,727 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:32:06,727 - INFO - Epoch 14/30
2025-03-02 21:32:06,727 - INFO - ----------------------------------------
2025-03-02 21:32:07,046 - INFO - [TRAIN] Epoch: 14/30 | Batch: 0/602 (0.2%) | Loss: 0.4358 | Batch time: 0.14s
2025-03-02 21:32:14,825 - INFO - [TRAIN] Epoch: 14/30 | Batch: 60/602 (10.1%) | Loss: 0.2921 | Batch time: 0.13s
2025-03-02 21:32:22,732 - INFO - [TRAIN] Epoch: 14/30 | Batch: 120/602 (20.1%) | Loss: 0.1480 | Batch time: 0.13s
2025-03-02 21:32:30,594 - INFO - [TRAIN] Epoch: 14/30 | Batch: 180/602 (30.1%) | Loss: 0.0831 | Batch time: 0.13s
2025-03-02 21:32:38,513 - INFO - [TRAIN] Epoch: 14/30 | Batch: 240/602 (40.0%) | Loss: 0.2065 | Batch time: 0.13s
2025-03-02 21:32:46,450 - INFO - [TRAIN] Epoch: 14/30 | Batch: 300/602 (50.0%) | Loss: 0.1248 | Batch time: 0.13s
2025-03-02 21:32:54,401 - INFO - [TRAIN] Epoch: 14/30 | Batch: 360/602 (60.0%) | Loss: 0.1734 | Batch time: 0.13s
2025-03-02 21:33:02,345 - INFO - [TRAIN] Epoch: 14/30 | Batch: 420/602 (69.9%) | Loss: 0.3248 | Batch time: 0.13s
2025-03-02 21:33:10,296 - INFO - [TRAIN] Epoch: 14/30 | Batch: 480/602 (79.9%) | Loss: 0.0516 | Batch time: 0.13s
2025-03-02 21:33:18,293 - INFO - [TRAIN] Epoch: 14/30 | Batch: 540/602 (89.9%) | Loss: 0.2269 | Batch time: 0.13s
2025-03-02 21:33:26,481 - INFO - [TRAIN] Epoch: 14/30 | Batch: 600/602 (99.8%) | Loss: 0.3758 | Batch time: 0.13s
2025-03-02 21:33:26,601 - INFO - [TRAIN] Epoch: 14/30 | Batch: 601/602 (100.0%) | Loss: 0.4847 | Batch time: 0.12s
2025-03-02 21:33:26,692 - INFO - [VAL] Epoch: 14/30 | Batch: 0/129 (0.8%) | Loss: 0.0024 | Batch time: 0.04s
2025-03-02 21:33:27,093 - INFO - [VAL] Epoch: 14/30 | Batch: 12/129 (10.1%) | Loss: 0.0028 | Batch time: 0.03s
2025-03-02 21:33:27,509 - INFO - [VAL] Epoch: 14/30 | Batch: 24/129 (19.4%) | Loss: 0.1259 | Batch time: 0.03s
2025-03-02 21:33:27,939 - INFO - [VAL] Epoch: 14/30 | Batch: 36/129 (28.7%) | Loss: 0.0334 | Batch time: 0.04s
2025-03-02 21:33:28,375 - INFO - [VAL] Epoch: 14/30 | Batch: 48/129 (38.0%) | Loss: 0.0356 | Batch time: 0.04s
2025-03-02 21:33:28,813 - INFO - [VAL] Epoch: 14/30 | Batch: 60/129 (47.3%) | Loss: 0.0017 | Batch time: 0.04s
2025-03-02 21:33:29,252 - INFO - [VAL] Epoch: 14/30 | Batch: 72/129 (56.6%) | Loss: 0.0109 | Batch time: 0.04s
2025-03-02 21:33:29,692 - INFO - [VAL] Epoch: 14/30 | Batch: 84/129 (65.9%) | Loss: 0.0145 | Batch time: 0.04s
2025-03-02 21:33:30,131 - INFO - [VAL] Epoch: 14/30 | Batch: 96/129 (75.2%) | Loss: 0.0080 | Batch time: 0.04s
2025-03-02 21:33:30,572 - INFO - [VAL] Epoch: 14/30 | Batch: 108/129 (84.5%) | Loss: 0.0042 | Batch time: 0.04s
2025-03-02 21:33:31,005 - INFO - [VAL] Epoch: 14/30 | Batch: 120/129 (93.8%) | Loss: 0.0079 | Batch time: 0.04s
2025-03-02 21:33:31,291 - INFO - [VAL] Epoch: 14/30 | Batch: 128/129 (100.0%) | Loss: 0.0077 | Batch time: 0.04s
2025-03-02 21:33:31,923 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 14)
2025-03-02 21:33:31,923 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:33:31,923 - INFO - Epoch 14/30 completed in 85.20s
2025-03-02 21:33:31,924 - INFO - Training   - Loss: 0.2305, Accuracy: 0.9231, F1: 0.9233
2025-03-02 21:33:31,924 - INFO - Validation - Loss: 0.0404, Accuracy: 0.9822, F1: 0.9823
2025-03-02 21:33:31,924 - INFO - Validation F1 improved from 0.9819 to 0.9823
2025-03-02 21:33:31,924 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:33:31,924 - INFO - Epoch 15/30
2025-03-02 21:33:31,924 - INFO - ----------------------------------------
2025-03-02 21:33:32,250 - INFO - [TRAIN] Epoch: 15/30 | Batch: 0/602 (0.2%) | Loss: 0.1735 | Batch time: 0.15s
2025-03-02 21:33:40,074 - INFO - [TRAIN] Epoch: 15/30 | Batch: 60/602 (10.1%) | Loss: 0.3081 | Batch time: 0.13s
2025-03-02 21:33:48,092 - INFO - [TRAIN] Epoch: 15/30 | Batch: 120/602 (20.1%) | Loss: 0.1117 | Batch time: 0.13s
2025-03-02 21:33:56,281 - INFO - [TRAIN] Epoch: 15/30 | Batch: 180/602 (30.1%) | Loss: 0.1310 | Batch time: 0.13s
2025-03-02 21:34:04,222 - INFO - [TRAIN] Epoch: 15/30 | Batch: 240/602 (40.0%) | Loss: 0.1896 | Batch time: 0.13s
2025-03-02 21:34:12,229 - INFO - [TRAIN] Epoch: 15/30 | Batch: 300/602 (50.0%) | Loss: 0.9905 | Batch time: 0.13s
2025-03-02 21:34:20,194 - INFO - [TRAIN] Epoch: 15/30 | Batch: 360/602 (60.0%) | Loss: 0.1624 | Batch time: 0.13s
2025-03-02 21:34:28,302 - INFO - [TRAIN] Epoch: 15/30 | Batch: 420/602 (69.9%) | Loss: 0.3759 | Batch time: 0.14s
2025-03-02 21:34:36,347 - INFO - [TRAIN] Epoch: 15/30 | Batch: 480/602 (79.9%) | Loss: 0.0891 | Batch time: 0.13s
2025-03-02 21:34:44,403 - INFO - [TRAIN] Epoch: 15/30 | Batch: 540/602 (89.9%) | Loss: 0.1713 | Batch time: 0.13s
2025-03-02 21:34:52,411 - INFO - [TRAIN] Epoch: 15/30 | Batch: 600/602 (99.8%) | Loss: 0.2592 | Batch time: 0.13s
2025-03-02 21:34:52,535 - INFO - [TRAIN] Epoch: 15/30 | Batch: 601/602 (100.0%) | Loss: 0.2455 | Batch time: 0.12s
2025-03-02 21:34:52,625 - INFO - [VAL] Epoch: 15/30 | Batch: 0/129 (0.8%) | Loss: 0.0020 | Batch time: 0.04s
2025-03-02 21:34:53,029 - INFO - [VAL] Epoch: 15/30 | Batch: 12/129 (10.1%) | Loss: 0.0018 | Batch time: 0.03s
2025-03-02 21:34:53,448 - INFO - [VAL] Epoch: 15/30 | Batch: 24/129 (19.4%) | Loss: 0.1028 | Batch time: 0.04s
2025-03-02 21:34:53,876 - INFO - [VAL] Epoch: 15/30 | Batch: 36/129 (28.7%) | Loss: 0.0103 | Batch time: 0.04s
2025-03-02 21:34:54,321 - INFO - [VAL] Epoch: 15/30 | Batch: 48/129 (38.0%) | Loss: 0.0389 | Batch time: 0.04s
2025-03-02 21:34:54,761 - INFO - [VAL] Epoch: 15/30 | Batch: 60/129 (47.3%) | Loss: 0.0013 | Batch time: 0.04s
2025-03-02 21:34:55,199 - INFO - [VAL] Epoch: 15/30 | Batch: 72/129 (56.6%) | Loss: 0.0021 | Batch time: 0.04s
2025-03-02 21:34:55,635 - INFO - [VAL] Epoch: 15/30 | Batch: 84/129 (65.9%) | Loss: 0.0165 | Batch time: 0.04s
2025-03-02 21:34:56,071 - INFO - [VAL] Epoch: 15/30 | Batch: 96/129 (75.2%) | Loss: 0.0061 | Batch time: 0.04s
2025-03-02 21:34:56,515 - INFO - [VAL] Epoch: 15/30 | Batch: 108/129 (84.5%) | Loss: 0.0021 | Batch time: 0.04s
2025-03-02 21:34:56,949 - INFO - [VAL] Epoch: 15/30 | Batch: 120/129 (93.8%) | Loss: 0.0060 | Batch time: 0.04s
2025-03-02 21:34:57,234 - INFO - [VAL] Epoch: 15/30 | Batch: 128/129 (100.0%) | Loss: 0.0089 | Batch time: 0.04s
2025-03-02 21:34:57,871 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 15)
2025-03-02 21:34:57,872 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:34:57,872 - INFO - Epoch 15/30 completed in 85.95s
2025-03-02 21:34:57,872 - INFO - Training   - Loss: 0.2112, Accuracy: 0.9279, F1: 0.9281
2025-03-02 21:34:57,872 - INFO - Validation - Loss: 0.0366, Accuracy: 0.9829, F1: 0.9829
2025-03-02 21:34:57,872 - INFO - Validation F1 improved from 0.9823 to 0.9829
2025-03-02 21:34:57,872 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:34:58,328 - INFO - Checkpoint saved: checkpoint_epoch_15.pth (Epoch 15)
2025-03-02 21:34:58,328 - INFO - Epoch 16/30
2025-03-02 21:34:58,328 - INFO - ----------------------------------------
2025-03-02 21:34:58,639 - INFO - [TRAIN] Epoch: 16/30 | Batch: 0/602 (0.2%) | Loss: 0.0862 | Batch time: 0.16s
2025-03-02 21:35:06,465 - INFO - [TRAIN] Epoch: 16/30 | Batch: 60/602 (10.1%) | Loss: 0.1007 | Batch time: 0.13s
2025-03-02 21:35:14,447 - INFO - [TRAIN] Epoch: 16/30 | Batch: 120/602 (20.1%) | Loss: 0.5849 | Batch time: 0.13s
2025-03-02 21:35:22,518 - INFO - [TRAIN] Epoch: 16/30 | Batch: 180/602 (30.1%) | Loss: 0.1584 | Batch time: 0.14s
2025-03-02 21:35:30,541 - INFO - [TRAIN] Epoch: 16/30 | Batch: 240/602 (40.0%) | Loss: 0.0358 | Batch time: 0.13s
2025-03-02 21:35:38,555 - INFO - [TRAIN] Epoch: 16/30 | Batch: 300/602 (50.0%) | Loss: 0.1936 | Batch time: 0.13s
2025-03-02 21:35:46,513 - INFO - [TRAIN] Epoch: 16/30 | Batch: 360/602 (60.0%) | Loss: 0.1804 | Batch time: 0.13s
2025-03-02 21:35:54,510 - INFO - [TRAIN] Epoch: 16/30 | Batch: 420/602 (69.9%) | Loss: 0.0581 | Batch time: 0.14s
2025-03-02 21:36:02,520 - INFO - [TRAIN] Epoch: 16/30 | Batch: 480/602 (79.9%) | Loss: 0.1246 | Batch time: 0.14s
2025-03-02 21:36:10,504 - INFO - [TRAIN] Epoch: 16/30 | Batch: 540/602 (89.9%) | Loss: 0.0590 | Batch time: 0.13s
2025-03-02 21:36:18,464 - INFO - [TRAIN] Epoch: 16/30 | Batch: 600/602 (99.8%) | Loss: 0.0869 | Batch time: 0.13s
2025-03-02 21:36:18,584 - INFO - [TRAIN] Epoch: 16/30 | Batch: 601/602 (100.0%) | Loss: 0.1980 | Batch time: 0.12s
2025-03-02 21:36:18,672 - INFO - [VAL] Epoch: 16/30 | Batch: 0/129 (0.8%) | Loss: 0.0022 | Batch time: 0.04s
2025-03-02 21:36:19,084 - INFO - [VAL] Epoch: 16/30 | Batch: 12/129 (10.1%) | Loss: 0.0027 | Batch time: 0.03s
2025-03-02 21:36:19,511 - INFO - [VAL] Epoch: 16/30 | Batch: 24/129 (19.4%) | Loss: 0.0810 | Batch time: 0.04s
2025-03-02 21:36:19,955 - INFO - [VAL] Epoch: 16/30 | Batch: 36/129 (28.7%) | Loss: 0.0098 | Batch time: 0.04s
2025-03-02 21:36:20,398 - INFO - [VAL] Epoch: 16/30 | Batch: 48/129 (38.0%) | Loss: 0.0312 | Batch time: 0.04s
2025-03-02 21:36:20,843 - INFO - [VAL] Epoch: 16/30 | Batch: 60/129 (47.3%) | Loss: 0.0018 | Batch time: 0.04s
2025-03-02 21:36:21,284 - INFO - [VAL] Epoch: 16/30 | Batch: 72/129 (56.6%) | Loss: 0.0026 | Batch time: 0.04s
2025-03-02 21:36:21,724 - INFO - [VAL] Epoch: 16/30 | Batch: 84/129 (65.9%) | Loss: 0.0145 | Batch time: 0.04s
2025-03-02 21:36:22,168 - INFO - [VAL] Epoch: 16/30 | Batch: 96/129 (75.2%) | Loss: 0.0130 | Batch time: 0.04s
2025-03-02 21:36:22,607 - INFO - [VAL] Epoch: 16/30 | Batch: 108/129 (84.5%) | Loss: 0.0029 | Batch time: 0.04s
2025-03-02 21:36:23,040 - INFO - [VAL] Epoch: 16/30 | Batch: 120/129 (93.8%) | Loss: 0.0100 | Batch time: 0.04s
2025-03-02 21:36:23,325 - INFO - [VAL] Epoch: 16/30 | Batch: 128/129 (100.0%) | Loss: 0.0068 | Batch time: 0.04s
2025-03-02 21:36:23,328 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:36:23,328 - INFO - Epoch 16/30 completed in 85.00s
2025-03-02 21:36:23,328 - INFO - Training   - Loss: 0.2077, Accuracy: 0.9285, F1: 0.9287
2025-03-02 21:36:23,328 - INFO - Validation - Loss: 0.0411, Accuracy: 0.9813, F1: 0.9813
2025-03-02 21:36:23,328 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:36:23,328 - INFO - Epoch 17/30
2025-03-02 21:36:23,328 - INFO - ----------------------------------------
2025-03-02 21:36:23,622 - INFO - [TRAIN] Epoch: 17/30 | Batch: 0/602 (0.2%) | Loss: 0.0844 | Batch time: 0.16s
2025-03-02 21:36:31,626 - INFO - [TRAIN] Epoch: 17/30 | Batch: 60/602 (10.1%) | Loss: 0.4589 | Batch time: 0.13s
2025-03-02 21:36:39,608 - INFO - [TRAIN] Epoch: 17/30 | Batch: 120/602 (20.1%) | Loss: 0.0198 | Batch time: 0.13s
2025-03-02 21:36:47,570 - INFO - [TRAIN] Epoch: 17/30 | Batch: 180/602 (30.1%) | Loss: 0.1287 | Batch time: 0.13s
2025-03-02 21:36:55,547 - INFO - [TRAIN] Epoch: 17/30 | Batch: 240/602 (40.0%) | Loss: 0.3430 | Batch time: 0.13s
2025-03-02 21:37:03,538 - INFO - [TRAIN] Epoch: 17/30 | Batch: 300/602 (50.0%) | Loss: 0.2601 | Batch time: 0.13s
2025-03-02 21:37:11,595 - INFO - [TRAIN] Epoch: 17/30 | Batch: 360/602 (60.0%) | Loss: 0.1706 | Batch time: 0.14s
2025-03-02 21:37:19,686 - INFO - [TRAIN] Epoch: 17/30 | Batch: 420/602 (69.9%) | Loss: 0.1044 | Batch time: 0.13s
2025-03-02 21:37:27,764 - INFO - [TRAIN] Epoch: 17/30 | Batch: 480/602 (79.9%) | Loss: 0.0600 | Batch time: 0.13s
2025-03-02 21:37:35,863 - INFO - [TRAIN] Epoch: 17/30 | Batch: 540/602 (89.9%) | Loss: 0.2542 | Batch time: 0.13s
2025-03-02 21:37:43,834 - INFO - [TRAIN] Epoch: 17/30 | Batch: 600/602 (99.8%) | Loss: 0.2517 | Batch time: 0.13s
2025-03-02 21:37:43,956 - INFO - [TRAIN] Epoch: 17/30 | Batch: 601/602 (100.0%) | Loss: 0.1645 | Batch time: 0.12s
2025-03-02 21:37:44,046 - INFO - [VAL] Epoch: 17/30 | Batch: 0/129 (0.8%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:37:44,452 - INFO - [VAL] Epoch: 17/30 | Batch: 12/129 (10.1%) | Loss: 0.0016 | Batch time: 0.03s
2025-03-02 21:37:44,873 - INFO - [VAL] Epoch: 17/30 | Batch: 24/129 (19.4%) | Loss: 0.0968 | Batch time: 0.04s
2025-03-02 21:37:45,305 - INFO - [VAL] Epoch: 17/30 | Batch: 36/129 (28.7%) | Loss: 0.0066 | Batch time: 0.04s
2025-03-02 21:37:45,746 - INFO - [VAL] Epoch: 17/30 | Batch: 48/129 (38.0%) | Loss: 0.0244 | Batch time: 0.04s
2025-03-02 21:37:46,189 - INFO - [VAL] Epoch: 17/30 | Batch: 60/129 (47.3%) | Loss: 0.0011 | Batch time: 0.04s
2025-03-02 21:37:46,631 - INFO - [VAL] Epoch: 17/30 | Batch: 72/129 (56.6%) | Loss: 0.0021 | Batch time: 0.04s
2025-03-02 21:37:47,071 - INFO - [VAL] Epoch: 17/30 | Batch: 84/129 (65.9%) | Loss: 0.0106 | Batch time: 0.04s
2025-03-02 21:37:47,510 - INFO - [VAL] Epoch: 17/30 | Batch: 96/129 (75.2%) | Loss: 0.0044 | Batch time: 0.04s
2025-03-02 21:37:47,949 - INFO - [VAL] Epoch: 17/30 | Batch: 108/129 (84.5%) | Loss: 0.0027 | Batch time: 0.04s
2025-03-02 21:37:48,380 - INFO - [VAL] Epoch: 17/30 | Batch: 120/129 (93.8%) | Loss: 0.0065 | Batch time: 0.04s
2025-03-02 21:37:48,666 - INFO - [VAL] Epoch: 17/30 | Batch: 128/129 (100.0%) | Loss: 0.0056 | Batch time: 0.04s
2025-03-02 21:37:48,670 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:37:48,670 - INFO - Epoch 17/30 completed in 85.34s
2025-03-02 21:37:48,670 - INFO - Training   - Loss: 0.2049, Accuracy: 0.9293, F1: 0.9294
2025-03-02 21:37:48,670 - INFO - Validation - Loss: 0.0372, Accuracy: 0.9822, F1: 0.9823
2025-03-02 21:37:48,670 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:37:48,670 - INFO - Epoch 18/30
2025-03-02 21:37:48,670 - INFO - ----------------------------------------
2025-03-02 21:37:48,964 - INFO - [TRAIN] Epoch: 18/30 | Batch: 0/602 (0.2%) | Loss: 0.1312 | Batch time: 0.15s
2025-03-02 21:37:57,019 - INFO - [TRAIN] Epoch: 18/30 | Batch: 60/602 (10.1%) | Loss: 0.0621 | Batch time: 0.13s
2025-03-02 21:38:05,018 - INFO - [TRAIN] Epoch: 18/30 | Batch: 120/602 (20.1%) | Loss: 0.1109 | Batch time: 0.13s
2025-03-02 21:38:13,033 - INFO - [TRAIN] Epoch: 18/30 | Batch: 180/602 (30.1%) | Loss: 0.1456 | Batch time: 0.13s
2025-03-02 21:38:21,020 - INFO - [TRAIN] Epoch: 18/30 | Batch: 240/602 (40.0%) | Loss: 0.3653 | Batch time: 0.13s
2025-03-02 21:38:29,001 - INFO - [TRAIN] Epoch: 18/30 | Batch: 300/602 (50.0%) | Loss: 0.1064 | Batch time: 0.13s
2025-03-02 21:38:37,008 - INFO - [TRAIN] Epoch: 18/30 | Batch: 360/602 (60.0%) | Loss: 0.2148 | Batch time: 0.13s
2025-03-02 21:38:45,113 - INFO - [TRAIN] Epoch: 18/30 | Batch: 420/602 (69.9%) | Loss: 0.0752 | Batch time: 0.15s
2025-03-02 21:38:53,206 - INFO - [TRAIN] Epoch: 18/30 | Batch: 480/602 (79.9%) | Loss: 0.2620 | Batch time: 0.13s
2025-03-02 21:39:01,211 - INFO - [TRAIN] Epoch: 18/30 | Batch: 540/602 (89.9%) | Loss: 0.1298 | Batch time: 0.13s
2025-03-02 21:39:09,153 - INFO - [TRAIN] Epoch: 18/30 | Batch: 600/602 (99.8%) | Loss: 0.1128 | Batch time: 0.13s
2025-03-02 21:39:09,274 - INFO - [TRAIN] Epoch: 18/30 | Batch: 601/602 (100.0%) | Loss: 0.2294 | Batch time: 0.12s
2025-03-02 21:39:09,367 - INFO - [VAL] Epoch: 18/30 | Batch: 0/129 (0.8%) | Loss: 0.0030 | Batch time: 0.04s
2025-03-02 21:39:09,775 - INFO - [VAL] Epoch: 18/30 | Batch: 12/129 (10.1%) | Loss: 0.0018 | Batch time: 0.03s
2025-03-02 21:39:10,195 - INFO - [VAL] Epoch: 18/30 | Batch: 24/129 (19.4%) | Loss: 0.1054 | Batch time: 0.04s
2025-03-02 21:39:10,627 - INFO - [VAL] Epoch: 18/30 | Batch: 36/129 (28.7%) | Loss: 0.0075 | Batch time: 0.04s
2025-03-02 21:39:11,064 - INFO - [VAL] Epoch: 18/30 | Batch: 48/129 (38.0%) | Loss: 0.0617 | Batch time: 0.04s
2025-03-02 21:39:11,502 - INFO - [VAL] Epoch: 18/30 | Batch: 60/129 (47.3%) | Loss: 0.0016 | Batch time: 0.04s
2025-03-02 21:39:11,940 - INFO - [VAL] Epoch: 18/30 | Batch: 72/129 (56.6%) | Loss: 0.0022 | Batch time: 0.04s
2025-03-02 21:39:12,378 - INFO - [VAL] Epoch: 18/30 | Batch: 84/129 (65.9%) | Loss: 0.0144 | Batch time: 0.04s
2025-03-02 21:39:12,817 - INFO - [VAL] Epoch: 18/30 | Batch: 96/129 (75.2%) | Loss: 0.0057 | Batch time: 0.04s
2025-03-02 21:39:13,266 - INFO - [VAL] Epoch: 18/30 | Batch: 108/129 (84.5%) | Loss: 0.0027 | Batch time: 0.04s
2025-03-02 21:39:13,719 - INFO - [VAL] Epoch: 18/30 | Batch: 120/129 (93.8%) | Loss: 0.0073 | Batch time: 0.04s
2025-03-02 21:39:14,016 - INFO - [VAL] Epoch: 18/30 | Batch: 128/129 (100.0%) | Loss: 0.0088 | Batch time: 0.04s
2025-03-02 21:39:14,718 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 18)
2025-03-02 21:39:14,718 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:39:14,718 - INFO - Epoch 18/30 completed in 86.05s
2025-03-02 21:39:14,718 - INFO - Training   - Loss: 0.2004, Accuracy: 0.9327, F1: 0.9328
2025-03-02 21:39:14,718 - INFO - Validation - Loss: 0.0359, Accuracy: 0.9835, F1: 0.9836
2025-03-02 21:39:14,718 - INFO - Validation F1 improved from 0.9829 to 0.9836
2025-03-02 21:39:14,718 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:39:14,718 - INFO - Epoch 19/30
2025-03-02 21:39:14,718 - INFO - ----------------------------------------
2025-03-02 21:39:15,041 - INFO - [TRAIN] Epoch: 19/30 | Batch: 0/602 (0.2%) | Loss: 0.1746 | Batch time: 0.15s
2025-03-02 21:39:23,114 - INFO - [TRAIN] Epoch: 19/30 | Batch: 60/602 (10.1%) | Loss: 0.3135 | Batch time: 0.14s
2025-03-02 21:39:31,170 - INFO - [TRAIN] Epoch: 19/30 | Batch: 120/602 (20.1%) | Loss: 0.0636 | Batch time: 0.13s
2025-03-02 21:39:39,221 - INFO - [TRAIN] Epoch: 19/30 | Batch: 180/602 (30.1%) | Loss: 0.2142 | Batch time: 0.13s
2025-03-02 21:39:47,310 - INFO - [TRAIN] Epoch: 19/30 | Batch: 240/602 (40.0%) | Loss: 0.1949 | Batch time: 0.13s
2025-03-02 21:39:55,319 - INFO - [TRAIN] Epoch: 19/30 | Batch: 300/602 (50.0%) | Loss: 0.2154 | Batch time: 0.13s
2025-03-02 21:40:03,586 - INFO - [TRAIN] Epoch: 19/30 | Batch: 360/602 (60.0%) | Loss: 0.1605 | Batch time: 0.14s
2025-03-02 21:40:11,914 - INFO - [TRAIN] Epoch: 19/30 | Batch: 420/602 (69.9%) | Loss: 0.1026 | Batch time: 0.13s
2025-03-02 21:40:19,951 - INFO - [TRAIN] Epoch: 19/30 | Batch: 480/602 (79.9%) | Loss: 0.1002 | Batch time: 0.13s
2025-03-02 21:40:27,977 - INFO - [TRAIN] Epoch: 19/30 | Batch: 540/602 (89.9%) | Loss: 0.1949 | Batch time: 0.14s
2025-03-02 21:40:35,955 - INFO - [TRAIN] Epoch: 19/30 | Batch: 600/602 (99.8%) | Loss: 0.2965 | Batch time: 0.13s
2025-03-02 21:40:36,076 - INFO - [TRAIN] Epoch: 19/30 | Batch: 601/602 (100.0%) | Loss: 0.1778 | Batch time: 0.12s
2025-03-02 21:40:36,164 - INFO - [VAL] Epoch: 19/30 | Batch: 0/129 (0.8%) | Loss: 0.0022 | Batch time: 0.04s
2025-03-02 21:40:36,573 - INFO - [VAL] Epoch: 19/30 | Batch: 12/129 (10.1%) | Loss: 0.0013 | Batch time: 0.03s
2025-03-02 21:40:36,999 - INFO - [VAL] Epoch: 19/30 | Batch: 24/129 (19.4%) | Loss: 0.1152 | Batch time: 0.04s
2025-03-02 21:40:37,432 - INFO - [VAL] Epoch: 19/30 | Batch: 36/129 (28.7%) | Loss: 0.0095 | Batch time: 0.04s
2025-03-02 21:40:37,881 - INFO - [VAL] Epoch: 19/30 | Batch: 48/129 (38.0%) | Loss: 0.0491 | Batch time: 0.04s
2025-03-02 21:40:38,335 - INFO - [VAL] Epoch: 19/30 | Batch: 60/129 (47.3%) | Loss: 0.0018 | Batch time: 0.04s
2025-03-02 21:40:38,777 - INFO - [VAL] Epoch: 19/30 | Batch: 72/129 (56.6%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:40:39,216 - INFO - [VAL] Epoch: 19/30 | Batch: 84/129 (65.9%) | Loss: 0.0121 | Batch time: 0.04s
2025-03-02 21:40:39,669 - INFO - [VAL] Epoch: 19/30 | Batch: 96/129 (75.2%) | Loss: 0.0079 | Batch time: 0.04s
2025-03-02 21:40:40,114 - INFO - [VAL] Epoch: 19/30 | Batch: 108/129 (84.5%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:40:40,551 - INFO - [VAL] Epoch: 19/30 | Batch: 120/129 (93.8%) | Loss: 0.0095 | Batch time: 0.04s
2025-03-02 21:40:40,839 - INFO - [VAL] Epoch: 19/30 | Batch: 128/129 (100.0%) | Loss: 0.0055 | Batch time: 0.04s
2025-03-02 21:40:41,484 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 19)
2025-03-02 21:40:41,484 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:40:41,484 - INFO - Epoch 19/30 completed in 86.77s
2025-03-02 21:40:41,484 - INFO - Training   - Loss: 0.1992, Accuracy: 0.9324, F1: 0.9325
2025-03-02 21:40:41,484 - INFO - Validation - Loss: 0.0346, Accuracy: 0.9848, F1: 0.9849
2025-03-02 21:40:41,484 - INFO - Validation F1 improved from 0.9836 to 0.9849
2025-03-02 21:40:41,484 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:40:41,484 - INFO - Epoch 20/30
2025-03-02 21:40:41,484 - INFO - ----------------------------------------
2025-03-02 21:40:41,827 - INFO - [TRAIN] Epoch: 20/30 | Batch: 0/602 (0.2%) | Loss: 0.2517 | Batch time: 0.16s
2025-03-02 21:40:49,740 - INFO - [TRAIN] Epoch: 20/30 | Batch: 60/602 (10.1%) | Loss: 0.3304 | Batch time: 0.13s
2025-03-02 21:40:57,900 - INFO - [TRAIN] Epoch: 20/30 | Batch: 120/602 (20.1%) | Loss: 0.7142 | Batch time: 0.13s
2025-03-02 21:41:05,870 - INFO - [TRAIN] Epoch: 20/30 | Batch: 180/602 (30.1%) | Loss: 0.0347 | Batch time: 0.13s
2025-03-02 21:41:13,851 - INFO - [TRAIN] Epoch: 20/30 | Batch: 240/602 (40.0%) | Loss: 0.1489 | Batch time: 0.13s
2025-03-02 21:41:21,870 - INFO - [TRAIN] Epoch: 20/30 | Batch: 300/602 (50.0%) | Loss: 0.2015 | Batch time: 0.13s
2025-03-02 21:41:29,939 - INFO - [TRAIN] Epoch: 20/30 | Batch: 360/602 (60.0%) | Loss: 0.0717 | Batch time: 0.14s
2025-03-02 21:41:37,983 - INFO - [TRAIN] Epoch: 20/30 | Batch: 420/602 (69.9%) | Loss: 0.2106 | Batch time: 0.13s
2025-03-02 21:41:46,083 - INFO - [TRAIN] Epoch: 20/30 | Batch: 480/602 (79.9%) | Loss: 0.3521 | Batch time: 0.14s
2025-03-02 21:41:54,123 - INFO - [TRAIN] Epoch: 20/30 | Batch: 540/602 (89.9%) | Loss: 0.3483 | Batch time: 0.13s
2025-03-02 21:42:02,071 - INFO - [TRAIN] Epoch: 20/30 | Batch: 600/602 (99.8%) | Loss: 0.0495 | Batch time: 0.13s
2025-03-02 21:42:02,192 - INFO - [TRAIN] Epoch: 20/30 | Batch: 601/602 (100.0%) | Loss: 0.2263 | Batch time: 0.12s
2025-03-02 21:42:02,277 - INFO - [VAL] Epoch: 20/30 | Batch: 0/129 (0.8%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:42:02,690 - INFO - [VAL] Epoch: 20/30 | Batch: 12/129 (10.1%) | Loss: 0.0019 | Batch time: 0.03s
2025-03-02 21:42:03,116 - INFO - [VAL] Epoch: 20/30 | Batch: 24/129 (19.4%) | Loss: 0.0802 | Batch time: 0.04s
2025-03-02 21:42:03,552 - INFO - [VAL] Epoch: 20/30 | Batch: 36/129 (28.7%) | Loss: 0.0160 | Batch time: 0.04s
2025-03-02 21:42:03,995 - INFO - [VAL] Epoch: 20/30 | Batch: 48/129 (38.0%) | Loss: 0.0539 | Batch time: 0.04s
2025-03-02 21:42:04,443 - INFO - [VAL] Epoch: 20/30 | Batch: 60/129 (47.3%) | Loss: 0.0017 | Batch time: 0.04s
2025-03-02 21:42:04,887 - INFO - [VAL] Epoch: 20/30 | Batch: 72/129 (56.6%) | Loss: 0.0068 | Batch time: 0.04s
2025-03-02 21:42:05,329 - INFO - [VAL] Epoch: 20/30 | Batch: 84/129 (65.9%) | Loss: 0.0062 | Batch time: 0.04s
2025-03-02 21:42:05,774 - INFO - [VAL] Epoch: 20/30 | Batch: 96/129 (75.2%) | Loss: 0.0099 | Batch time: 0.04s
2025-03-02 21:42:06,222 - INFO - [VAL] Epoch: 20/30 | Batch: 108/129 (84.5%) | Loss: 0.0024 | Batch time: 0.04s
2025-03-02 21:42:06,662 - INFO - [VAL] Epoch: 20/30 | Batch: 120/129 (93.8%) | Loss: 0.0081 | Batch time: 0.04s
2025-03-02 21:42:06,952 - INFO - [VAL] Epoch: 20/30 | Batch: 128/129 (100.0%) | Loss: 0.0043 | Batch time: 0.04s
2025-03-02 21:42:06,956 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:42:06,956 - INFO - Epoch 20/30 completed in 85.47s
2025-03-02 21:42:06,956 - INFO - Training   - Loss: 0.1957, Accuracy: 0.9357, F1: 0.9358
2025-03-02 21:42:06,956 - INFO - Validation - Loss: 0.0374, Accuracy: 0.9813, F1: 0.9813
2025-03-02 21:42:06,956 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:42:07,400 - INFO - Checkpoint saved: checkpoint_epoch_20.pth (Epoch 20)
2025-03-02 21:42:07,400 - INFO - Epoch 21/30
2025-03-02 21:42:07,400 - INFO - ----------------------------------------
2025-03-02 21:42:07,711 - INFO - [TRAIN] Epoch: 21/30 | Batch: 0/602 (0.2%) | Loss: 0.3232 | Batch time: 0.16s
2025-03-02 21:42:15,704 - INFO - [TRAIN] Epoch: 21/30 | Batch: 60/602 (10.1%) | Loss: 0.1745 | Batch time: 0.13s
2025-03-02 21:42:23,758 - INFO - [TRAIN] Epoch: 21/30 | Batch: 120/602 (20.1%) | Loss: 0.3788 | Batch time: 0.13s
2025-03-02 21:42:31,715 - INFO - [TRAIN] Epoch: 21/30 | Batch: 180/602 (30.1%) | Loss: 0.3076 | Batch time: 0.13s
2025-03-02 21:42:39,692 - INFO - [TRAIN] Epoch: 21/30 | Batch: 240/602 (40.0%) | Loss: 0.1780 | Batch time: 0.13s
2025-03-02 21:42:47,649 - INFO - [TRAIN] Epoch: 21/30 | Batch: 300/602 (50.0%) | Loss: 0.1370 | Batch time: 0.13s
2025-03-02 21:42:55,603 - INFO - [TRAIN] Epoch: 21/30 | Batch: 360/602 (60.0%) | Loss: 0.2650 | Batch time: 0.13s
2025-03-02 21:43:03,574 - INFO - [TRAIN] Epoch: 21/30 | Batch: 420/602 (69.9%) | Loss: 0.0731 | Batch time: 0.13s
2025-03-02 21:43:11,535 - INFO - [TRAIN] Epoch: 21/30 | Batch: 480/602 (79.9%) | Loss: 0.1895 | Batch time: 0.13s
2025-03-02 21:43:19,545 - INFO - [TRAIN] Epoch: 21/30 | Batch: 540/602 (89.9%) | Loss: 0.3396 | Batch time: 0.13s
2025-03-02 21:43:27,440 - INFO - [TRAIN] Epoch: 21/30 | Batch: 600/602 (99.8%) | Loss: 0.1831 | Batch time: 0.13s
2025-03-02 21:43:27,560 - INFO - [TRAIN] Epoch: 21/30 | Batch: 601/602 (100.0%) | Loss: 0.0613 | Batch time: 0.12s
2025-03-02 21:43:27,649 - INFO - [VAL] Epoch: 21/30 | Batch: 0/129 (0.8%) | Loss: 0.0020 | Batch time: 0.04s
2025-03-02 21:43:28,054 - INFO - [VAL] Epoch: 21/30 | Batch: 12/129 (10.1%) | Loss: 0.0020 | Batch time: 0.03s
2025-03-02 21:43:28,471 - INFO - [VAL] Epoch: 21/30 | Batch: 24/129 (19.4%) | Loss: 0.0694 | Batch time: 0.03s
2025-03-02 21:43:28,900 - INFO - [VAL] Epoch: 21/30 | Batch: 36/129 (28.7%) | Loss: 0.0105 | Batch time: 0.04s
2025-03-02 21:43:29,335 - INFO - [VAL] Epoch: 21/30 | Batch: 48/129 (38.0%) | Loss: 0.0259 | Batch time: 0.04s
2025-03-02 21:43:29,770 - INFO - [VAL] Epoch: 21/30 | Batch: 60/129 (47.3%) | Loss: 0.0010 | Batch time: 0.04s
2025-03-02 21:43:30,205 - INFO - [VAL] Epoch: 21/30 | Batch: 72/129 (56.6%) | Loss: 0.0035 | Batch time: 0.04s
2025-03-02 21:43:30,640 - INFO - [VAL] Epoch: 21/30 | Batch: 84/129 (65.9%) | Loss: 0.0078 | Batch time: 0.04s
2025-03-02 21:43:31,073 - INFO - [VAL] Epoch: 21/30 | Batch: 96/129 (75.2%) | Loss: 0.0067 | Batch time: 0.04s
2025-03-02 21:43:31,507 - INFO - [VAL] Epoch: 21/30 | Batch: 108/129 (84.5%) | Loss: 0.0015 | Batch time: 0.04s
2025-03-02 21:43:31,938 - INFO - [VAL] Epoch: 21/30 | Batch: 120/129 (93.8%) | Loss: 0.0068 | Batch time: 0.04s
2025-03-02 21:43:32,223 - INFO - [VAL] Epoch: 21/30 | Batch: 128/129 (100.0%) | Loss: 0.0048 | Batch time: 0.03s
2025-03-02 21:43:32,226 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:43:32,226 - INFO - Epoch 21/30 completed in 84.83s
2025-03-02 21:43:32,226 - INFO - Training   - Loss: 0.2009, Accuracy: 0.9308, F1: 0.9310
2025-03-02 21:43:32,226 - INFO - Validation - Loss: 0.0355, Accuracy: 0.9832, F1: 0.9832
2025-03-02 21:43:32,226 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:43:32,226 - INFO - Epoch 22/30
2025-03-02 21:43:32,226 - INFO - ----------------------------------------
2025-03-02 21:43:32,518 - INFO - [TRAIN] Epoch: 22/30 | Batch: 0/602 (0.2%) | Loss: 0.0842 | Batch time: 0.15s
2025-03-02 21:43:40,449 - INFO - [TRAIN] Epoch: 22/30 | Batch: 60/602 (10.1%) | Loss: 0.5260 | Batch time: 0.13s
2025-03-02 21:43:48,444 - INFO - [TRAIN] Epoch: 22/30 | Batch: 120/602 (20.1%) | Loss: 0.0725 | Batch time: 0.13s
2025-03-02 21:43:56,516 - INFO - [TRAIN] Epoch: 22/30 | Batch: 180/602 (30.1%) | Loss: 0.1432 | Batch time: 0.14s
2025-03-02 21:44:04,712 - INFO - [TRAIN] Epoch: 22/30 | Batch: 240/602 (40.0%) | Loss: 0.0924 | Batch time: 0.14s
2025-03-02 21:44:12,683 - INFO - [TRAIN] Epoch: 22/30 | Batch: 300/602 (50.0%) | Loss: 0.1744 | Batch time: 0.13s
2025-03-02 21:44:20,652 - INFO - [TRAIN] Epoch: 22/30 | Batch: 360/602 (60.0%) | Loss: 0.0845 | Batch time: 0.13s
2025-03-02 21:44:28,603 - INFO - [TRAIN] Epoch: 22/30 | Batch: 420/602 (69.9%) | Loss: 0.2130 | Batch time: 0.13s
2025-03-02 21:44:36,550 - INFO - [TRAIN] Epoch: 22/30 | Batch: 480/602 (79.9%) | Loss: 0.0701 | Batch time: 0.13s
2025-03-02 21:44:44,459 - INFO - [TRAIN] Epoch: 22/30 | Batch: 540/602 (89.9%) | Loss: 0.2737 | Batch time: 0.13s
2025-03-02 21:44:52,383 - INFO - [TRAIN] Epoch: 22/30 | Batch: 600/602 (99.8%) | Loss: 0.1417 | Batch time: 0.13s
2025-03-02 21:44:52,505 - INFO - [TRAIN] Epoch: 22/30 | Batch: 601/602 (100.0%) | Loss: 0.1267 | Batch time: 0.12s
2025-03-02 21:44:52,598 - INFO - [VAL] Epoch: 22/30 | Batch: 0/129 (0.8%) | Loss: 0.0016 | Batch time: 0.04s
2025-03-02 21:44:53,010 - INFO - [VAL] Epoch: 22/30 | Batch: 12/129 (10.1%) | Loss: 0.0018 | Batch time: 0.03s
2025-03-02 21:44:53,437 - INFO - [VAL] Epoch: 22/30 | Batch: 24/129 (19.4%) | Loss: 0.0568 | Batch time: 0.04s
2025-03-02 21:44:53,872 - INFO - [VAL] Epoch: 22/30 | Batch: 36/129 (28.7%) | Loss: 0.0075 | Batch time: 0.04s
2025-03-02 21:44:54,310 - INFO - [VAL] Epoch: 22/30 | Batch: 48/129 (38.0%) | Loss: 0.0129 | Batch time: 0.04s
2025-03-02 21:44:54,750 - INFO - [VAL] Epoch: 22/30 | Batch: 60/129 (47.3%) | Loss: 0.0008 | Batch time: 0.04s
2025-03-02 21:44:55,187 - INFO - [VAL] Epoch: 22/30 | Batch: 72/129 (56.6%) | Loss: 0.0046 | Batch time: 0.04s
2025-03-02 21:44:55,624 - INFO - [VAL] Epoch: 22/30 | Batch: 84/129 (65.9%) | Loss: 0.0034 | Batch time: 0.04s
2025-03-02 21:44:56,060 - INFO - [VAL] Epoch: 22/30 | Batch: 96/129 (75.2%) | Loss: 0.0056 | Batch time: 0.04s
2025-03-02 21:44:56,495 - INFO - [VAL] Epoch: 22/30 | Batch: 108/129 (84.5%) | Loss: 0.0023 | Batch time: 0.04s
2025-03-02 21:44:56,923 - INFO - [VAL] Epoch: 22/30 | Batch: 120/129 (93.8%) | Loss: 0.0060 | Batch time: 0.04s
2025-03-02 21:44:57,206 - INFO - [VAL] Epoch: 22/30 | Batch: 128/129 (100.0%) | Loss: 0.0030 | Batch time: 0.03s
2025-03-02 21:44:57,209 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:44:57,210 - INFO - Epoch 22/30 completed in 84.98s
2025-03-02 21:44:57,210 - INFO - Training   - Loss: 0.1890, Accuracy: 0.9391, F1: 0.9393
2025-03-02 21:44:57,210 - INFO - Validation - Loss: 0.0345, Accuracy: 0.9845, F1: 0.9845
2025-03-02 21:44:57,210 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:44:57,210 - INFO - Epoch 23/30
2025-03-02 21:44:57,210 - INFO - ----------------------------------------
2025-03-02 21:44:57,505 - INFO - [TRAIN] Epoch: 23/30 | Batch: 0/602 (0.2%) | Loss: 0.2782 | Batch time: 0.15s
2025-03-02 21:45:05,600 - INFO - [TRAIN] Epoch: 23/30 | Batch: 60/602 (10.1%) | Loss: 0.0783 | Batch time: 0.13s
2025-03-02 21:45:13,596 - INFO - [TRAIN] Epoch: 23/30 | Batch: 120/602 (20.1%) | Loss: 0.0817 | Batch time: 0.13s
2025-03-02 21:45:21,720 - INFO - [TRAIN] Epoch: 23/30 | Batch: 180/602 (30.1%) | Loss: 0.1377 | Batch time: 0.13s
2025-03-02 21:45:29,735 - INFO - [TRAIN] Epoch: 23/30 | Batch: 240/602 (40.0%) | Loss: 0.1544 | Batch time: 0.13s
2025-03-02 21:45:37,745 - INFO - [TRAIN] Epoch: 23/30 | Batch: 300/602 (50.0%) | Loss: 0.0956 | Batch time: 0.13s
2025-03-02 21:45:45,759 - INFO - [TRAIN] Epoch: 23/30 | Batch: 360/602 (60.0%) | Loss: 0.1692 | Batch time: 0.13s
2025-03-02 21:45:53,773 - INFO - [TRAIN] Epoch: 23/30 | Batch: 420/602 (69.9%) | Loss: 0.2050 | Batch time: 0.13s
2025-03-02 21:46:01,766 - INFO - [TRAIN] Epoch: 23/30 | Batch: 480/602 (79.9%) | Loss: 0.1438 | Batch time: 0.13s
2025-03-02 21:46:09,743 - INFO - [TRAIN] Epoch: 23/30 | Batch: 540/602 (89.9%) | Loss: 0.1178 | Batch time: 0.14s
2025-03-02 21:46:17,663 - INFO - [TRAIN] Epoch: 23/30 | Batch: 600/602 (99.8%) | Loss: 0.0582 | Batch time: 0.13s
2025-03-02 21:46:17,784 - INFO - [TRAIN] Epoch: 23/30 | Batch: 601/602 (100.0%) | Loss: 0.0968 | Batch time: 0.12s
2025-03-02 21:46:17,875 - INFO - [VAL] Epoch: 23/30 | Batch: 0/129 (0.8%) | Loss: 0.0021 | Batch time: 0.03s
2025-03-02 21:46:18,274 - INFO - [VAL] Epoch: 23/30 | Batch: 12/129 (10.1%) | Loss: 0.0021 | Batch time: 0.03s
2025-03-02 21:46:18,690 - INFO - [VAL] Epoch: 23/30 | Batch: 24/129 (19.4%) | Loss: 0.1001 | Batch time: 0.03s
2025-03-02 21:46:19,115 - INFO - [VAL] Epoch: 23/30 | Batch: 36/129 (28.7%) | Loss: 0.0073 | Batch time: 0.04s
2025-03-02 21:46:19,547 - INFO - [VAL] Epoch: 23/30 | Batch: 48/129 (38.0%) | Loss: 0.0226 | Batch time: 0.04s
2025-03-02 21:46:19,978 - INFO - [VAL] Epoch: 23/30 | Batch: 60/129 (47.3%) | Loss: 0.0012 | Batch time: 0.04s
2025-03-02 21:46:20,410 - INFO - [VAL] Epoch: 23/30 | Batch: 72/129 (56.6%) | Loss: 0.0037 | Batch time: 0.04s
2025-03-02 21:46:20,843 - INFO - [VAL] Epoch: 23/30 | Batch: 84/129 (65.9%) | Loss: 0.0046 | Batch time: 0.04s
2025-03-02 21:46:21,274 - INFO - [VAL] Epoch: 23/30 | Batch: 96/129 (75.2%) | Loss: 0.0050 | Batch time: 0.04s
2025-03-02 21:46:21,706 - INFO - [VAL] Epoch: 23/30 | Batch: 108/129 (84.5%) | Loss: 0.0014 | Batch time: 0.04s
2025-03-02 21:46:22,132 - INFO - [VAL] Epoch: 23/30 | Batch: 120/129 (93.8%) | Loss: 0.0041 | Batch time: 0.03s
2025-03-02 21:46:22,412 - INFO - [VAL] Epoch: 23/30 | Batch: 128/129 (100.0%) | Loss: 0.0032 | Batch time: 0.03s
2025-03-02 21:46:22,415 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:46:22,415 - INFO - Epoch 23/30 completed in 85.21s
2025-03-02 21:46:22,415 - INFO - Training   - Loss: 0.2038, Accuracy: 0.9308, F1: 0.9312
2025-03-02 21:46:22,415 - INFO - Validation - Loss: 0.0355, Accuracy: 0.9826, F1: 0.9826
2025-03-02 21:46:22,415 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:46:22,415 - INFO - Epoch 24/30
2025-03-02 21:46:22,415 - INFO - ----------------------------------------
2025-03-02 21:46:22,706 - INFO - [TRAIN] Epoch: 24/30 | Batch: 0/602 (0.2%) | Loss: 0.3989 | Batch time: 0.15s
2025-03-02 21:46:30,588 - INFO - [TRAIN] Epoch: 24/30 | Batch: 60/602 (10.1%) | Loss: 0.1536 | Batch time: 0.13s
2025-03-02 21:46:38,493 - INFO - [TRAIN] Epoch: 24/30 | Batch: 120/602 (20.1%) | Loss: 0.2564 | Batch time: 0.13s
2025-03-02 21:46:46,392 - INFO - [TRAIN] Epoch: 24/30 | Batch: 180/602 (30.1%) | Loss: 0.0680 | Batch time: 0.13s
2025-03-02 21:46:54,343 - INFO - [TRAIN] Epoch: 24/30 | Batch: 240/602 (40.0%) | Loss: 0.2176 | Batch time: 0.13s
2025-03-02 21:47:02,245 - INFO - [TRAIN] Epoch: 24/30 | Batch: 300/602 (50.0%) | Loss: 0.6873 | Batch time: 0.13s
2025-03-02 21:47:10,176 - INFO - [TRAIN] Epoch: 24/30 | Batch: 360/602 (60.0%) | Loss: 0.0177 | Batch time: 0.13s
2025-03-02 21:47:18,248 - INFO - [TRAIN] Epoch: 24/30 | Batch: 420/602 (69.9%) | Loss: 0.0831 | Batch time: 0.13s
2025-03-02 21:47:26,183 - INFO - [TRAIN] Epoch: 24/30 | Batch: 480/602 (79.9%) | Loss: 0.7943 | Batch time: 0.13s
2025-03-02 21:47:34,148 - INFO - [TRAIN] Epoch: 24/30 | Batch: 540/602 (89.9%) | Loss: 0.4239 | Batch time: 0.13s
2025-03-02 21:47:42,030 - INFO - [TRAIN] Epoch: 24/30 | Batch: 600/602 (99.8%) | Loss: 0.0802 | Batch time: 0.13s
2025-03-02 21:47:42,150 - INFO - [TRAIN] Epoch: 24/30 | Batch: 601/602 (100.0%) | Loss: 0.2852 | Batch time: 0.12s
2025-03-02 21:47:42,226 - INFO - [VAL] Epoch: 24/30 | Batch: 0/129 (0.8%) | Loss: 0.0017 | Batch time: 0.04s
2025-03-02 21:47:42,629 - INFO - [VAL] Epoch: 24/30 | Batch: 12/129 (10.1%) | Loss: 0.0019 | Batch time: 0.03s
2025-03-02 21:47:43,047 - INFO - [VAL] Epoch: 24/30 | Batch: 24/129 (19.4%) | Loss: 0.0775 | Batch time: 0.03s
2025-03-02 21:47:43,476 - INFO - [VAL] Epoch: 24/30 | Batch: 36/129 (28.7%) | Loss: 0.0081 | Batch time: 0.04s
2025-03-02 21:47:43,908 - INFO - [VAL] Epoch: 24/30 | Batch: 48/129 (38.0%) | Loss: 0.0313 | Batch time: 0.04s
2025-03-02 21:47:44,339 - INFO - [VAL] Epoch: 24/30 | Batch: 60/129 (47.3%) | Loss: 0.0016 | Batch time: 0.04s
2025-03-02 21:47:44,772 - INFO - [VAL] Epoch: 24/30 | Batch: 72/129 (56.6%) | Loss: 0.0039 | Batch time: 0.04s
2025-03-02 21:47:45,202 - INFO - [VAL] Epoch: 24/30 | Batch: 84/129 (65.9%) | Loss: 0.0042 | Batch time: 0.04s
2025-03-02 21:47:45,633 - INFO - [VAL] Epoch: 24/30 | Batch: 96/129 (75.2%) | Loss: 0.0074 | Batch time: 0.04s
2025-03-02 21:47:46,063 - INFO - [VAL] Epoch: 24/30 | Batch: 108/129 (84.5%) | Loss: 0.0024 | Batch time: 0.03s
2025-03-02 21:47:46,487 - INFO - [VAL] Epoch: 24/30 | Batch: 120/129 (93.8%) | Loss: 0.0065 | Batch time: 0.03s
2025-03-02 21:47:46,768 - INFO - [VAL] Epoch: 24/30 | Batch: 128/129 (100.0%) | Loss: 0.0035 | Batch time: 0.03s
2025-03-02 21:47:46,772 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:47:46,772 - INFO - Epoch 24/30 completed in 84.36s
2025-03-02 21:47:46,772 - INFO - Training   - Loss: 0.2095, Accuracy: 0.9305, F1: 0.9307
2025-03-02 21:47:46,772 - INFO - Validation - Loss: 0.0347, Accuracy: 0.9842, F1: 0.9842
2025-03-02 21:47:46,772 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:47:46,772 - INFO - Epoch 25/30
2025-03-02 21:47:46,772 - INFO - ----------------------------------------
2025-03-02 21:47:47,067 - INFO - [TRAIN] Epoch: 25/30 | Batch: 0/602 (0.2%) | Loss: 0.2314 | Batch time: 0.14s
2025-03-02 21:47:54,983 - INFO - [TRAIN] Epoch: 25/30 | Batch: 60/602 (10.1%) | Loss: 0.1524 | Batch time: 0.13s
2025-03-02 21:48:02,911 - INFO - [TRAIN] Epoch: 25/30 | Batch: 120/602 (20.1%) | Loss: 0.3775 | Batch time: 0.13s
2025-03-02 21:48:10,875 - INFO - [TRAIN] Epoch: 25/30 | Batch: 180/602 (30.1%) | Loss: 0.3691 | Batch time: 0.13s
2025-03-02 21:48:18,816 - INFO - [TRAIN] Epoch: 25/30 | Batch: 240/602 (40.0%) | Loss: 0.1553 | Batch time: 0.13s
2025-03-02 21:48:26,772 - INFO - [TRAIN] Epoch: 25/30 | Batch: 300/602 (50.0%) | Loss: 0.8041 | Batch time: 0.13s
2025-03-02 21:48:34,813 - INFO - [TRAIN] Epoch: 25/30 | Batch: 360/602 (60.0%) | Loss: 0.2351 | Batch time: 0.13s
2025-03-02 21:48:43,154 - INFO - [TRAIN] Epoch: 25/30 | Batch: 420/602 (69.9%) | Loss: 0.0823 | Batch time: 0.13s
2025-03-02 21:48:51,208 - INFO - [TRAIN] Epoch: 25/30 | Batch: 480/602 (79.9%) | Loss: 0.1998 | Batch time: 0.13s
2025-03-02 21:48:59,260 - INFO - [TRAIN] Epoch: 25/30 | Batch: 540/602 (89.9%) | Loss: 0.0460 | Batch time: 0.13s
2025-03-02 21:49:07,201 - INFO - [TRAIN] Epoch: 25/30 | Batch: 600/602 (99.8%) | Loss: 0.0815 | Batch time: 0.13s
2025-03-02 21:49:07,323 - INFO - [TRAIN] Epoch: 25/30 | Batch: 601/602 (100.0%) | Loss: 0.1130 | Batch time: 0.12s
2025-03-02 21:49:07,416 - INFO - [VAL] Epoch: 25/30 | Batch: 0/129 (0.8%) | Loss: 0.0016 | Batch time: 0.04s
2025-03-02 21:49:07,827 - INFO - [VAL] Epoch: 25/30 | Batch: 12/129 (10.1%) | Loss: 0.0015 | Batch time: 0.03s
2025-03-02 21:49:08,254 - INFO - [VAL] Epoch: 25/30 | Batch: 24/129 (19.4%) | Loss: 0.0817 | Batch time: 0.04s
2025-03-02 21:49:08,690 - INFO - [VAL] Epoch: 25/30 | Batch: 36/129 (28.7%) | Loss: 0.0070 | Batch time: 0.04s
2025-03-02 21:49:09,130 - INFO - [VAL] Epoch: 25/30 | Batch: 48/129 (38.0%) | Loss: 0.0284 | Batch time: 0.04s
2025-03-02 21:49:09,571 - INFO - [VAL] Epoch: 25/30 | Batch: 60/129 (47.3%) | Loss: 0.0012 | Batch time: 0.04s
2025-03-02 21:49:10,012 - INFO - [VAL] Epoch: 25/30 | Batch: 72/129 (56.6%) | Loss: 0.0024 | Batch time: 0.04s
2025-03-02 21:49:10,451 - INFO - [VAL] Epoch: 25/30 | Batch: 84/129 (65.9%) | Loss: 0.0061 | Batch time: 0.04s
2025-03-02 21:49:10,888 - INFO - [VAL] Epoch: 25/30 | Batch: 96/129 (75.2%) | Loss: 0.0089 | Batch time: 0.04s
2025-03-02 21:49:11,326 - INFO - [VAL] Epoch: 25/30 | Batch: 108/129 (84.5%) | Loss: 0.0016 | Batch time: 0.04s
2025-03-02 21:49:11,754 - INFO - [VAL] Epoch: 25/30 | Batch: 120/129 (93.8%) | Loss: 0.0065 | Batch time: 0.03s
2025-03-02 21:49:12,039 - INFO - [VAL] Epoch: 25/30 | Batch: 128/129 (100.0%) | Loss: 0.0047 | Batch time: 0.04s
2025-03-02 21:49:12,043 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:49:12,043 - INFO - Epoch 25/30 completed in 85.27s
2025-03-02 21:49:12,043 - INFO - Training   - Loss: 0.2069, Accuracy: 0.9318, F1: 0.9321
2025-03-02 21:49:12,043 - INFO - Validation - Loss: 0.0341, Accuracy: 0.9835, F1: 0.9836
2025-03-02 21:49:12,043 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:49:12,480 - INFO - Checkpoint saved: checkpoint_epoch_25.pth (Epoch 25)
2025-03-02 21:49:12,480 - INFO - Epoch 26/30
2025-03-02 21:49:12,480 - INFO - ----------------------------------------
2025-03-02 21:49:12,786 - INFO - [TRAIN] Epoch: 26/30 | Batch: 0/602 (0.2%) | Loss: 0.5249 | Batch time: 0.15s
2025-03-02 21:49:20,891 - INFO - [TRAIN] Epoch: 26/30 | Batch: 60/602 (10.1%) | Loss: 0.1231 | Batch time: 0.14s
2025-03-02 21:49:28,852 - INFO - [TRAIN] Epoch: 26/30 | Batch: 120/602 (20.1%) | Loss: 0.1654 | Batch time: 0.13s
2025-03-02 21:49:36,812 - INFO - [TRAIN] Epoch: 26/30 | Batch: 180/602 (30.1%) | Loss: 0.1548 | Batch time: 0.13s
2025-03-02 21:49:44,768 - INFO - [TRAIN] Epoch: 26/30 | Batch: 240/602 (40.0%) | Loss: 0.5898 | Batch time: 0.13s
2025-03-02 21:49:52,725 - INFO - [TRAIN] Epoch: 26/30 | Batch: 300/602 (50.0%) | Loss: 0.1243 | Batch time: 0.13s
2025-03-02 21:50:00,683 - INFO - [TRAIN] Epoch: 26/30 | Batch: 360/602 (60.0%) | Loss: 0.0179 | Batch time: 0.13s
2025-03-02 21:50:08,638 - INFO - [TRAIN] Epoch: 26/30 | Batch: 420/602 (69.9%) | Loss: 0.2182 | Batch time: 0.13s
2025-03-02 21:50:16,659 - INFO - [TRAIN] Epoch: 26/30 | Batch: 480/602 (79.9%) | Loss: 0.1690 | Batch time: 0.13s
2025-03-02 21:50:24,741 - INFO - [TRAIN] Epoch: 26/30 | Batch: 540/602 (89.9%) | Loss: 0.1911 | Batch time: 0.13s
2025-03-02 21:50:32,772 - INFO - [TRAIN] Epoch: 26/30 | Batch: 600/602 (99.8%) | Loss: 0.0196 | Batch time: 0.13s
2025-03-02 21:50:32,894 - INFO - [TRAIN] Epoch: 26/30 | Batch: 601/602 (100.0%) | Loss: 0.0380 | Batch time: 0.12s
2025-03-02 21:50:32,984 - INFO - [VAL] Epoch: 26/30 | Batch: 0/129 (0.8%) | Loss: 0.0018 | Batch time: 0.04s
2025-03-02 21:50:33,393 - INFO - [VAL] Epoch: 26/30 | Batch: 12/129 (10.1%) | Loss: 0.0013 | Batch time: 0.03s
2025-03-02 21:50:33,813 - INFO - [VAL] Epoch: 26/30 | Batch: 24/129 (19.4%) | Loss: 0.0777 | Batch time: 0.04s
2025-03-02 21:50:34,247 - INFO - [VAL] Epoch: 26/30 | Batch: 36/129 (28.7%) | Loss: 0.0052 | Batch time: 0.04s
2025-03-02 21:50:34,692 - INFO - [VAL] Epoch: 26/30 | Batch: 48/129 (38.0%) | Loss: 0.0279 | Batch time: 0.04s
2025-03-02 21:50:35,139 - INFO - [VAL] Epoch: 26/30 | Batch: 60/129 (47.3%) | Loss: 0.0010 | Batch time: 0.04s
2025-03-02 21:50:35,581 - INFO - [VAL] Epoch: 26/30 | Batch: 72/129 (56.6%) | Loss: 0.0024 | Batch time: 0.04s
2025-03-02 21:50:36,023 - INFO - [VAL] Epoch: 26/30 | Batch: 84/129 (65.9%) | Loss: 0.0053 | Batch time: 0.04s
2025-03-02 21:50:36,468 - INFO - [VAL] Epoch: 26/30 | Batch: 96/129 (75.2%) | Loss: 0.0029 | Batch time: 0.04s
2025-03-02 21:50:36,911 - INFO - [VAL] Epoch: 26/30 | Batch: 108/129 (84.5%) | Loss: 0.0026 | Batch time: 0.04s
2025-03-02 21:50:37,363 - INFO - [VAL] Epoch: 26/30 | Batch: 120/129 (93.8%) | Loss: 0.0093 | Batch time: 0.04s
2025-03-02 21:50:37,664 - INFO - [VAL] Epoch: 26/30 | Batch: 128/129 (100.0%) | Loss: 0.0056 | Batch time: 0.04s
2025-03-02 21:50:37,668 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:50:37,668 - INFO - Epoch 26/30 completed in 85.19s
2025-03-02 21:50:37,668 - INFO - Training   - Loss: 0.1864, Accuracy: 0.9328, F1: 0.9330
2025-03-02 21:50:37,668 - INFO - Validation - Loss: 0.0338, Accuracy: 0.9832, F1: 0.9832
2025-03-02 21:50:37,668 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:50:37,668 - INFO - Epoch 27/30
2025-03-02 21:50:37,668 - INFO - ----------------------------------------
2025-03-02 21:50:38,005 - INFO - [TRAIN] Epoch: 27/30 | Batch: 0/602 (0.2%) | Loss: 0.2528 | Batch time: 0.15s
2025-03-02 21:50:46,018 - INFO - [TRAIN] Epoch: 27/30 | Batch: 60/602 (10.1%) | Loss: 0.5159 | Batch time: 0.13s
2025-03-02 21:50:54,230 - INFO - [TRAIN] Epoch: 27/30 | Batch: 120/602 (20.1%) | Loss: 0.0538 | Batch time: 0.14s
2025-03-02 21:51:02,348 - INFO - [TRAIN] Epoch: 27/30 | Batch: 180/602 (30.1%) | Loss: 0.2073 | Batch time: 0.13s
2025-03-02 21:51:10,580 - INFO - [TRAIN] Epoch: 27/30 | Batch: 240/602 (40.0%) | Loss: 0.2944 | Batch time: 0.13s
2025-03-02 21:51:18,602 - INFO - [TRAIN] Epoch: 27/30 | Batch: 300/602 (50.0%) | Loss: 0.1563 | Batch time: 0.13s
2025-03-02 21:51:26,630 - INFO - [TRAIN] Epoch: 27/30 | Batch: 360/602 (60.0%) | Loss: 0.1781 | Batch time: 0.13s
2025-03-02 21:51:34,689 - INFO - [TRAIN] Epoch: 27/30 | Batch: 420/602 (69.9%) | Loss: 0.0385 | Batch time: 0.13s
2025-03-02 21:51:42,743 - INFO - [TRAIN] Epoch: 27/30 | Batch: 480/602 (79.9%) | Loss: 0.1359 | Batch time: 0.13s
2025-03-02 21:51:50,740 - INFO - [TRAIN] Epoch: 27/30 | Batch: 540/602 (89.9%) | Loss: 0.0515 | Batch time: 0.13s
2025-03-02 21:51:58,709 - INFO - [TRAIN] Epoch: 27/30 | Batch: 600/602 (99.8%) | Loss: 0.1126 | Batch time: 0.13s
2025-03-02 21:51:58,831 - INFO - [TRAIN] Epoch: 27/30 | Batch: 601/602 (100.0%) | Loss: 0.2127 | Batch time: 0.12s
2025-03-02 21:51:58,915 - INFO - [VAL] Epoch: 27/30 | Batch: 0/129 (0.8%) | Loss: 0.0018 | Batch time: 0.04s
2025-03-02 21:51:59,324 - INFO - [VAL] Epoch: 27/30 | Batch: 12/129 (10.1%) | Loss: 0.0020 | Batch time: 0.03s
2025-03-02 21:51:59,751 - INFO - [VAL] Epoch: 27/30 | Batch: 24/129 (19.4%) | Loss: 0.0553 | Batch time: 0.04s
2025-03-02 21:52:00,189 - INFO - [VAL] Epoch: 27/30 | Batch: 36/129 (28.7%) | Loss: 0.0073 | Batch time: 0.04s
2025-03-02 21:52:00,626 - INFO - [VAL] Epoch: 27/30 | Batch: 48/129 (38.0%) | Loss: 0.0332 | Batch time: 0.04s
2025-03-02 21:52:01,064 - INFO - [VAL] Epoch: 27/30 | Batch: 60/129 (47.3%) | Loss: 0.0011 | Batch time: 0.04s
2025-03-02 21:52:01,511 - INFO - [VAL] Epoch: 27/30 | Batch: 72/129 (56.6%) | Loss: 0.0035 | Batch time: 0.04s
2025-03-02 21:52:01,956 - INFO - [VAL] Epoch: 27/30 | Batch: 84/129 (65.9%) | Loss: 0.0055 | Batch time: 0.04s
2025-03-02 21:52:02,393 - INFO - [VAL] Epoch: 27/30 | Batch: 96/129 (75.2%) | Loss: 0.0074 | Batch time: 0.04s
2025-03-02 21:52:02,830 - INFO - [VAL] Epoch: 27/30 | Batch: 108/129 (84.5%) | Loss: 0.0031 | Batch time: 0.04s
2025-03-02 21:52:03,260 - INFO - [VAL] Epoch: 27/30 | Batch: 120/129 (93.8%) | Loss: 0.0060 | Batch time: 0.04s
2025-03-02 21:52:03,545 - INFO - [VAL] Epoch: 27/30 | Batch: 128/129 (100.0%) | Loss: 0.0052 | Batch time: 0.04s
2025-03-02 21:52:03,548 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:52:03,548 - INFO - Epoch 27/30 completed in 85.88s
2025-03-02 21:52:03,548 - INFO - Training   - Loss: 0.1956, Accuracy: 0.9326, F1: 0.9328
2025-03-02 21:52:03,548 - INFO - Validation - Loss: 0.0365, Accuracy: 0.9826, F1: 0.9826
2025-03-02 21:52:03,548 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:52:03,548 - INFO - Epoch 28/30
2025-03-02 21:52:03,548 - INFO - ----------------------------------------
2025-03-02 21:52:03,851 - INFO - [TRAIN] Epoch: 28/30 | Batch: 0/602 (0.2%) | Loss: 0.0421 | Batch time: 0.15s
2025-03-02 21:52:11,879 - INFO - [TRAIN] Epoch: 28/30 | Batch: 60/602 (10.1%) | Loss: 0.1517 | Batch time: 0.13s
2025-03-02 21:52:19,948 - INFO - [TRAIN] Epoch: 28/30 | Batch: 120/602 (20.1%) | Loss: 0.1012 | Batch time: 0.14s
2025-03-02 21:52:28,225 - INFO - [TRAIN] Epoch: 28/30 | Batch: 180/602 (30.1%) | Loss: 0.3632 | Batch time: 0.13s
2025-03-02 21:52:36,167 - INFO - [TRAIN] Epoch: 28/30 | Batch: 240/602 (40.0%) | Loss: 0.0086 | Batch time: 0.13s
2025-03-02 21:52:44,153 - INFO - [TRAIN] Epoch: 28/30 | Batch: 300/602 (50.0%) | Loss: 0.0828 | Batch time: 0.13s
2025-03-02 21:52:52,247 - INFO - [TRAIN] Epoch: 28/30 | Batch: 360/602 (60.0%) | Loss: 0.0694 | Batch time: 0.13s
2025-03-02 21:53:00,308 - INFO - [TRAIN] Epoch: 28/30 | Batch: 420/602 (69.9%) | Loss: 0.0473 | Batch time: 0.13s
2025-03-02 21:53:08,296 - INFO - [TRAIN] Epoch: 28/30 | Batch: 480/602 (79.9%) | Loss: 0.0629 | Batch time: 0.13s
2025-03-02 21:53:16,351 - INFO - [TRAIN] Epoch: 28/30 | Batch: 540/602 (89.9%) | Loss: 0.1190 | Batch time: 0.13s
2025-03-02 21:53:24,291 - INFO - [TRAIN] Epoch: 28/30 | Batch: 600/602 (99.8%) | Loss: 0.0829 | Batch time: 0.13s
2025-03-02 21:53:24,412 - INFO - [TRAIN] Epoch: 28/30 | Batch: 601/602 (100.0%) | Loss: 0.1693 | Batch time: 0.12s
2025-03-02 21:53:24,501 - INFO - [VAL] Epoch: 28/30 | Batch: 0/129 (0.8%) | Loss: 0.0023 | Batch time: 0.04s
2025-03-02 21:53:24,903 - INFO - [VAL] Epoch: 28/30 | Batch: 12/129 (10.1%) | Loss: 0.0021 | Batch time: 0.03s
2025-03-02 21:53:25,323 - INFO - [VAL] Epoch: 28/30 | Batch: 24/129 (19.4%) | Loss: 0.0747 | Batch time: 0.04s
2025-03-02 21:53:25,760 - INFO - [VAL] Epoch: 28/30 | Batch: 36/129 (28.7%) | Loss: 0.0089 | Batch time: 0.04s
2025-03-02 21:53:26,208 - INFO - [VAL] Epoch: 28/30 | Batch: 48/129 (38.0%) | Loss: 0.0456 | Batch time: 0.04s
2025-03-02 21:53:26,650 - INFO - [VAL] Epoch: 28/30 | Batch: 60/129 (47.3%) | Loss: 0.0012 | Batch time: 0.04s
2025-03-02 21:53:27,091 - INFO - [VAL] Epoch: 28/30 | Batch: 72/129 (56.6%) | Loss: 0.0039 | Batch time: 0.04s
2025-03-02 21:53:27,531 - INFO - [VAL] Epoch: 28/30 | Batch: 84/129 (65.9%) | Loss: 0.0056 | Batch time: 0.04s
2025-03-02 21:53:27,969 - INFO - [VAL] Epoch: 28/30 | Batch: 96/129 (75.2%) | Loss: 0.0081 | Batch time: 0.04s
2025-03-02 21:53:28,407 - INFO - [VAL] Epoch: 28/30 | Batch: 108/129 (84.5%) | Loss: 0.0028 | Batch time: 0.04s
2025-03-02 21:53:28,839 - INFO - [VAL] Epoch: 28/30 | Batch: 120/129 (93.8%) | Loss: 0.0055 | Batch time: 0.04s
2025-03-02 21:53:29,123 - INFO - [VAL] Epoch: 28/30 | Batch: 128/129 (100.0%) | Loss: 0.0042 | Batch time: 0.03s
2025-03-02 21:53:29,127 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:53:29,127 - INFO - Epoch 28/30 completed in 85.58s
2025-03-02 21:53:29,127 - INFO - Training   - Loss: 0.1911, Accuracy: 0.9345, F1: 0.9347
2025-03-02 21:53:29,127 - INFO - Validation - Loss: 0.0369, Accuracy: 0.9819, F1: 0.9820
2025-03-02 21:53:29,127 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:53:29,127 - INFO - Epoch 29/30
2025-03-02 21:53:29,127 - INFO - ----------------------------------------
2025-03-02 21:53:29,412 - INFO - [TRAIN] Epoch: 29/30 | Batch: 0/602 (0.2%) | Loss: 0.0726 | Batch time: 0.14s
2025-03-02 21:53:37,412 - INFO - [TRAIN] Epoch: 29/30 | Batch: 60/602 (10.1%) | Loss: 0.1153 | Batch time: 0.13s
2025-03-02 21:53:45,397 - INFO - [TRAIN] Epoch: 29/30 | Batch: 120/602 (20.1%) | Loss: 0.0511 | Batch time: 0.13s
2025-03-02 21:53:53,425 - INFO - [TRAIN] Epoch: 29/30 | Batch: 180/602 (30.1%) | Loss: 0.1374 | Batch time: 0.14s
2025-03-02 21:54:01,452 - INFO - [TRAIN] Epoch: 29/30 | Batch: 240/602 (40.0%) | Loss: 0.2304 | Batch time: 0.13s
2025-03-02 21:54:09,614 - INFO - [TRAIN] Epoch: 29/30 | Batch: 300/602 (50.0%) | Loss: 0.4041 | Batch time: 0.13s
2025-03-02 21:54:17,626 - INFO - [TRAIN] Epoch: 29/30 | Batch: 360/602 (60.0%) | Loss: 0.4659 | Batch time: 0.13s
2025-03-02 21:54:25,726 - INFO - [TRAIN] Epoch: 29/30 | Batch: 420/602 (69.9%) | Loss: 0.2595 | Batch time: 0.14s
2025-03-02 21:54:33,914 - INFO - [TRAIN] Epoch: 29/30 | Batch: 480/602 (79.9%) | Loss: 0.0275 | Batch time: 0.14s
2025-03-02 21:54:42,119 - INFO - [TRAIN] Epoch: 29/30 | Batch: 540/602 (89.9%) | Loss: 0.0852 | Batch time: 0.13s
2025-03-02 21:54:50,070 - INFO - [TRAIN] Epoch: 29/30 | Batch: 600/602 (99.8%) | Loss: 0.3698 | Batch time: 0.13s
2025-03-02 21:54:50,191 - INFO - [TRAIN] Epoch: 29/30 | Batch: 601/602 (100.0%) | Loss: 0.1978 | Batch time: 0.12s
2025-03-02 21:54:50,279 - INFO - [VAL] Epoch: 29/30 | Batch: 0/129 (0.8%) | Loss: 0.0020 | Batch time: 0.04s
2025-03-02 21:54:50,697 - INFO - [VAL] Epoch: 29/30 | Batch: 12/129 (10.1%) | Loss: 0.0021 | Batch time: 0.03s
2025-03-02 21:54:51,121 - INFO - [VAL] Epoch: 29/30 | Batch: 24/129 (19.4%) | Loss: 0.0951 | Batch time: 0.04s
2025-03-02 21:54:51,558 - INFO - [VAL] Epoch: 29/30 | Batch: 36/129 (28.7%) | Loss: 0.0116 | Batch time: 0.04s
2025-03-02 21:54:52,002 - INFO - [VAL] Epoch: 29/30 | Batch: 48/129 (38.0%) | Loss: 0.0650 | Batch time: 0.04s
2025-03-02 21:54:52,448 - INFO - [VAL] Epoch: 29/30 | Batch: 60/129 (47.3%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:54:52,893 - INFO - [VAL] Epoch: 29/30 | Batch: 72/129 (56.6%) | Loss: 0.0045 | Batch time: 0.04s
2025-03-02 21:54:53,337 - INFO - [VAL] Epoch: 29/30 | Batch: 84/129 (65.9%) | Loss: 0.0050 | Batch time: 0.04s
2025-03-02 21:54:53,779 - INFO - [VAL] Epoch: 29/30 | Batch: 96/129 (75.2%) | Loss: 0.0052 | Batch time: 0.04s
2025-03-02 21:54:54,219 - INFO - [VAL] Epoch: 29/30 | Batch: 108/129 (84.5%) | Loss: 0.0029 | Batch time: 0.04s
2025-03-02 21:54:54,651 - INFO - [VAL] Epoch: 29/30 | Batch: 120/129 (93.8%) | Loss: 0.0079 | Batch time: 0.04s
2025-03-02 21:54:54,936 - INFO - [VAL] Epoch: 29/30 | Batch: 128/129 (100.0%) | Loss: 0.0035 | Batch time: 0.04s
2025-03-02 21:54:54,940 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:54:54,940 - INFO - Epoch 29/30 completed in 85.81s
2025-03-02 21:54:54,940 - INFO - Training   - Loss: 0.1976, Accuracy: 0.9344, F1: 0.9345
2025-03-02 21:54:54,940 - INFO - Validation - Loss: 0.0384, Accuracy: 0.9816, F1: 0.9816
2025-03-02 21:54:54,940 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:54:54,940 - INFO - Epoch 30/30
2025-03-02 21:54:54,940 - INFO - ----------------------------------------
2025-03-02 21:54:55,230 - INFO - [TRAIN] Epoch: 30/30 | Batch: 0/602 (0.2%) | Loss: 0.1977 | Batch time: 0.15s
2025-03-02 21:55:03,300 - INFO - [TRAIN] Epoch: 30/30 | Batch: 60/602 (10.1%) | Loss: 0.0480 | Batch time: 0.13s
2025-03-02 21:55:11,333 - INFO - [TRAIN] Epoch: 30/30 | Batch: 120/602 (20.1%) | Loss: 0.1336 | Batch time: 0.13s
2025-03-02 21:55:19,394 - INFO - [TRAIN] Epoch: 30/30 | Batch: 180/602 (30.1%) | Loss: 0.3689 | Batch time: 0.14s
2025-03-02 21:55:27,403 - INFO - [TRAIN] Epoch: 30/30 | Batch: 240/602 (40.0%) | Loss: 0.3214 | Batch time: 0.13s
2025-03-02 21:55:35,487 - INFO - [TRAIN] Epoch: 30/30 | Batch: 300/602 (50.0%) | Loss: 0.1118 | Batch time: 0.14s
2025-03-02 21:55:43,559 - INFO - [TRAIN] Epoch: 30/30 | Batch: 360/602 (60.0%) | Loss: 0.2711 | Batch time: 0.14s
2025-03-02 21:55:51,666 - INFO - [TRAIN] Epoch: 30/30 | Batch: 420/602 (69.9%) | Loss: 0.3240 | Batch time: 0.13s
2025-03-02 21:55:59,671 - INFO - [TRAIN] Epoch: 30/30 | Batch: 480/602 (79.9%) | Loss: 0.1683 | Batch time: 0.13s
2025-03-02 21:56:07,671 - INFO - [TRAIN] Epoch: 30/30 | Batch: 540/602 (89.9%) | Loss: 0.1999 | Batch time: 0.13s
2025-03-02 21:56:15,601 - INFO - [TRAIN] Epoch: 30/30 | Batch: 600/602 (99.8%) | Loss: 0.5493 | Batch time: 0.13s
2025-03-02 21:56:15,724 - INFO - [TRAIN] Epoch: 30/30 | Batch: 601/602 (100.0%) | Loss: 0.2010 | Batch time: 0.12s
2025-03-02 21:56:15,812 - INFO - [VAL] Epoch: 30/30 | Batch: 0/129 (0.8%) | Loss: 0.0023 | Batch time: 0.04s
2025-03-02 21:56:16,219 - INFO - [VAL] Epoch: 30/30 | Batch: 12/129 (10.1%) | Loss: 0.0022 | Batch time: 0.03s
2025-03-02 21:56:16,643 - INFO - [VAL] Epoch: 30/30 | Batch: 24/129 (19.4%) | Loss: 0.0908 | Batch time: 0.04s
2025-03-02 21:56:17,075 - INFO - [VAL] Epoch: 30/30 | Batch: 36/129 (28.7%) | Loss: 0.0033 | Batch time: 0.04s
2025-03-02 21:56:17,513 - INFO - [VAL] Epoch: 30/30 | Batch: 48/129 (38.0%) | Loss: 0.0188 | Batch time: 0.04s
2025-03-02 21:56:17,952 - INFO - [VAL] Epoch: 30/30 | Batch: 60/129 (47.3%) | Loss: 0.0010 | Batch time: 0.04s
2025-03-02 21:56:18,392 - INFO - [VAL] Epoch: 30/30 | Batch: 72/129 (56.6%) | Loss: 0.0031 | Batch time: 0.04s
2025-03-02 21:56:18,830 - INFO - [VAL] Epoch: 30/30 | Batch: 84/129 (65.9%) | Loss: 0.0031 | Batch time: 0.04s
2025-03-02 21:56:19,266 - INFO - [VAL] Epoch: 30/30 | Batch: 96/129 (75.2%) | Loss: 0.0042 | Batch time: 0.04s
2025-03-02 21:56:19,701 - INFO - [VAL] Epoch: 30/30 | Batch: 108/129 (84.5%) | Loss: 0.0013 | Batch time: 0.04s
2025-03-02 21:56:20,129 - INFO - [VAL] Epoch: 30/30 | Batch: 120/129 (93.8%) | Loss: 0.0025 | Batch time: 0.04s
2025-03-02 21:56:20,411 - INFO - [VAL] Epoch: 30/30 | Batch: 128/129 (100.0%) | Loss: 0.0045 | Batch time: 0.03s
2025-03-02 21:56:21,037 - INFO - Checkpoint saved: resnet_attention_v1_best.pth (Epoch 30)
2025-03-02 21:56:21,037 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:56:21,038 - INFO - Epoch 30/30 completed in 86.10s
2025-03-02 21:56:21,038 - INFO - Training   - Loss: 0.1986, Accuracy: 0.9308, F1: 0.9310
2025-03-02 21:56:21,038 - INFO - Validation - Loss: 0.0318, Accuracy: 0.9851, F1: 0.9852
2025-03-02 21:56:21,038 - INFO - Validation F1 improved from 0.9849 to 0.9852
2025-03-02 21:56:21,038 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:56:21,484 - INFO - Checkpoint saved: checkpoint_epoch_30.pth (Epoch 30)
2025-03-02 21:56:21,486 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:56:21,486 - INFO - Training completed in 0h 43m 22.91s
2025-03-02 21:56:21,486 - INFO - Best validation F1: 0.9852 (Epoch 30)
2025-03-02 21:56:21,486 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:56:22,193 - INFO - Final model saved to models/resnet_attention_v1/models/resnet_attention_v1_final.pth

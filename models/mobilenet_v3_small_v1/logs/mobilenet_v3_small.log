2025-03-04 00:25:48,351 - INFO - Starting experiment: mobilenet_v3_small
2025-03-04 00:25:48,351 - INFO - Command line arguments: Namespace(data_dir='data/raw', output_dir='models/mobilenet_v3_small_v1', model='mobilenet_v3_small', img_size=224, batch_size=64, num_workers=16, epochs=30, lr=0.001, weight_decay=0.0001, use_weights=True, freeze_backbone=True, no_cuda=False, no_mps=False, use_mps=True, use_amp=False, memory_efficient=True, cache_dataset=True, mps_graph=True, mps_fallback=False, pin_memory=False, optimize_for_m_series=True, patience=10, keep_top_k=3, version=None, find_lr=False, experiment_name='mobilenet_v3_small', resnet_version=50)
2025-03-04 00:25:48,351 - INFO - Processing dataset...
2025-03-04 00:25:48,531 - INFO - Class distribution:
2025-03-04 00:25:48,531 - INFO -   Tomato_healthy: 1591 images
2025-03-04 00:25:48,531 - INFO -   Potato___Early_blight: 1000 images
2025-03-04 00:25:48,531 - INFO -   Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Early_blight: 1000 images
2025-03-04 00:25:48,532 - INFO -   Tomato__Target_Spot: 1404 images
2025-03-04 00:25:48,532 - INFO -   Potato___Late_blight: 1000 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Leaf_Mold: 952 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Septoria_leaf_spot: 1771 images
2025-03-04 00:25:48,532 - INFO -   Tomato__Tomato_mosaic_virus: 373 images
2025-03-04 00:25:48,532 - INFO -   Pepper__bell___Bacterial_spot: 997 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Bacterial_spot: 2127 images
2025-03-04 00:25:48,532 - INFO -   Tomato_Late_blight: 1909 images
2025-03-04 00:25:48,532 - INFO -   Pepper__bell___healthy: 1478 images
2025-03-04 00:25:48,532 - INFO -   Potato___healthy: 152 images
2025-03-04 00:25:48,532 - INFO - Creating model: mobilenet_v3_small with 15 classes
2025-03-04 00:25:48,727 - INFO - Model architecture:
MobileNetV3(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
    (1): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (2): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (3): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
          (1): BatchNorm2d(88, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): ReLU(inplace=True)
        )
        (2): Conv2dNormActivation(
          (0): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (4): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (5): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (6): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(240, 64, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(64, 240, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (7): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (8): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(40, 144, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(48, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (9): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
          (1): BatchNorm2d(288, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (10): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (11): InvertedResidual(
      (block): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
          (2): Hardswish()
        )
        (2): SqueezeExcitation(
          (avgpool): AdaptiveAvgPool2d(output_size=1)
          (fc1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (fc2): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (activation): ReLU()
          (scale_activation): Hardsigmoid()
        )
        (3): Conv2dNormActivation(
          (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
        )
      )
    )
    (12): Conv2dNormActivation(
      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(576, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
      (2): Hardswish()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (classifier): Sequential(
    (0): Linear(in_features=576, out_features=512, bias=True)
    (1): Hardswish()
    (2): Dropout(p=0.2, inplace=True)
    (3): Linear(in_features=512, out_features=15, bias=True)
  )
)
2025-03-04 00:25:48,728 - INFO - Using class weights: [0.5015516  0.7979687  0.24874336 0.7979687  0.5683538  0.7979687
 0.8382024  0.47611496 0.4505752  2.1393263  0.8003698  0.3751616
 0.4180035  0.5398976  5.249794  ]
2025-03-04 00:25:48,729 - INFO - Training only 4 parameters (classifier)
2025-03-04 00:25:48,729 - INFO - Starting training for 30 epochs
2025-03-04 00:25:48,729 - INFO - Using Automatic Mixed Precision: False
2025-03-04 00:25:48,729 - INFO - Early stopping patience: 10
2025-03-04 00:25:48,729 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:25:48,729 - INFO - Starting training: mobilenet_v3_small
2025-03-04 00:25:48,729 - INFO - Total epochs: 30
2025-03-04 00:25:48,729 - INFO - Training batches per epoch: 226
2025-03-04 00:25:48,729 - INFO - Validation batches per epoch: 49
2025-03-04 00:25:48,729 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:25:48,730 - INFO - Training model: mobilenet_v3_small_v1
2025-03-04 00:25:48,730 - INFO - Epoch 1/30
2025-03-04 00:25:48,730 - INFO - ----------------------------------------
2025-03-04 00:26:34,855 - INFO - [TRAIN] Epoch: 1/30 | Batch: 0/226 (0.4%) | Loss: 2.6925 | Batch time: 1.40s
2025-03-04 00:26:35,639 - INFO - [TRAIN] Epoch: 1/30 | Batch: 22/226 (10.2%) | Loss: 2.0410 | Batch time: 0.05s
2025-03-04 00:26:36,881 - INFO - [TRAIN] Epoch: 1/30 | Batch: 44/226 (19.9%) | Loss: 1.4009 | Batch time: 0.04s
2025-03-04 00:26:38,258 - INFO - [TRAIN] Epoch: 1/30 | Batch: 66/226 (29.6%) | Loss: 1.4160 | Batch time: 0.03s
2025-03-04 00:26:39,536 - INFO - [TRAIN] Epoch: 1/30 | Batch: 88/226 (39.4%) | Loss: 1.1685 | Batch time: 0.03s
2025-03-04 00:26:40,571 - INFO - [TRAIN] Epoch: 1/30 | Batch: 110/226 (49.1%) | Loss: 1.2249 | Batch time: 0.04s
2025-03-04 00:26:41,703 - INFO - [TRAIN] Epoch: 1/30 | Batch: 132/226 (58.8%) | Loss: 1.2018 | Batch time: 0.04s
2025-03-04 00:26:43,018 - INFO - [TRAIN] Epoch: 1/30 | Batch: 154/226 (68.6%) | Loss: 1.1605 | Batch time: 0.06s
2025-03-04 00:26:44,221 - INFO - [TRAIN] Epoch: 1/30 | Batch: 176/226 (78.3%) | Loss: 1.1852 | Batch time: 0.08s
2025-03-04 00:26:45,217 - INFO - [TRAIN] Epoch: 1/30 | Batch: 198/226 (88.1%) | Loss: 0.8874 | Batch time: 0.02s
2025-03-04 00:26:45,794 - INFO - [TRAIN] Epoch: 1/30 | Batch: 220/226 (97.8%) | Loss: 1.0315 | Batch time: 0.02s
2025-03-04 00:26:46,312 - INFO - [TRAIN] Epoch: 1/30 | Batch: 225/226 (100.0%) | Loss: 1.1555 | Batch time: 0.44s
2025-03-04 00:27:21,338 - INFO - [VAL] Epoch: 1/30 | Batch: 0/49 (2.0%) | Loss: 0.6283 | Batch time: 0.21s
2025-03-04 00:27:21,384 - INFO - [VAL] Epoch: 1/30 | Batch: 4/49 (10.2%) | Loss: 0.7271 | Batch time: 0.01s
2025-03-04 00:27:21,432 - INFO - [VAL] Epoch: 1/30 | Batch: 8/49 (18.4%) | Loss: 0.4255 | Batch time: 0.01s
2025-03-04 00:27:21,497 - INFO - [VAL] Epoch: 1/30 | Batch: 12/49 (26.5%) | Loss: 0.9369 | Batch time: 0.02s
2025-03-04 00:27:21,562 - INFO - [VAL] Epoch: 1/30 | Batch: 16/49 (34.7%) | Loss: 0.7973 | Batch time: 0.01s
2025-03-04 00:27:21,655 - INFO - [VAL] Epoch: 1/30 | Batch: 20/49 (42.9%) | Loss: 0.8869 | Batch time: 0.02s
2025-03-04 00:27:21,750 - INFO - [VAL] Epoch: 1/30 | Batch: 24/49 (51.0%) | Loss: 0.7637 | Batch time: 0.02s
2025-03-04 00:27:21,796 - INFO - [VAL] Epoch: 1/30 | Batch: 28/49 (59.2%) | Loss: 1.1749 | Batch time: 0.01s
2025-03-04 00:27:21,835 - INFO - [VAL] Epoch: 1/30 | Batch: 32/49 (67.3%) | Loss: 0.8838 | Batch time: 0.01s
2025-03-04 00:27:21,875 - INFO - [VAL] Epoch: 1/30 | Batch: 36/49 (75.5%) | Loss: 0.8110 | Batch time: 0.01s
2025-03-04 00:27:21,915 - INFO - [VAL] Epoch: 1/30 | Batch: 40/49 (83.7%) | Loss: 1.0400 | Batch time: 0.01s
2025-03-04 00:27:21,956 - INFO - [VAL] Epoch: 1/30 | Batch: 44/49 (91.8%) | Loss: 0.6607 | Batch time: 0.01s
2025-03-04 00:27:22,262 - INFO - [VAL] Epoch: 1/30 | Batch: 48/49 (100.0%) | Loss: 0.8114 | Batch time: 0.27s
2025-03-04 00:27:22,362 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 1)
2025-03-04 00:27:22,362 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:22,362 - INFO - Epoch 1/30 completed in 93.63s
2025-03-04 00:27:22,362 - INFO - Training   - Loss: 1.4481, Accuracy: 0.5548, F1: 0.5675
2025-03-04 00:27:22,362 - INFO - Validation - Loss: 0.8493, Accuracy: 0.7083, F1: 0.7176
2025-03-04 00:27:22,362 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:22,362 - INFO - Epoch 2/30
2025-03-04 00:27:22,362 - INFO - ----------------------------------------
2025-03-04 00:27:22,918 - INFO - [TRAIN] Epoch: 2/30 | Batch: 0/226 (0.4%) | Loss: 1.3367 | Batch time: 0.06s
2025-03-04 00:27:24,009 - INFO - [TRAIN] Epoch: 2/30 | Batch: 22/226 (10.2%) | Loss: 0.8695 | Batch time: 0.06s
2025-03-04 00:27:24,961 - INFO - [TRAIN] Epoch: 2/30 | Batch: 44/226 (19.9%) | Loss: 1.1965 | Batch time: 0.03s
2025-03-04 00:27:26,150 - INFO - [TRAIN] Epoch: 2/30 | Batch: 66/226 (29.6%) | Loss: 0.9492 | Batch time: 0.07s
2025-03-04 00:27:27,216 - INFO - [TRAIN] Epoch: 2/30 | Batch: 88/226 (39.4%) | Loss: 1.3831 | Batch time: 0.05s
2025-03-04 00:27:28,266 - INFO - [TRAIN] Epoch: 2/30 | Batch: 110/226 (49.1%) | Loss: 0.7857 | Batch time: 0.05s
2025-03-04 00:27:29,217 - INFO - [TRAIN] Epoch: 2/30 | Batch: 132/226 (58.8%) | Loss: 1.0276 | Batch time: 0.03s
2025-03-04 00:27:30,206 - INFO - [TRAIN] Epoch: 2/30 | Batch: 154/226 (68.6%) | Loss: 0.8264 | Batch time: 0.04s
2025-03-04 00:27:31,077 - INFO - [TRAIN] Epoch: 2/30 | Batch: 176/226 (78.3%) | Loss: 0.9031 | Batch time: 0.03s
2025-03-04 00:27:32,055 - INFO - [TRAIN] Epoch: 2/30 | Batch: 198/226 (88.1%) | Loss: 0.9931 | Batch time: 0.02s
2025-03-04 00:27:32,514 - INFO - [TRAIN] Epoch: 2/30 | Batch: 220/226 (97.8%) | Loss: 1.3326 | Batch time: 0.03s
2025-03-04 00:27:32,672 - INFO - [TRAIN] Epoch: 2/30 | Batch: 225/226 (100.0%) | Loss: 0.7731 | Batch time: 0.03s
2025-03-04 00:27:32,959 - INFO - [VAL] Epoch: 2/30 | Batch: 0/49 (2.0%) | Loss: 0.3603 | Batch time: 0.02s
2025-03-04 00:27:33,036 - INFO - [VAL] Epoch: 2/30 | Batch: 4/49 (10.2%) | Loss: 0.6256 | Batch time: 0.02s
2025-03-04 00:27:33,101 - INFO - [VAL] Epoch: 2/30 | Batch: 8/49 (18.4%) | Loss: 0.2858 | Batch time: 0.01s
2025-03-04 00:27:33,193 - INFO - [VAL] Epoch: 2/30 | Batch: 12/49 (26.5%) | Loss: 0.5755 | Batch time: 0.03s
2025-03-04 00:27:33,281 - INFO - [VAL] Epoch: 2/30 | Batch: 16/49 (34.7%) | Loss: 0.5481 | Batch time: 0.03s
2025-03-04 00:27:33,389 - INFO - [VAL] Epoch: 2/30 | Batch: 20/49 (42.9%) | Loss: 0.6339 | Batch time: 0.03s
2025-03-04 00:27:33,486 - INFO - [VAL] Epoch: 2/30 | Batch: 24/49 (51.0%) | Loss: 0.5133 | Batch time: 0.01s
2025-03-04 00:27:33,534 - INFO - [VAL] Epoch: 2/30 | Batch: 28/49 (59.2%) | Loss: 0.7754 | Batch time: 0.01s
2025-03-04 00:27:33,583 - INFO - [VAL] Epoch: 2/30 | Batch: 32/49 (67.3%) | Loss: 0.4730 | Batch time: 0.01s
2025-03-04 00:27:33,629 - INFO - [VAL] Epoch: 2/30 | Batch: 36/49 (75.5%) | Loss: 0.5104 | Batch time: 0.01s
2025-03-04 00:27:33,677 - INFO - [VAL] Epoch: 2/30 | Batch: 40/49 (83.7%) | Loss: 0.8098 | Batch time: 0.01s
2025-03-04 00:27:33,723 - INFO - [VAL] Epoch: 2/30 | Batch: 44/49 (91.8%) | Loss: 0.5182 | Batch time: 0.01s
2025-03-04 00:27:33,777 - INFO - [VAL] Epoch: 2/30 | Batch: 48/49 (100.0%) | Loss: 0.6123 | Batch time: 0.02s
2025-03-04 00:27:34,069 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 2)
2025-03-04 00:27:34,070 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:34,070 - INFO - Epoch 2/30 completed in 11.71s
2025-03-04 00:27:34,070 - INFO - Training   - Loss: 1.0472, Accuracy: 0.6661, F1: 0.6725
2025-03-04 00:27:34,070 - INFO - Validation - Loss: 0.5568, Accuracy: 0.8217, F1: 0.8217
2025-03-04 00:27:34,070 - INFO - Validation F1 improved from 0.7176 to 0.8217
2025-03-04 00:27:34,070 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:34,070 - INFO - Epoch 3/30
2025-03-04 00:27:34,070 - INFO - ----------------------------------------
2025-03-04 00:27:34,648 - INFO - [TRAIN] Epoch: 3/30 | Batch: 0/226 (0.4%) | Loss: 0.7800 | Batch time: 0.03s
2025-03-04 00:27:35,979 - INFO - [TRAIN] Epoch: 3/30 | Batch: 22/226 (10.2%) | Loss: 0.7266 | Batch time: 0.02s
2025-03-04 00:27:36,933 - INFO - [TRAIN] Epoch: 3/30 | Batch: 44/226 (19.9%) | Loss: 1.1487 | Batch time: 0.04s
2025-03-04 00:27:37,774 - INFO - [TRAIN] Epoch: 3/30 | Batch: 66/226 (29.6%) | Loss: 0.9605 | Batch time: 0.02s
2025-03-04 00:27:38,789 - INFO - [TRAIN] Epoch: 3/30 | Batch: 88/226 (39.4%) | Loss: 1.0335 | Batch time: 0.03s
2025-03-04 00:27:39,796 - INFO - [TRAIN] Epoch: 3/30 | Batch: 110/226 (49.1%) | Loss: 1.1679 | Batch time: 0.04s
2025-03-04 00:27:40,560 - INFO - [TRAIN] Epoch: 3/30 | Batch: 132/226 (58.8%) | Loss: 0.7454 | Batch time: 0.03s
2025-03-04 00:27:41,455 - INFO - [TRAIN] Epoch: 3/30 | Batch: 154/226 (68.6%) | Loss: 0.9067 | Batch time: 0.03s
2025-03-04 00:27:42,240 - INFO - [TRAIN] Epoch: 3/30 | Batch: 176/226 (78.3%) | Loss: 0.7310 | Batch time: 0.03s
2025-03-04 00:27:43,257 - INFO - [TRAIN] Epoch: 3/30 | Batch: 198/226 (88.1%) | Loss: 0.9343 | Batch time: 0.02s
2025-03-04 00:27:43,762 - INFO - [TRAIN] Epoch: 3/30 | Batch: 220/226 (97.8%) | Loss: 0.8659 | Batch time: 0.01s
2025-03-04 00:27:43,837 - INFO - [TRAIN] Epoch: 3/30 | Batch: 225/226 (100.0%) | Loss: 1.0247 | Batch time: 0.01s
2025-03-04 00:27:44,040 - INFO - [VAL] Epoch: 3/30 | Batch: 0/49 (2.0%) | Loss: 0.3381 | Batch time: 0.02s
2025-03-04 00:27:44,107 - INFO - [VAL] Epoch: 3/30 | Batch: 4/49 (10.2%) | Loss: 0.5259 | Batch time: 0.02s
2025-03-04 00:27:44,247 - INFO - [VAL] Epoch: 3/30 | Batch: 8/49 (18.4%) | Loss: 0.3480 | Batch time: 0.02s
2025-03-04 00:27:44,354 - INFO - [VAL] Epoch: 3/30 | Batch: 12/49 (26.5%) | Loss: 0.6577 | Batch time: 0.03s
2025-03-04 00:27:44,464 - INFO - [VAL] Epoch: 3/30 | Batch: 16/49 (34.7%) | Loss: 0.4842 | Batch time: 0.01s
2025-03-04 00:27:44,525 - INFO - [VAL] Epoch: 3/30 | Batch: 20/49 (42.9%) | Loss: 0.8089 | Batch time: 0.01s
2025-03-04 00:27:44,574 - INFO - [VAL] Epoch: 3/30 | Batch: 24/49 (51.0%) | Loss: 0.5444 | Batch time: 0.01s
2025-03-04 00:27:44,621 - INFO - [VAL] Epoch: 3/30 | Batch: 28/49 (59.2%) | Loss: 0.9050 | Batch time: 0.01s
2025-03-04 00:27:44,667 - INFO - [VAL] Epoch: 3/30 | Batch: 32/49 (67.3%) | Loss: 0.5463 | Batch time: 0.01s
2025-03-04 00:27:44,712 - INFO - [VAL] Epoch: 3/30 | Batch: 36/49 (75.5%) | Loss: 0.5281 | Batch time: 0.01s
2025-03-04 00:27:44,757 - INFO - [VAL] Epoch: 3/30 | Batch: 40/49 (83.7%) | Loss: 0.8137 | Batch time: 0.01s
2025-03-04 00:27:44,827 - INFO - [VAL] Epoch: 3/30 | Batch: 44/49 (91.8%) | Loss: 0.4918 | Batch time: 0.02s
2025-03-04 00:27:44,906 - INFO - [VAL] Epoch: 3/30 | Batch: 48/49 (100.0%) | Loss: 0.6436 | Batch time: 0.02s
2025-03-04 00:27:44,910 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:44,910 - INFO - Epoch 3/30 completed in 10.84s
2025-03-04 00:27:44,910 - INFO - Training   - Loss: 0.9325, Accuracy: 0.6990, F1: 0.7036
2025-03-04 00:27:44,910 - INFO - Validation - Loss: 0.6102, Accuracy: 0.7852, F1: 0.7918
2025-03-04 00:27:44,910 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:44,910 - INFO - Epoch 4/30
2025-03-04 00:27:44,911 - INFO - ----------------------------------------
2025-03-04 00:27:45,552 - INFO - [TRAIN] Epoch: 4/30 | Batch: 0/226 (0.4%) | Loss: 0.6244 | Batch time: 0.04s
2025-03-04 00:27:46,806 - INFO - [TRAIN] Epoch: 4/30 | Batch: 22/226 (10.2%) | Loss: 0.8017 | Batch time: 0.02s
2025-03-04 00:27:47,715 - INFO - [TRAIN] Epoch: 4/30 | Batch: 44/226 (19.9%) | Loss: 0.6280 | Batch time: 0.04s
2025-03-04 00:27:48,641 - INFO - [TRAIN] Epoch: 4/30 | Batch: 66/226 (29.6%) | Loss: 0.9539 | Batch time: 0.03s
2025-03-04 00:27:49,668 - INFO - [TRAIN] Epoch: 4/30 | Batch: 88/226 (39.4%) | Loss: 0.5145 | Batch time: 0.03s
2025-03-04 00:27:50,514 - INFO - [TRAIN] Epoch: 4/30 | Batch: 110/226 (49.1%) | Loss: 0.6561 | Batch time: 0.07s
2025-03-04 00:27:51,404 - INFO - [TRAIN] Epoch: 4/30 | Batch: 132/226 (58.8%) | Loss: 0.9257 | Batch time: 0.04s
2025-03-04 00:27:52,393 - INFO - [TRAIN] Epoch: 4/30 | Batch: 154/226 (68.6%) | Loss: 0.7435 | Batch time: 0.05s
2025-03-04 00:27:53,198 - INFO - [TRAIN] Epoch: 4/30 | Batch: 176/226 (78.3%) | Loss: 0.9119 | Batch time: 0.02s
2025-03-04 00:27:54,081 - INFO - [TRAIN] Epoch: 4/30 | Batch: 198/226 (88.1%) | Loss: 0.8732 | Batch time: 0.02s
2025-03-04 00:27:54,486 - INFO - [TRAIN] Epoch: 4/30 | Batch: 220/226 (97.8%) | Loss: 0.6342 | Batch time: 0.01s
2025-03-04 00:27:54,599 - INFO - [TRAIN] Epoch: 4/30 | Batch: 225/226 (100.0%) | Loss: 0.6584 | Batch time: 0.02s
2025-03-04 00:27:54,905 - INFO - [VAL] Epoch: 4/30 | Batch: 0/49 (2.0%) | Loss: 0.3701 | Batch time: 0.01s
2025-03-04 00:27:54,974 - INFO - [VAL] Epoch: 4/30 | Batch: 4/49 (10.2%) | Loss: 0.6263 | Batch time: 0.02s
2025-03-04 00:27:55,041 - INFO - [VAL] Epoch: 4/30 | Batch: 8/49 (18.4%) | Loss: 0.3187 | Batch time: 0.01s
2025-03-04 00:27:55,108 - INFO - [VAL] Epoch: 4/30 | Batch: 12/49 (26.5%) | Loss: 0.5862 | Batch time: 0.01s
2025-03-04 00:27:55,182 - INFO - [VAL] Epoch: 4/30 | Batch: 16/49 (34.7%) | Loss: 0.4693 | Batch time: 0.02s
2025-03-04 00:27:55,243 - INFO - [VAL] Epoch: 4/30 | Batch: 20/49 (42.9%) | Loss: 0.6995 | Batch time: 0.01s
2025-03-04 00:27:55,317 - INFO - [VAL] Epoch: 4/30 | Batch: 24/49 (51.0%) | Loss: 0.4271 | Batch time: 0.02s
2025-03-04 00:27:55,395 - INFO - [VAL] Epoch: 4/30 | Batch: 28/49 (59.2%) | Loss: 0.7913 | Batch time: 0.02s
2025-03-04 00:27:55,513 - INFO - [VAL] Epoch: 4/30 | Batch: 32/49 (67.3%) | Loss: 0.3569 | Batch time: 0.03s
2025-03-04 00:27:55,573 - INFO - [VAL] Epoch: 4/30 | Batch: 36/49 (75.5%) | Loss: 0.5205 | Batch time: 0.01s
2025-03-04 00:27:55,620 - INFO - [VAL] Epoch: 4/30 | Batch: 40/49 (83.7%) | Loss: 0.5975 | Batch time: 0.01s
2025-03-04 00:27:55,665 - INFO - [VAL] Epoch: 4/30 | Batch: 44/49 (91.8%) | Loss: 0.3698 | Batch time: 0.01s
2025-03-04 00:27:55,707 - INFO - [VAL] Epoch: 4/30 | Batch: 48/49 (100.0%) | Loss: 0.5904 | Batch time: 0.01s
2025-03-04 00:27:55,711 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:55,711 - INFO - Epoch 4/30 completed in 10.80s
2025-03-04 00:27:55,711 - INFO - Training   - Loss: 0.8751, Accuracy: 0.7138, F1: 0.7182
2025-03-04 00:27:55,711 - INFO - Validation - Loss: 0.5240, Accuracy: 0.8052, F1: 0.8092
2025-03-04 00:27:55,711 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:27:55,711 - INFO - Epoch 5/30
2025-03-04 00:27:55,711 - INFO - ----------------------------------------
2025-03-04 00:27:56,191 - INFO - [TRAIN] Epoch: 5/30 | Batch: 0/226 (0.4%) | Loss: 1.0252 | Batch time: 0.05s
2025-03-04 00:27:57,492 - INFO - [TRAIN] Epoch: 5/30 | Batch: 22/226 (10.2%) | Loss: 0.7869 | Batch time: 0.02s
2025-03-04 00:27:58,391 - INFO - [TRAIN] Epoch: 5/30 | Batch: 44/226 (19.9%) | Loss: 0.9606 | Batch time: 0.04s
2025-03-04 00:27:59,148 - INFO - [TRAIN] Epoch: 5/30 | Batch: 66/226 (29.6%) | Loss: 0.6098 | Batch time: 0.03s
2025-03-04 00:28:00,101 - INFO - [TRAIN] Epoch: 5/30 | Batch: 88/226 (39.4%) | Loss: 1.0919 | Batch time: 0.03s
2025-03-04 00:28:00,988 - INFO - [TRAIN] Epoch: 5/30 | Batch: 110/226 (49.1%) | Loss: 0.7773 | Batch time: 0.06s
2025-03-04 00:28:01,833 - INFO - [TRAIN] Epoch: 5/30 | Batch: 132/226 (58.8%) | Loss: 0.9846 | Batch time: 0.03s
2025-03-04 00:28:02,840 - INFO - [TRAIN] Epoch: 5/30 | Batch: 154/226 (68.6%) | Loss: 0.7760 | Batch time: 0.03s
2025-03-04 00:28:03,840 - INFO - [TRAIN] Epoch: 5/30 | Batch: 176/226 (78.3%) | Loss: 0.6765 | Batch time: 0.07s
2025-03-04 00:28:04,591 - INFO - [TRAIN] Epoch: 5/30 | Batch: 198/226 (88.1%) | Loss: 0.9055 | Batch time: 0.02s
2025-03-04 00:28:05,120 - INFO - [TRAIN] Epoch: 5/30 | Batch: 220/226 (97.8%) | Loss: 0.6316 | Batch time: 0.02s
2025-03-04 00:28:05,195 - INFO - [TRAIN] Epoch: 5/30 | Batch: 225/226 (100.0%) | Loss: 0.7312 | Batch time: 0.01s
2025-03-04 00:28:05,371 - INFO - [VAL] Epoch: 5/30 | Batch: 0/49 (2.0%) | Loss: 0.3003 | Batch time: 0.02s
2025-03-04 00:28:05,536 - INFO - [VAL] Epoch: 5/30 | Batch: 4/49 (10.2%) | Loss: 0.4177 | Batch time: 0.02s
2025-03-04 00:28:05,645 - INFO - [VAL] Epoch: 5/30 | Batch: 8/49 (18.4%) | Loss: 0.2146 | Batch time: 0.03s
2025-03-04 00:28:05,713 - INFO - [VAL] Epoch: 5/30 | Batch: 12/49 (26.5%) | Loss: 0.4548 | Batch time: 0.01s
2025-03-04 00:28:05,764 - INFO - [VAL] Epoch: 5/30 | Batch: 16/49 (34.7%) | Loss: 0.3711 | Batch time: 0.01s
2025-03-04 00:28:05,815 - INFO - [VAL] Epoch: 5/30 | Batch: 20/49 (42.9%) | Loss: 0.5277 | Batch time: 0.01s
2025-03-04 00:28:05,862 - INFO - [VAL] Epoch: 5/30 | Batch: 24/49 (51.0%) | Loss: 0.3177 | Batch time: 0.01s
2025-03-04 00:28:05,906 - INFO - [VAL] Epoch: 5/30 | Batch: 28/49 (59.2%) | Loss: 0.7092 | Batch time: 0.01s
2025-03-04 00:28:05,950 - INFO - [VAL] Epoch: 5/30 | Batch: 32/49 (67.3%) | Loss: 0.2827 | Batch time: 0.01s
2025-03-04 00:28:05,993 - INFO - [VAL] Epoch: 5/30 | Batch: 36/49 (75.5%) | Loss: 0.4032 | Batch time: 0.01s
2025-03-04 00:28:06,076 - INFO - [VAL] Epoch: 5/30 | Batch: 40/49 (83.7%) | Loss: 0.6327 | Batch time: 0.02s
2025-03-04 00:28:06,166 - INFO - [VAL] Epoch: 5/30 | Batch: 44/49 (91.8%) | Loss: 0.3260 | Batch time: 0.03s
2025-03-04 00:28:06,273 - INFO - [VAL] Epoch: 5/30 | Batch: 48/49 (100.0%) | Loss: 0.6567 | Batch time: 0.02s
2025-03-04 00:28:06,372 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 5)
2025-03-04 00:28:06,372 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:06,372 - INFO - Epoch 5/30 completed in 10.66s
2025-03-04 00:28:06,372 - INFO - Training   - Loss: 0.8353, Accuracy: 0.7286, F1: 0.7325
2025-03-04 00:28:06,372 - INFO - Validation - Loss: 0.4184, Accuracy: 0.8524, F1: 0.8580
2025-03-04 00:28:06,372 - INFO - Validation F1 improved from 0.8217 to 0.8580
2025-03-04 00:28:06,372 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:06,436 - INFO - Checkpoint saved: checkpoint_epoch_5.pth (Epoch 5)
2025-03-04 00:28:06,436 - INFO - Epoch 6/30
2025-03-04 00:28:06,436 - INFO - ----------------------------------------
2025-03-04 00:28:06,977 - INFO - [TRAIN] Epoch: 6/30 | Batch: 0/226 (0.4%) | Loss: 0.5068 | Batch time: 0.03s
2025-03-04 00:28:08,165 - INFO - [TRAIN] Epoch: 6/30 | Batch: 22/226 (10.2%) | Loss: 1.3290 | Batch time: 0.03s
2025-03-04 00:28:09,022 - INFO - [TRAIN] Epoch: 6/30 | Batch: 44/226 (19.9%) | Loss: 0.8356 | Batch time: 0.03s
2025-03-04 00:28:09,925 - INFO - [TRAIN] Epoch: 6/30 | Batch: 66/226 (29.6%) | Loss: 0.6390 | Batch time: 0.07s
2025-03-04 00:28:10,735 - INFO - [TRAIN] Epoch: 6/30 | Batch: 88/226 (39.4%) | Loss: 0.5556 | Batch time: 0.02s
2025-03-04 00:28:11,696 - INFO - [TRAIN] Epoch: 6/30 | Batch: 110/226 (49.1%) | Loss: 0.8877 | Batch time: 0.03s
2025-03-04 00:28:12,514 - INFO - [TRAIN] Epoch: 6/30 | Batch: 132/226 (58.8%) | Loss: 0.8674 | Batch time: 0.03s
2025-03-04 00:28:13,402 - INFO - [TRAIN] Epoch: 6/30 | Batch: 154/226 (68.6%) | Loss: 0.7690 | Batch time: 0.06s
2025-03-04 00:28:14,282 - INFO - [TRAIN] Epoch: 6/30 | Batch: 176/226 (78.3%) | Loss: 0.5932 | Batch time: 0.03s
2025-03-04 00:28:15,049 - INFO - [TRAIN] Epoch: 6/30 | Batch: 198/226 (88.1%) | Loss: 0.6954 | Batch time: 0.02s
2025-03-04 00:28:15,548 - INFO - [TRAIN] Epoch: 6/30 | Batch: 220/226 (97.8%) | Loss: 0.8547 | Batch time: 0.01s
2025-03-04 00:28:15,621 - INFO - [TRAIN] Epoch: 6/30 | Batch: 225/226 (100.0%) | Loss: 0.7554 | Batch time: 0.01s
2025-03-04 00:28:15,812 - INFO - [VAL] Epoch: 6/30 | Batch: 0/49 (2.0%) | Loss: 0.2657 | Batch time: 0.02s
2025-03-04 00:28:15,927 - INFO - [VAL] Epoch: 6/30 | Batch: 4/49 (10.2%) | Loss: 0.3982 | Batch time: 0.06s
2025-03-04 00:28:15,999 - INFO - [VAL] Epoch: 6/30 | Batch: 8/49 (18.4%) | Loss: 0.2488 | Batch time: 0.02s
2025-03-04 00:28:16,100 - INFO - [VAL] Epoch: 6/30 | Batch: 12/49 (26.5%) | Loss: 0.4095 | Batch time: 0.02s
2025-03-04 00:28:16,218 - INFO - [VAL] Epoch: 6/30 | Batch: 16/49 (34.7%) | Loss: 0.4187 | Batch time: 0.02s
2025-03-04 00:28:16,262 - INFO - [VAL] Epoch: 6/30 | Batch: 20/49 (42.9%) | Loss: 0.4387 | Batch time: 0.01s
2025-03-04 00:28:16,306 - INFO - [VAL] Epoch: 6/30 | Batch: 24/49 (51.0%) | Loss: 0.3040 | Batch time: 0.01s
2025-03-04 00:28:16,348 - INFO - [VAL] Epoch: 6/30 | Batch: 28/49 (59.2%) | Loss: 0.7404 | Batch time: 0.01s
2025-03-04 00:28:16,392 - INFO - [VAL] Epoch: 6/30 | Batch: 32/49 (67.3%) | Loss: 0.3282 | Batch time: 0.01s
2025-03-04 00:28:16,444 - INFO - [VAL] Epoch: 6/30 | Batch: 36/49 (75.5%) | Loss: 0.3760 | Batch time: 0.02s
2025-03-04 00:28:16,496 - INFO - [VAL] Epoch: 6/30 | Batch: 40/49 (83.7%) | Loss: 0.5368 | Batch time: 0.01s
2025-03-04 00:28:16,538 - INFO - [VAL] Epoch: 6/30 | Batch: 44/49 (91.8%) | Loss: 0.3745 | Batch time: 0.01s
2025-03-04 00:28:16,579 - INFO - [VAL] Epoch: 6/30 | Batch: 48/49 (100.0%) | Loss: 0.3301 | Batch time: 0.01s
2025-03-04 00:28:16,584 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:16,585 - INFO - Epoch 6/30 completed in 10.15s
2025-03-04 00:28:16,585 - INFO - Training   - Loss: 0.7994, Accuracy: 0.7409, F1: 0.7435
2025-03-04 00:28:16,585 - INFO - Validation - Loss: 0.4155, Accuracy: 0.8472, F1: 0.8491
2025-03-04 00:28:16,585 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:16,585 - INFO - Epoch 7/30
2025-03-04 00:28:16,585 - INFO - ----------------------------------------
2025-03-04 00:28:17,180 - INFO - [TRAIN] Epoch: 7/30 | Batch: 0/226 (0.4%) | Loss: 0.6440 | Batch time: 0.03s
2025-03-04 00:28:18,092 - INFO - [TRAIN] Epoch: 7/30 | Batch: 22/226 (10.2%) | Loss: 0.9693 | Batch time: 0.03s
2025-03-04 00:28:19,118 - INFO - [TRAIN] Epoch: 7/30 | Batch: 44/226 (19.9%) | Loss: 0.6805 | Batch time: 0.02s
2025-03-04 00:28:20,059 - INFO - [TRAIN] Epoch: 7/30 | Batch: 66/226 (29.6%) | Loss: 0.9893 | Batch time: 0.03s
2025-03-04 00:28:20,855 - INFO - [TRAIN] Epoch: 7/30 | Batch: 88/226 (39.4%) | Loss: 0.5786 | Batch time: 0.07s
2025-03-04 00:28:21,615 - INFO - [TRAIN] Epoch: 7/30 | Batch: 110/226 (49.1%) | Loss: 0.7358 | Batch time: 0.03s
2025-03-04 00:28:22,586 - INFO - [TRAIN] Epoch: 7/30 | Batch: 132/226 (58.8%) | Loss: 0.7771 | Batch time: 0.03s
2025-03-04 00:28:23,425 - INFO - [TRAIN] Epoch: 7/30 | Batch: 154/226 (68.6%) | Loss: 0.7243 | Batch time: 0.06s
2025-03-04 00:28:24,294 - INFO - [TRAIN] Epoch: 7/30 | Batch: 176/226 (78.3%) | Loss: 0.6943 | Batch time: 0.02s
2025-03-04 00:28:25,099 - INFO - [TRAIN] Epoch: 7/30 | Batch: 198/226 (88.1%) | Loss: 0.8028 | Batch time: 0.02s
2025-03-04 00:28:25,505 - INFO - [TRAIN] Epoch: 7/30 | Batch: 220/226 (97.8%) | Loss: 0.6126 | Batch time: 0.01s
2025-03-04 00:28:25,617 - INFO - [TRAIN] Epoch: 7/30 | Batch: 225/226 (100.0%) | Loss: 0.8803 | Batch time: 0.02s
2025-03-04 00:28:25,837 - INFO - [VAL] Epoch: 7/30 | Batch: 0/49 (2.0%) | Loss: 0.2446 | Batch time: 0.01s
2025-03-04 00:28:25,906 - INFO - [VAL] Epoch: 7/30 | Batch: 4/49 (10.2%) | Loss: 0.4323 | Batch time: 0.01s
2025-03-04 00:28:25,973 - INFO - [VAL] Epoch: 7/30 | Batch: 8/49 (18.4%) | Loss: 0.2693 | Batch time: 0.02s
2025-03-04 00:28:26,028 - INFO - [VAL] Epoch: 7/30 | Batch: 12/49 (26.5%) | Loss: 0.4544 | Batch time: 0.01s
2025-03-04 00:28:26,096 - INFO - [VAL] Epoch: 7/30 | Batch: 16/49 (34.7%) | Loss: 0.3166 | Batch time: 0.02s
2025-03-04 00:28:26,157 - INFO - [VAL] Epoch: 7/30 | Batch: 20/49 (42.9%) | Loss: 0.4573 | Batch time: 0.01s
2025-03-04 00:28:26,205 - INFO - [VAL] Epoch: 7/30 | Batch: 24/49 (51.0%) | Loss: 0.2718 | Batch time: 0.01s
2025-03-04 00:28:26,288 - INFO - [VAL] Epoch: 7/30 | Batch: 28/49 (59.2%) | Loss: 0.5942 | Batch time: 0.02s
2025-03-04 00:28:26,388 - INFO - [VAL] Epoch: 7/30 | Batch: 32/49 (67.3%) | Loss: 0.2181 | Batch time: 0.03s
2025-03-04 00:28:26,494 - INFO - [VAL] Epoch: 7/30 | Batch: 36/49 (75.5%) | Loss: 0.3948 | Batch time: 0.02s
2025-03-04 00:28:26,534 - INFO - [VAL] Epoch: 7/30 | Batch: 40/49 (83.7%) | Loss: 0.5388 | Batch time: 0.01s
2025-03-04 00:28:26,576 - INFO - [VAL] Epoch: 7/30 | Batch: 44/49 (91.8%) | Loss: 0.4196 | Batch time: 0.01s
2025-03-04 00:28:26,617 - INFO - [VAL] Epoch: 7/30 | Batch: 48/49 (100.0%) | Loss: 0.3234 | Batch time: 0.01s
2025-03-04 00:28:26,621 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:26,621 - INFO - Epoch 7/30 completed in 10.04s
2025-03-04 00:28:26,621 - INFO - Training   - Loss: 0.7684, Accuracy: 0.7482, F1: 0.7517
2025-03-04 00:28:26,621 - INFO - Validation - Loss: 0.3887, Accuracy: 0.8521, F1: 0.8529
2025-03-04 00:28:26,621 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:26,621 - INFO - Epoch 8/30
2025-03-04 00:28:26,621 - INFO - ----------------------------------------
2025-03-04 00:28:27,119 - INFO - [TRAIN] Epoch: 8/30 | Batch: 0/226 (0.4%) | Loss: 1.1015 | Batch time: 0.04s
2025-03-04 00:28:28,223 - INFO - [TRAIN] Epoch: 8/30 | Batch: 22/226 (10.2%) | Loss: 0.9765 | Batch time: 0.03s
2025-03-04 00:28:29,120 - INFO - [TRAIN] Epoch: 8/30 | Batch: 44/226 (19.9%) | Loss: 0.7174 | Batch time: 0.03s
2025-03-04 00:28:29,900 - INFO - [TRAIN] Epoch: 8/30 | Batch: 66/226 (29.6%) | Loss: 0.8726 | Batch time: 0.06s
2025-03-04 00:28:30,672 - INFO - [TRAIN] Epoch: 8/30 | Batch: 88/226 (39.4%) | Loss: 0.6374 | Batch time: 0.02s
2025-03-04 00:28:31,583 - INFO - [TRAIN] Epoch: 8/30 | Batch: 110/226 (49.1%) | Loss: 0.6691 | Batch time: 0.04s
2025-03-04 00:28:32,321 - INFO - [TRAIN] Epoch: 8/30 | Batch: 132/226 (58.8%) | Loss: 0.6818 | Batch time: 0.03s
2025-03-04 00:28:33,199 - INFO - [TRAIN] Epoch: 8/30 | Batch: 154/226 (68.6%) | Loss: 0.7428 | Batch time: 0.04s
2025-03-04 00:28:34,122 - INFO - [TRAIN] Epoch: 8/30 | Batch: 176/226 (78.3%) | Loss: 0.7663 | Batch time: 0.05s
2025-03-04 00:28:34,846 - INFO - [TRAIN] Epoch: 8/30 | Batch: 198/226 (88.1%) | Loss: 0.8494 | Batch time: 0.02s
2025-03-04 00:28:35,318 - INFO - [TRAIN] Epoch: 8/30 | Batch: 220/226 (97.8%) | Loss: 0.6451 | Batch time: 0.01s
2025-03-04 00:28:35,391 - INFO - [TRAIN] Epoch: 8/30 | Batch: 225/226 (100.0%) | Loss: 0.6405 | Batch time: 0.01s
2025-03-04 00:28:35,521 - INFO - [VAL] Epoch: 8/30 | Batch: 0/49 (2.0%) | Loss: 0.1855 | Batch time: 0.01s
2025-03-04 00:28:35,621 - INFO - [VAL] Epoch: 8/30 | Batch: 4/49 (10.2%) | Loss: 0.2904 | Batch time: 0.02s
2025-03-04 00:28:35,704 - INFO - [VAL] Epoch: 8/30 | Batch: 8/49 (18.4%) | Loss: 0.2118 | Batch time: 0.01s
2025-03-04 00:28:35,793 - INFO - [VAL] Epoch: 8/30 | Batch: 12/49 (26.5%) | Loss: 0.3457 | Batch time: 0.03s
2025-03-04 00:28:35,876 - INFO - [VAL] Epoch: 8/30 | Batch: 16/49 (34.7%) | Loss: 0.2969 | Batch time: 0.01s
2025-03-04 00:28:35,943 - INFO - [VAL] Epoch: 8/30 | Batch: 20/49 (42.9%) | Loss: 0.3861 | Batch time: 0.01s
2025-03-04 00:28:35,999 - INFO - [VAL] Epoch: 8/30 | Batch: 24/49 (51.0%) | Loss: 0.2375 | Batch time: 0.01s
2025-03-04 00:28:36,043 - INFO - [VAL] Epoch: 8/30 | Batch: 28/49 (59.2%) | Loss: 0.5336 | Batch time: 0.01s
2025-03-04 00:28:36,088 - INFO - [VAL] Epoch: 8/30 | Batch: 32/49 (67.3%) | Loss: 0.2145 | Batch time: 0.01s
2025-03-04 00:28:36,132 - INFO - [VAL] Epoch: 8/30 | Batch: 36/49 (75.5%) | Loss: 0.3164 | Batch time: 0.01s
2025-03-04 00:28:36,175 - INFO - [VAL] Epoch: 8/30 | Batch: 40/49 (83.7%) | Loss: 0.4036 | Batch time: 0.01s
2025-03-04 00:28:36,217 - INFO - [VAL] Epoch: 8/30 | Batch: 44/49 (91.8%) | Loss: 0.2704 | Batch time: 0.01s
2025-03-04 00:28:36,257 - INFO - [VAL] Epoch: 8/30 | Batch: 48/49 (100.0%) | Loss: 0.3751 | Batch time: 0.01s
2025-03-04 00:28:36,519 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 8)
2025-03-04 00:28:36,519 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:36,519 - INFO - Epoch 8/30 completed in 9.90s
2025-03-04 00:28:36,519 - INFO - Training   - Loss: 0.7134, Accuracy: 0.7697, F1: 0.7721
2025-03-04 00:28:36,519 - INFO - Validation - Loss: 0.3305, Accuracy: 0.8773, F1: 0.8792
2025-03-04 00:28:36,519 - INFO - Validation F1 improved from 0.8580 to 0.8792
2025-03-04 00:28:36,519 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:36,519 - INFO - Epoch 9/30
2025-03-04 00:28:36,520 - INFO - ----------------------------------------
2025-03-04 00:28:37,028 - INFO - [TRAIN] Epoch: 9/30 | Batch: 0/226 (0.4%) | Loss: 0.5584 | Batch time: 0.02s
2025-03-04 00:28:38,230 - INFO - [TRAIN] Epoch: 9/30 | Batch: 22/226 (10.2%) | Loss: 0.4652 | Batch time: 0.02s
2025-03-04 00:28:39,079 - INFO - [TRAIN] Epoch: 9/30 | Batch: 44/226 (19.9%) | Loss: 0.8180 | Batch time: 0.04s
2025-03-04 00:28:39,859 - INFO - [TRAIN] Epoch: 9/30 | Batch: 66/226 (29.6%) | Loss: 0.8745 | Batch time: 0.10s
2025-03-04 00:28:40,705 - INFO - [TRAIN] Epoch: 9/30 | Batch: 88/226 (39.4%) | Loss: 0.5962 | Batch time: 0.02s
2025-03-04 00:28:41,515 - INFO - [TRAIN] Epoch: 9/30 | Batch: 110/226 (49.1%) | Loss: 0.7330 | Batch time: 0.05s
2025-03-04 00:28:42,315 - INFO - [TRAIN] Epoch: 9/30 | Batch: 132/226 (58.8%) | Loss: 0.6647 | Batch time: 0.03s
2025-03-04 00:28:43,215 - INFO - [TRAIN] Epoch: 9/30 | Batch: 154/226 (68.6%) | Loss: 0.5971 | Batch time: 0.03s
2025-03-04 00:28:44,007 - INFO - [TRAIN] Epoch: 9/30 | Batch: 176/226 (78.3%) | Loss: 0.8343 | Batch time: 0.07s
2025-03-04 00:28:44,822 - INFO - [TRAIN] Epoch: 9/30 | Batch: 198/226 (88.1%) | Loss: 0.7287 | Batch time: 0.02s
2025-03-04 00:28:45,283 - INFO - [TRAIN] Epoch: 9/30 | Batch: 220/226 (97.8%) | Loss: 0.6760 | Batch time: 0.03s
2025-03-04 00:28:45,400 - INFO - [TRAIN] Epoch: 9/30 | Batch: 225/226 (100.0%) | Loss: 0.5843 | Batch time: 0.02s
2025-03-04 00:28:45,607 - INFO - [VAL] Epoch: 9/30 | Batch: 0/49 (2.0%) | Loss: 0.1632 | Batch time: 0.01s
2025-03-04 00:28:45,669 - INFO - [VAL] Epoch: 9/30 | Batch: 4/49 (10.2%) | Loss: 0.2742 | Batch time: 0.01s
2025-03-04 00:28:45,727 - INFO - [VAL] Epoch: 9/30 | Batch: 8/49 (18.4%) | Loss: 0.2065 | Batch time: 0.01s
2025-03-04 00:28:45,816 - INFO - [VAL] Epoch: 9/30 | Batch: 12/49 (26.5%) | Loss: 0.3354 | Batch time: 0.02s
2025-03-04 00:28:45,897 - INFO - [VAL] Epoch: 9/30 | Batch: 16/49 (34.7%) | Loss: 0.2668 | Batch time: 0.02s
2025-03-04 00:28:46,002 - INFO - [VAL] Epoch: 9/30 | Batch: 20/49 (42.9%) | Loss: 0.3929 | Batch time: 0.03s
2025-03-04 00:28:46,073 - INFO - [VAL] Epoch: 9/30 | Batch: 24/49 (51.0%) | Loss: 0.2458 | Batch time: 0.01s
2025-03-04 00:28:46,115 - INFO - [VAL] Epoch: 9/30 | Batch: 28/49 (59.2%) | Loss: 0.5663 | Batch time: 0.01s
2025-03-04 00:28:46,163 - INFO - [VAL] Epoch: 9/30 | Batch: 32/49 (67.3%) | Loss: 0.1901 | Batch time: 0.01s
2025-03-04 00:28:46,206 - INFO - [VAL] Epoch: 9/30 | Batch: 36/49 (75.5%) | Loss: 0.2725 | Batch time: 0.01s
2025-03-04 00:28:46,248 - INFO - [VAL] Epoch: 9/30 | Batch: 40/49 (83.7%) | Loss: 0.4124 | Batch time: 0.01s
2025-03-04 00:28:46,289 - INFO - [VAL] Epoch: 9/30 | Batch: 44/49 (91.8%) | Loss: 0.2732 | Batch time: 0.01s
2025-03-04 00:28:46,331 - INFO - [VAL] Epoch: 9/30 | Batch: 48/49 (100.0%) | Loss: 0.3663 | Batch time: 0.01s
2025-03-04 00:28:46,598 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 9)
2025-03-04 00:28:46,598 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:46,598 - INFO - Epoch 9/30 completed in 10.08s
2025-03-04 00:28:46,598 - INFO - Training   - Loss: 0.6859, Accuracy: 0.7727, F1: 0.7752
2025-03-04 00:28:46,598 - INFO - Validation - Loss: 0.3274, Accuracy: 0.8798, F1: 0.8818
2025-03-04 00:28:46,598 - INFO - Validation F1 improved from 0.8792 to 0.8818
2025-03-04 00:28:46,598 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:46,598 - INFO - Epoch 10/30
2025-03-04 00:28:46,598 - INFO - ----------------------------------------
2025-03-04 00:28:47,105 - INFO - [TRAIN] Epoch: 10/30 | Batch: 0/226 (0.4%) | Loss: 0.7862 | Batch time: 0.04s
2025-03-04 00:28:48,125 - INFO - [TRAIN] Epoch: 10/30 | Batch: 22/226 (10.2%) | Loss: 0.5565 | Batch time: 0.03s
2025-03-04 00:28:48,982 - INFO - [TRAIN] Epoch: 10/30 | Batch: 44/226 (19.9%) | Loss: 0.7334 | Batch time: 0.04s
2025-03-04 00:28:49,782 - INFO - [TRAIN] Epoch: 10/30 | Batch: 66/226 (29.6%) | Loss: 0.7103 | Batch time: 0.03s
2025-03-04 00:28:50,605 - INFO - [TRAIN] Epoch: 10/30 | Batch: 88/226 (39.4%) | Loss: 1.0196 | Batch time: 0.03s
2025-03-04 00:28:51,433 - INFO - [TRAIN] Epoch: 10/30 | Batch: 110/226 (49.1%) | Loss: 0.9437 | Batch time: 0.05s
2025-03-04 00:28:52,268 - INFO - [TRAIN] Epoch: 10/30 | Batch: 132/226 (58.8%) | Loss: 0.6562 | Batch time: 0.02s
2025-03-04 00:28:53,112 - INFO - [TRAIN] Epoch: 10/30 | Batch: 154/226 (68.6%) | Loss: 0.7971 | Batch time: 0.03s
2025-03-04 00:28:53,844 - INFO - [TRAIN] Epoch: 10/30 | Batch: 176/226 (78.3%) | Loss: 0.6682 | Batch time: 0.02s
2025-03-04 00:28:54,677 - INFO - [TRAIN] Epoch: 10/30 | Batch: 198/226 (88.1%) | Loss: 1.1966 | Batch time: 0.02s
2025-03-04 00:28:55,171 - INFO - [TRAIN] Epoch: 10/30 | Batch: 220/226 (97.8%) | Loss: 0.6245 | Batch time: 0.02s
2025-03-04 00:28:55,245 - INFO - [TRAIN] Epoch: 10/30 | Batch: 225/226 (100.0%) | Loss: 0.4933 | Batch time: 0.01s
2025-03-04 00:28:55,421 - INFO - [VAL] Epoch: 10/30 | Batch: 0/49 (2.0%) | Loss: 0.1512 | Batch time: 0.02s
2025-03-04 00:28:55,493 - INFO - [VAL] Epoch: 10/30 | Batch: 4/49 (10.2%) | Loss: 0.2588 | Batch time: 0.02s
2025-03-04 00:28:55,553 - INFO - [VAL] Epoch: 10/30 | Batch: 8/49 (18.4%) | Loss: 0.1645 | Batch time: 0.01s
2025-03-04 00:28:55,639 - INFO - [VAL] Epoch: 10/30 | Batch: 12/49 (26.5%) | Loss: 0.3144 | Batch time: 0.01s
2025-03-04 00:28:55,727 - INFO - [VAL] Epoch: 10/30 | Batch: 16/49 (34.7%) | Loss: 0.2673 | Batch time: 0.02s
2025-03-04 00:28:55,831 - INFO - [VAL] Epoch: 10/30 | Batch: 20/49 (42.9%) | Loss: 0.3712 | Batch time: 0.02s
2025-03-04 00:28:55,894 - INFO - [VAL] Epoch: 10/30 | Batch: 24/49 (51.0%) | Loss: 0.2281 | Batch time: 0.01s
2025-03-04 00:28:55,935 - INFO - [VAL] Epoch: 10/30 | Batch: 28/49 (59.2%) | Loss: 0.5638 | Batch time: 0.01s
2025-03-04 00:28:55,976 - INFO - [VAL] Epoch: 10/30 | Batch: 32/49 (67.3%) | Loss: 0.2072 | Batch time: 0.01s
2025-03-04 00:28:56,017 - INFO - [VAL] Epoch: 10/30 | Batch: 36/49 (75.5%) | Loss: 0.2553 | Batch time: 0.01s
2025-03-04 00:28:56,058 - INFO - [VAL] Epoch: 10/30 | Batch: 40/49 (83.7%) | Loss: 0.4015 | Batch time: 0.01s
2025-03-04 00:28:56,098 - INFO - [VAL] Epoch: 10/30 | Batch: 44/49 (91.8%) | Loss: 0.2588 | Batch time: 0.01s
2025-03-04 00:28:56,152 - INFO - [VAL] Epoch: 10/30 | Batch: 48/49 (100.0%) | Loss: 0.4400 | Batch time: 0.02s
2025-03-04 00:28:56,401 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 10)
2025-03-04 00:28:56,401 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:56,401 - INFO - Epoch 10/30 completed in 9.80s
2025-03-04 00:28:56,401 - INFO - Training   - Loss: 0.6820, Accuracy: 0.7759, F1: 0.7779
2025-03-04 00:28:56,401 - INFO - Validation - Loss: 0.3191, Accuracy: 0.8853, F1: 0.8867
2025-03-04 00:28:56,401 - INFO - Validation F1 improved from 0.8818 to 0.8867
2025-03-04 00:28:56,401 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:28:56,448 - INFO - Checkpoint saved: checkpoint_epoch_10.pth (Epoch 10)
2025-03-04 00:28:56,448 - INFO - Epoch 11/30
2025-03-04 00:28:56,448 - INFO - ----------------------------------------
2025-03-04 00:28:56,861 - INFO - [TRAIN] Epoch: 11/30 | Batch: 0/226 (0.4%) | Loss: 0.5025 | Batch time: 0.03s
2025-03-04 00:28:57,805 - INFO - [TRAIN] Epoch: 11/30 | Batch: 22/226 (10.2%) | Loss: 0.6180 | Batch time: 0.03s
2025-03-04 00:28:58,627 - INFO - [TRAIN] Epoch: 11/30 | Batch: 44/226 (19.9%) | Loss: 0.4837 | Batch time: 0.03s
2025-03-04 00:28:59,441 - INFO - [TRAIN] Epoch: 11/30 | Batch: 66/226 (29.6%) | Loss: 0.5883 | Batch time: 0.07s
2025-03-04 00:29:00,213 - INFO - [TRAIN] Epoch: 11/30 | Batch: 88/226 (39.4%) | Loss: 0.7167 | Batch time: 0.02s
2025-03-04 00:29:01,076 - INFO - [TRAIN] Epoch: 11/30 | Batch: 110/226 (49.1%) | Loss: 0.7982 | Batch time: 0.07s
2025-03-04 00:29:01,810 - INFO - [TRAIN] Epoch: 11/30 | Batch: 132/226 (58.8%) | Loss: 0.7659 | Batch time: 0.03s
2025-03-04 00:29:02,666 - INFO - [TRAIN] Epoch: 11/30 | Batch: 154/226 (68.6%) | Loss: 0.6852 | Batch time: 0.03s
2025-03-04 00:29:03,482 - INFO - [TRAIN] Epoch: 11/30 | Batch: 176/226 (78.3%) | Loss: 0.6585 | Batch time: 0.04s
2025-03-04 00:29:04,222 - INFO - [TRAIN] Epoch: 11/30 | Batch: 198/226 (88.1%) | Loss: 0.6870 | Batch time: 0.02s
2025-03-04 00:29:04,714 - INFO - [TRAIN] Epoch: 11/30 | Batch: 220/226 (97.8%) | Loss: 0.6361 | Batch time: 0.01s
2025-03-04 00:29:04,785 - INFO - [TRAIN] Epoch: 11/30 | Batch: 225/226 (100.0%) | Loss: 0.6049 | Batch time: 0.01s
2025-03-04 00:29:04,943 - INFO - [VAL] Epoch: 11/30 | Batch: 0/49 (2.0%) | Loss: 0.1420 | Batch time: 0.02s
2025-03-04 00:29:05,013 - INFO - [VAL] Epoch: 11/30 | Batch: 4/49 (10.2%) | Loss: 0.2734 | Batch time: 0.02s
2025-03-04 00:29:05,064 - INFO - [VAL] Epoch: 11/30 | Batch: 8/49 (18.4%) | Loss: 0.1690 | Batch time: 0.01s
2025-03-04 00:29:05,152 - INFO - [VAL] Epoch: 11/30 | Batch: 12/49 (26.5%) | Loss: 0.2869 | Batch time: 0.02s
2025-03-04 00:29:05,248 - INFO - [VAL] Epoch: 11/30 | Batch: 16/49 (34.7%) | Loss: 0.2721 | Batch time: 0.02s
2025-03-04 00:29:05,353 - INFO - [VAL] Epoch: 11/30 | Batch: 20/49 (42.9%) | Loss: 0.3658 | Batch time: 0.03s
2025-03-04 00:29:05,426 - INFO - [VAL] Epoch: 11/30 | Batch: 24/49 (51.0%) | Loss: 0.2317 | Batch time: 0.01s
2025-03-04 00:29:05,468 - INFO - [VAL] Epoch: 11/30 | Batch: 28/49 (59.2%) | Loss: 0.5316 | Batch time: 0.01s
2025-03-04 00:29:05,510 - INFO - [VAL] Epoch: 11/30 | Batch: 32/49 (67.3%) | Loss: 0.2134 | Batch time: 0.01s
2025-03-04 00:29:05,550 - INFO - [VAL] Epoch: 11/30 | Batch: 36/49 (75.5%) | Loss: 0.2700 | Batch time: 0.01s
2025-03-04 00:29:05,592 - INFO - [VAL] Epoch: 11/30 | Batch: 40/49 (83.7%) | Loss: 0.3775 | Batch time: 0.01s
2025-03-04 00:29:05,632 - INFO - [VAL] Epoch: 11/30 | Batch: 44/49 (91.8%) | Loss: 0.2311 | Batch time: 0.01s
2025-03-04 00:29:05,688 - INFO - [VAL] Epoch: 11/30 | Batch: 48/49 (100.0%) | Loss: 0.4280 | Batch time: 0.01s
2025-03-04 00:29:05,934 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 11)
2025-03-04 00:29:05,934 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:05,934 - INFO - Epoch 11/30 completed in 9.49s
2025-03-04 00:29:05,934 - INFO - Training   - Loss: 0.6929, Accuracy: 0.7739, F1: 0.7775
2025-03-04 00:29:05,934 - INFO - Validation - Loss: 0.3117, Accuracy: 0.8892, F1: 0.8904
2025-03-04 00:29:05,934 - INFO - Validation F1 improved from 0.8867 to 0.8904
2025-03-04 00:29:05,934 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:05,934 - INFO - Epoch 12/30
2025-03-04 00:29:05,934 - INFO - ----------------------------------------
2025-03-04 00:29:06,372 - INFO - [TRAIN] Epoch: 12/30 | Batch: 0/226 (0.4%) | Loss: 0.5642 | Batch time: 0.03s
2025-03-04 00:29:07,569 - INFO - [TRAIN] Epoch: 12/30 | Batch: 22/226 (10.2%) | Loss: 0.5210 | Batch time: 0.02s
2025-03-04 00:29:08,369 - INFO - [TRAIN] Epoch: 12/30 | Batch: 44/226 (19.9%) | Loss: 0.6369 | Batch time: 0.05s
2025-03-04 00:29:09,227 - INFO - [TRAIN] Epoch: 12/30 | Batch: 66/226 (29.6%) | Loss: 0.6724 | Batch time: 0.03s
2025-03-04 00:29:10,105 - INFO - [TRAIN] Epoch: 12/30 | Batch: 88/226 (39.4%) | Loss: 0.9124 | Batch time: 0.03s
2025-03-04 00:29:10,874 - INFO - [TRAIN] Epoch: 12/30 | Batch: 110/226 (49.1%) | Loss: 0.8740 | Batch time: 0.03s
2025-03-04 00:29:11,739 - INFO - [TRAIN] Epoch: 12/30 | Batch: 132/226 (58.8%) | Loss: 0.5283 | Batch time: 0.03s
2025-03-04 00:29:12,590 - INFO - [TRAIN] Epoch: 12/30 | Batch: 154/226 (68.6%) | Loss: 0.4866 | Batch time: 0.05s
2025-03-04 00:29:13,395 - INFO - [TRAIN] Epoch: 12/30 | Batch: 176/226 (78.3%) | Loss: 0.6510 | Batch time: 0.03s
2025-03-04 00:29:14,178 - INFO - [TRAIN] Epoch: 12/30 | Batch: 198/226 (88.1%) | Loss: 1.0121 | Batch time: 0.02s
2025-03-04 00:29:14,560 - INFO - [TRAIN] Epoch: 12/30 | Batch: 220/226 (97.8%) | Loss: 0.3944 | Batch time: 0.02s
2025-03-04 00:29:14,697 - INFO - [TRAIN] Epoch: 12/30 | Batch: 225/226 (100.0%) | Loss: 0.7773 | Batch time: 0.02s
2025-03-04 00:29:14,889 - INFO - [VAL] Epoch: 12/30 | Batch: 0/49 (2.0%) | Loss: 0.1727 | Batch time: 0.01s
2025-03-04 00:29:14,967 - INFO - [VAL] Epoch: 12/30 | Batch: 4/49 (10.2%) | Loss: 0.2733 | Batch time: 0.01s
2025-03-04 00:29:15,029 - INFO - [VAL] Epoch: 12/30 | Batch: 8/49 (18.4%) | Loss: 0.1844 | Batch time: 0.01s
2025-03-04 00:29:15,091 - INFO - [VAL] Epoch: 12/30 | Batch: 12/49 (26.5%) | Loss: 0.3322 | Batch time: 0.01s
2025-03-04 00:29:15,165 - INFO - [VAL] Epoch: 12/30 | Batch: 16/49 (34.7%) | Loss: 0.2797 | Batch time: 0.02s
2025-03-04 00:29:15,228 - INFO - [VAL] Epoch: 12/30 | Batch: 20/49 (42.9%) | Loss: 0.4109 | Batch time: 0.01s
2025-03-04 00:29:15,311 - INFO - [VAL] Epoch: 12/30 | Batch: 24/49 (51.0%) | Loss: 0.2452 | Batch time: 0.02s
2025-03-04 00:29:15,384 - INFO - [VAL] Epoch: 12/30 | Batch: 28/49 (59.2%) | Loss: 0.5851 | Batch time: 0.02s
2025-03-04 00:29:15,498 - INFO - [VAL] Epoch: 12/30 | Batch: 32/49 (67.3%) | Loss: 0.2124 | Batch time: 0.03s
2025-03-04 00:29:15,566 - INFO - [VAL] Epoch: 12/30 | Batch: 36/49 (75.5%) | Loss: 0.2420 | Batch time: 0.01s
2025-03-04 00:29:15,607 - INFO - [VAL] Epoch: 12/30 | Batch: 40/49 (83.7%) | Loss: 0.3910 | Batch time: 0.01s
2025-03-04 00:29:15,650 - INFO - [VAL] Epoch: 12/30 | Batch: 44/49 (91.8%) | Loss: 0.2495 | Batch time: 0.01s
2025-03-04 00:29:15,689 - INFO - [VAL] Epoch: 12/30 | Batch: 48/49 (100.0%) | Loss: 0.3405 | Batch time: 0.01s
2025-03-04 00:29:15,692 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:15,693 - INFO - Epoch 12/30 completed in 9.76s
2025-03-04 00:29:15,693 - INFO - Training   - Loss: 0.6632, Accuracy: 0.7839, F1: 0.7861
2025-03-04 00:29:15,693 - INFO - Validation - Loss: 0.3228, Accuracy: 0.8844, F1: 0.8857
2025-03-04 00:29:15,693 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:15,693 - INFO - Epoch 13/30
2025-03-04 00:29:15,693 - INFO - ----------------------------------------
2025-03-04 00:29:16,293 - INFO - [TRAIN] Epoch: 13/30 | Batch: 0/226 (0.4%) | Loss: 0.5629 | Batch time: 0.04s
2025-03-04 00:29:17,337 - INFO - [TRAIN] Epoch: 13/30 | Batch: 22/226 (10.2%) | Loss: 0.6443 | Batch time: 0.03s
2025-03-04 00:29:18,341 - INFO - [TRAIN] Epoch: 13/30 | Batch: 44/226 (19.9%) | Loss: 0.5807 | Batch time: 0.03s
2025-03-04 00:29:19,360 - INFO - [TRAIN] Epoch: 13/30 | Batch: 66/226 (29.6%) | Loss: 0.7691 | Batch time: 0.03s
2025-03-04 00:29:20,172 - INFO - [TRAIN] Epoch: 13/30 | Batch: 88/226 (39.4%) | Loss: 0.7245 | Batch time: 0.04s
2025-03-04 00:29:21,137 - INFO - [TRAIN] Epoch: 13/30 | Batch: 110/226 (49.1%) | Loss: 0.4276 | Batch time: 0.03s
2025-03-04 00:29:22,273 - INFO - [TRAIN] Epoch: 13/30 | Batch: 132/226 (58.8%) | Loss: 0.6892 | Batch time: 0.02s
2025-03-04 00:29:23,046 - INFO - [TRAIN] Epoch: 13/30 | Batch: 154/226 (68.6%) | Loss: 0.5952 | Batch time: 0.04s
2025-03-04 00:29:23,981 - INFO - [TRAIN] Epoch: 13/30 | Batch: 176/226 (78.3%) | Loss: 0.3814 | Batch time: 0.03s
2025-03-04 00:29:24,929 - INFO - [TRAIN] Epoch: 13/30 | Batch: 198/226 (88.1%) | Loss: 0.3729 | Batch time: 0.03s
2025-03-04 00:29:25,320 - INFO - [TRAIN] Epoch: 13/30 | Batch: 220/226 (97.8%) | Loss: 0.9508 | Batch time: 0.01s
2025-03-04 00:29:25,420 - INFO - [TRAIN] Epoch: 13/30 | Batch: 225/226 (100.0%) | Loss: 0.6570 | Batch time: 0.02s
2025-03-04 00:29:25,717 - INFO - [VAL] Epoch: 13/30 | Batch: 0/49 (2.0%) | Loss: 0.1449 | Batch time: 0.03s
2025-03-04 00:29:25,799 - INFO - [VAL] Epoch: 13/30 | Batch: 4/49 (10.2%) | Loss: 0.3222 | Batch time: 0.02s
2025-03-04 00:29:25,867 - INFO - [VAL] Epoch: 13/30 | Batch: 8/49 (18.4%) | Loss: 0.1692 | Batch time: 0.01s
2025-03-04 00:29:25,926 - INFO - [VAL] Epoch: 13/30 | Batch: 12/49 (26.5%) | Loss: 0.2933 | Batch time: 0.01s
2025-03-04 00:29:25,998 - INFO - [VAL] Epoch: 13/30 | Batch: 16/49 (34.7%) | Loss: 0.2565 | Batch time: 0.01s
2025-03-04 00:29:26,062 - INFO - [VAL] Epoch: 13/30 | Batch: 20/49 (42.9%) | Loss: 0.3711 | Batch time: 0.01s
2025-03-04 00:29:26,113 - INFO - [VAL] Epoch: 13/30 | Batch: 24/49 (51.0%) | Loss: 0.2232 | Batch time: 0.01s
2025-03-04 00:29:26,156 - INFO - [VAL] Epoch: 13/30 | Batch: 28/49 (59.2%) | Loss: 0.5697 | Batch time: 0.01s
2025-03-04 00:29:26,230 - INFO - [VAL] Epoch: 13/30 | Batch: 32/49 (67.3%) | Loss: 0.1997 | Batch time: 0.02s
2025-03-04 00:29:26,312 - INFO - [VAL] Epoch: 13/30 | Batch: 36/49 (75.5%) | Loss: 0.2627 | Batch time: 0.02s
2025-03-04 00:29:26,425 - INFO - [VAL] Epoch: 13/30 | Batch: 40/49 (83.7%) | Loss: 0.4212 | Batch time: 0.03s
2025-03-04 00:29:26,477 - INFO - [VAL] Epoch: 13/30 | Batch: 44/49 (91.8%) | Loss: 0.2166 | Batch time: 0.01s
2025-03-04 00:29:26,517 - INFO - [VAL] Epoch: 13/30 | Batch: 48/49 (100.0%) | Loss: 0.3384 | Batch time: 0.01s
2025-03-04 00:29:26,610 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 13)
2025-03-04 00:29:26,610 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:26,610 - INFO - Epoch 13/30 completed in 10.92s
2025-03-04 00:29:26,610 - INFO - Training   - Loss: 0.6626, Accuracy: 0.7810, F1: 0.7834
2025-03-04 00:29:26,610 - INFO - Validation - Loss: 0.3102, Accuracy: 0.8899, F1: 0.8913
2025-03-04 00:29:26,610 - INFO - Validation F1 improved from 0.8904 to 0.8913
2025-03-04 00:29:26,610 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:26,610 - INFO - Epoch 14/30
2025-03-04 00:29:26,610 - INFO - ----------------------------------------
2025-03-04 00:29:27,212 - INFO - [TRAIN] Epoch: 14/30 | Batch: 0/226 (0.4%) | Loss: 0.8771 | Batch time: 0.06s
2025-03-04 00:29:28,384 - INFO - [TRAIN] Epoch: 14/30 | Batch: 22/226 (10.2%) | Loss: 0.8266 | Batch time: 0.03s
2025-03-04 00:29:29,283 - INFO - [TRAIN] Epoch: 14/30 | Batch: 44/226 (19.9%) | Loss: 0.6084 | Batch time: 0.02s
2025-03-04 00:29:30,329 - INFO - [TRAIN] Epoch: 14/30 | Batch: 66/226 (29.6%) | Loss: 0.6093 | Batch time: 0.03s
2025-03-04 00:29:31,146 - INFO - [TRAIN] Epoch: 14/30 | Batch: 88/226 (39.4%) | Loss: 1.0356 | Batch time: 0.06s
2025-03-04 00:29:32,030 - INFO - [TRAIN] Epoch: 14/30 | Batch: 110/226 (49.1%) | Loss: 0.7529 | Batch time: 0.03s
2025-03-04 00:29:33,014 - INFO - [TRAIN] Epoch: 14/30 | Batch: 132/226 (58.8%) | Loss: 0.5651 | Batch time: 0.04s
2025-03-04 00:29:33,848 - INFO - [TRAIN] Epoch: 14/30 | Batch: 154/226 (68.6%) | Loss: 0.5065 | Batch time: 0.10s
2025-03-04 00:29:34,804 - INFO - [TRAIN] Epoch: 14/30 | Batch: 176/226 (78.3%) | Loss: 0.6302 | Batch time: 0.04s
2025-03-04 00:29:35,722 - INFO - [TRAIN] Epoch: 14/30 | Batch: 198/226 (88.1%) | Loss: 0.7104 | Batch time: 0.02s
2025-03-04 00:29:36,116 - INFO - [TRAIN] Epoch: 14/30 | Batch: 220/226 (97.8%) | Loss: 0.7191 | Batch time: 0.02s
2025-03-04 00:29:36,257 - INFO - [TRAIN] Epoch: 14/30 | Batch: 225/226 (100.0%) | Loss: 0.6151 | Batch time: 0.03s
2025-03-04 00:29:36,484 - INFO - [VAL] Epoch: 14/30 | Batch: 0/49 (2.0%) | Loss: 0.1365 | Batch time: 0.02s
2025-03-04 00:29:36,556 - INFO - [VAL] Epoch: 14/30 | Batch: 4/49 (10.2%) | Loss: 0.3077 | Batch time: 0.02s
2025-03-04 00:29:36,637 - INFO - [VAL] Epoch: 14/30 | Batch: 8/49 (18.4%) | Loss: 0.1616 | Batch time: 0.01s
2025-03-04 00:29:36,694 - INFO - [VAL] Epoch: 14/30 | Batch: 12/49 (26.5%) | Loss: 0.2803 | Batch time: 0.01s
2025-03-04 00:29:36,758 - INFO - [VAL] Epoch: 14/30 | Batch: 16/49 (34.7%) | Loss: 0.2437 | Batch time: 0.01s
2025-03-04 00:29:36,808 - INFO - [VAL] Epoch: 14/30 | Batch: 20/49 (42.9%) | Loss: 0.3785 | Batch time: 0.01s
2025-03-04 00:29:36,853 - INFO - [VAL] Epoch: 14/30 | Batch: 24/49 (51.0%) | Loss: 0.2038 | Batch time: 0.01s
2025-03-04 00:29:36,933 - INFO - [VAL] Epoch: 14/30 | Batch: 28/49 (59.2%) | Loss: 0.5689 | Batch time: 0.01s
2025-03-04 00:29:37,030 - INFO - [VAL] Epoch: 14/30 | Batch: 32/49 (67.3%) | Loss: 0.2044 | Batch time: 0.03s
2025-03-04 00:29:37,130 - INFO - [VAL] Epoch: 14/30 | Batch: 36/49 (75.5%) | Loss: 0.2295 | Batch time: 0.02s
2025-03-04 00:29:37,172 - INFO - [VAL] Epoch: 14/30 | Batch: 40/49 (83.7%) | Loss: 0.4250 | Batch time: 0.01s
2025-03-04 00:29:37,212 - INFO - [VAL] Epoch: 14/30 | Batch: 44/49 (91.8%) | Loss: 0.2222 | Batch time: 0.01s
2025-03-04 00:29:37,249 - INFO - [VAL] Epoch: 14/30 | Batch: 48/49 (100.0%) | Loss: 0.3573 | Batch time: 0.01s
2025-03-04 00:29:37,331 - INFO - Checkpoint saved: mobilenet_v3_small_v1_best.pth (Epoch 14)
2025-03-04 00:29:37,331 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:37,331 - INFO - Epoch 14/30 completed in 10.72s
2025-03-04 00:29:37,331 - INFO - Training   - Loss: 0.6561, Accuracy: 0.7804, F1: 0.7828
2025-03-04 00:29:37,331 - INFO - Validation - Loss: 0.3082, Accuracy: 0.8918, F1: 0.8930
2025-03-04 00:29:37,331 - INFO - Validation F1 improved from 0.8913 to 0.8930
2025-03-04 00:29:37,331 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:37,331 - INFO - Epoch 15/30
2025-03-04 00:29:37,331 - INFO - ----------------------------------------
2025-03-04 00:29:37,958 - INFO - [TRAIN] Epoch: 15/30 | Batch: 0/226 (0.4%) | Loss: 0.7444 | Batch time: 0.06s
2025-03-04 00:29:38,900 - INFO - [TRAIN] Epoch: 15/30 | Batch: 22/226 (10.2%) | Loss: 0.6657 | Batch time: 0.03s
2025-03-04 00:29:39,980 - INFO - [TRAIN] Epoch: 15/30 | Batch: 44/226 (19.9%) | Loss: 0.6524 | Batch time: 0.02s
2025-03-04 00:29:40,991 - INFO - [TRAIN] Epoch: 15/30 | Batch: 66/226 (29.6%) | Loss: 0.6229 | Batch time: 0.04s
2025-03-04 00:29:41,717 - INFO - [TRAIN] Epoch: 15/30 | Batch: 88/226 (39.4%) | Loss: 0.6427 | Batch time: 0.06s
2025-03-04 00:29:42,659 - INFO - [TRAIN] Epoch: 15/30 | Batch: 110/226 (49.1%) | Loss: 0.7252 | Batch time: 0.05s
2025-03-04 00:29:43,603 - INFO - [TRAIN] Epoch: 15/30 | Batch: 132/226 (58.8%) | Loss: 0.6275 | Batch time: 0.03s
2025-03-04 00:29:44,552 - INFO - [TRAIN] Epoch: 15/30 | Batch: 154/226 (68.6%) | Loss: 0.6290 | Batch time: 0.03s
2025-03-04 00:29:45,386 - INFO - [TRAIN] Epoch: 15/30 | Batch: 176/226 (78.3%) | Loss: 0.5549 | Batch time: 0.04s
2025-03-04 00:29:46,298 - INFO - [TRAIN] Epoch: 15/30 | Batch: 198/226 (88.1%) | Loss: 0.5967 | Batch time: 0.02s
2025-03-04 00:29:46,751 - INFO - [TRAIN] Epoch: 15/30 | Batch: 220/226 (97.8%) | Loss: 0.7679 | Batch time: 0.03s
2025-03-04 00:29:46,848 - INFO - [TRAIN] Epoch: 15/30 | Batch: 225/226 (100.0%) | Loss: 0.6005 | Batch time: 0.01s
2025-03-04 00:29:47,014 - INFO - [VAL] Epoch: 15/30 | Batch: 0/49 (2.0%) | Loss: 0.1505 | Batch time: 0.01s
2025-03-04 00:29:47,110 - INFO - [VAL] Epoch: 15/30 | Batch: 4/49 (10.2%) | Loss: 0.2956 | Batch time: 0.02s
2025-03-04 00:29:47,198 - INFO - [VAL] Epoch: 15/30 | Batch: 8/49 (18.4%) | Loss: 0.1702 | Batch time: 0.01s
2025-03-04 00:29:47,252 - INFO - [VAL] Epoch: 15/30 | Batch: 12/49 (26.5%) | Loss: 0.3052 | Batch time: 0.01s
2025-03-04 00:29:47,394 - INFO - [VAL] Epoch: 15/30 | Batch: 16/49 (34.7%) | Loss: 0.2562 | Batch time: 0.01s
2025-03-04 00:29:47,483 - INFO - [VAL] Epoch: 15/30 | Batch: 20/49 (42.9%) | Loss: 0.3813 | Batch time: 0.02s
2025-03-04 00:29:47,588 - INFO - [VAL] Epoch: 15/30 | Batch: 24/49 (51.0%) | Loss: 0.2129 | Batch time: 0.02s
2025-03-04 00:29:47,634 - INFO - [VAL] Epoch: 15/30 | Batch: 28/49 (59.2%) | Loss: 0.5642 | Batch time: 0.01s
2025-03-04 00:29:47,676 - INFO - [VAL] Epoch: 15/30 | Batch: 32/49 (67.3%) | Loss: 0.1961 | Batch time: 0.01s
2025-03-04 00:29:47,727 - INFO - [VAL] Epoch: 15/30 | Batch: 36/49 (75.5%) | Loss: 0.2408 | Batch time: 0.01s
2025-03-04 00:29:47,768 - INFO - [VAL] Epoch: 15/30 | Batch: 40/49 (83.7%) | Loss: 0.4104 | Batch time: 0.01s
2025-03-04 00:29:47,810 - INFO - [VAL] Epoch: 15/30 | Batch: 44/49 (91.8%) | Loss: 0.2306 | Batch time: 0.01s
2025-03-04 00:29:47,849 - INFO - [VAL] Epoch: 15/30 | Batch: 48/49 (100.0%) | Loss: 0.3554 | Batch time: 0.01s
2025-03-04 00:29:47,853 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:47,853 - INFO - Epoch 15/30 completed in 10.52s
2025-03-04 00:29:47,853 - INFO - Training   - Loss: 0.6671, Accuracy: 0.7801, F1: 0.7819
2025-03-04 00:29:47,853 - INFO - Validation - Loss: 0.3097, Accuracy: 0.8895, F1: 0.8906
2025-03-04 00:29:47,853 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:47,945 - INFO - Checkpoint saved: checkpoint_epoch_15.pth (Epoch 15)
2025-03-04 00:29:47,945 - INFO - Epoch 16/30
2025-03-04 00:29:47,945 - INFO - ----------------------------------------
2025-03-04 00:29:48,541 - INFO - [TRAIN] Epoch: 16/30 | Batch: 0/226 (0.4%) | Loss: 0.6008 | Batch time: 0.03s
2025-03-04 00:29:49,569 - INFO - [TRAIN] Epoch: 16/30 | Batch: 22/226 (10.2%) | Loss: 0.4984 | Batch time: 0.10s
2025-03-04 00:29:50,522 - INFO - [TRAIN] Epoch: 16/30 | Batch: 44/226 (19.9%) | Loss: 0.5514 | Batch time: 0.03s
2025-03-04 00:29:51,620 - INFO - [TRAIN] Epoch: 16/30 | Batch: 66/226 (29.6%) | Loss: 0.6741 | Batch time: 0.03s
2025-03-04 00:29:52,525 - INFO - [TRAIN] Epoch: 16/30 | Batch: 88/226 (39.4%) | Loss: 0.9953 | Batch time: 0.09s
2025-03-04 00:29:53,339 - INFO - [TRAIN] Epoch: 16/30 | Batch: 110/226 (49.1%) | Loss: 0.3401 | Batch time: 0.04s
2025-03-04 00:29:54,278 - INFO - [TRAIN] Epoch: 16/30 | Batch: 132/226 (58.8%) | Loss: 0.5267 | Batch time: 0.03s
2025-03-04 00:29:55,053 - INFO - [TRAIN] Epoch: 16/30 | Batch: 154/226 (68.6%) | Loss: 0.8445 | Batch time: 0.04s
2025-03-04 00:29:55,991 - INFO - [TRAIN] Epoch: 16/30 | Batch: 176/226 (78.3%) | Loss: 0.7186 | Batch time: 0.03s
2025-03-04 00:29:56,804 - INFO - [TRAIN] Epoch: 16/30 | Batch: 198/226 (88.1%) | Loss: 0.6986 | Batch time: 0.03s
2025-03-04 00:29:57,196 - INFO - [TRAIN] Epoch: 16/30 | Batch: 220/226 (97.8%) | Loss: 0.6100 | Batch time: 0.02s
2025-03-04 00:29:57,320 - INFO - [TRAIN] Epoch: 16/30 | Batch: 225/226 (100.0%) | Loss: 0.5502 | Batch time: 0.02s
2025-03-04 00:29:57,589 - INFO - [VAL] Epoch: 16/30 | Batch: 0/49 (2.0%) | Loss: 0.1564 | Batch time: 0.02s
2025-03-04 00:29:57,671 - INFO - [VAL] Epoch: 16/30 | Batch: 4/49 (10.2%) | Loss: 0.2741 | Batch time: 0.02s
2025-03-04 00:29:57,723 - INFO - [VAL] Epoch: 16/30 | Batch: 8/49 (18.4%) | Loss: 0.1756 | Batch time: 0.01s
2025-03-04 00:29:57,783 - INFO - [VAL] Epoch: 16/30 | Batch: 12/49 (26.5%) | Loss: 0.3101 | Batch time: 0.02s
2025-03-04 00:29:57,864 - INFO - [VAL] Epoch: 16/30 | Batch: 16/49 (34.7%) | Loss: 0.2628 | Batch time: 0.02s
2025-03-04 00:29:57,917 - INFO - [VAL] Epoch: 16/30 | Batch: 20/49 (42.9%) | Loss: 0.3900 | Batch time: 0.01s
2025-03-04 00:29:57,962 - INFO - [VAL] Epoch: 16/30 | Batch: 24/49 (51.0%) | Loss: 0.2210 | Batch time: 0.01s
2025-03-04 00:29:58,044 - INFO - [VAL] Epoch: 16/30 | Batch: 28/49 (59.2%) | Loss: 0.5363 | Batch time: 0.01s
2025-03-04 00:29:58,131 - INFO - [VAL] Epoch: 16/30 | Batch: 32/49 (67.3%) | Loss: 0.2024 | Batch time: 0.02s
2025-03-04 00:29:58,231 - INFO - [VAL] Epoch: 16/30 | Batch: 36/49 (75.5%) | Loss: 0.2386 | Batch time: 0.02s
2025-03-04 00:29:58,278 - INFO - [VAL] Epoch: 16/30 | Batch: 40/49 (83.7%) | Loss: 0.4073 | Batch time: 0.01s
2025-03-04 00:29:58,318 - INFO - [VAL] Epoch: 16/30 | Batch: 44/49 (91.8%) | Loss: 0.2325 | Batch time: 0.01s
2025-03-04 00:29:58,357 - INFO - [VAL] Epoch: 16/30 | Batch: 48/49 (100.0%) | Loss: 0.3748 | Batch time: 0.01s
2025-03-04 00:29:58,361 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:58,361 - INFO - Epoch 16/30 completed in 10.42s
2025-03-04 00:29:58,361 - INFO - Training   - Loss: 0.6664, Accuracy: 0.7837, F1: 0.7861
2025-03-04 00:29:58,361 - INFO - Validation - Loss: 0.3129, Accuracy: 0.8866, F1: 0.8877
2025-03-04 00:29:58,361 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:29:58,361 - INFO - Epoch 17/30
2025-03-04 00:29:58,361 - INFO - ----------------------------------------
2025-03-04 00:29:59,055 - INFO - [TRAIN] Epoch: 17/30 | Batch: 0/226 (0.4%) | Loss: 0.7683 | Batch time: 0.07s
2025-03-04 00:30:00,078 - INFO - [TRAIN] Epoch: 17/30 | Batch: 22/226 (10.2%) | Loss: 0.8267 | Batch time: 0.04s
2025-03-04 00:30:01,068 - INFO - [TRAIN] Epoch: 17/30 | Batch: 44/226 (19.9%) | Loss: 0.5884 | Batch time: 0.04s
2025-03-04 00:30:02,094 - INFO - [TRAIN] Epoch: 17/30 | Batch: 66/226 (29.6%) | Loss: 0.4892 | Batch time: 0.03s
2025-03-04 00:30:02,951 - INFO - [TRAIN] Epoch: 17/30 | Batch: 88/226 (39.4%) | Loss: 0.5663 | Batch time: 0.06s
2025-03-04 00:30:03,817 - INFO - [TRAIN] Epoch: 17/30 | Batch: 110/226 (49.1%) | Loss: 0.6644 | Batch time: 0.03s
2025-03-04 00:30:04,828 - INFO - [TRAIN] Epoch: 17/30 | Batch: 132/226 (58.8%) | Loss: 0.5072 | Batch time: 0.08s
2025-03-04 00:30:05,634 - INFO - [TRAIN] Epoch: 17/30 | Batch: 154/226 (68.6%) | Loss: 0.5791 | Batch time: 0.04s
2025-03-04 00:30:06,476 - INFO - [TRAIN] Epoch: 17/30 | Batch: 176/226 (78.3%) | Loss: 0.6394 | Batch time: 0.04s
2025-03-04 00:30:07,332 - INFO - [TRAIN] Epoch: 17/30 | Batch: 198/226 (88.1%) | Loss: 0.7452 | Batch time: 0.02s
2025-03-04 00:30:07,709 - INFO - [TRAIN] Epoch: 17/30 | Batch: 220/226 (97.8%) | Loss: 0.4236 | Batch time: 0.02s
2025-03-04 00:30:07,839 - INFO - [TRAIN] Epoch: 17/30 | Batch: 225/226 (100.0%) | Loss: 0.7033 | Batch time: 0.03s
2025-03-04 00:30:08,067 - INFO - [VAL] Epoch: 17/30 | Batch: 0/49 (2.0%) | Loss: 0.1480 | Batch time: 0.02s
2025-03-04 00:30:08,140 - INFO - [VAL] Epoch: 17/30 | Batch: 4/49 (10.2%) | Loss: 0.2785 | Batch time: 0.01s
2025-03-04 00:30:08,210 - INFO - [VAL] Epoch: 17/30 | Batch: 8/49 (18.4%) | Loss: 0.1732 | Batch time: 0.01s
2025-03-04 00:30:08,268 - INFO - [VAL] Epoch: 17/30 | Batch: 12/49 (26.5%) | Loss: 0.3050 | Batch time: 0.01s
2025-03-04 00:30:08,331 - INFO - [VAL] Epoch: 17/30 | Batch: 16/49 (34.7%) | Loss: 0.2554 | Batch time: 0.02s
2025-03-04 00:30:08,392 - INFO - [VAL] Epoch: 17/30 | Batch: 20/49 (42.9%) | Loss: 0.3851 | Batch time: 0.01s
2025-03-04 00:30:08,436 - INFO - [VAL] Epoch: 17/30 | Batch: 24/49 (51.0%) | Loss: 0.2172 | Batch time: 0.01s
2025-03-04 00:30:08,511 - INFO - [VAL] Epoch: 17/30 | Batch: 28/49 (59.2%) | Loss: 0.5629 | Batch time: 0.02s
2025-03-04 00:30:08,588 - INFO - [VAL] Epoch: 17/30 | Batch: 32/49 (67.3%) | Loss: 0.1964 | Batch time: 0.02s
2025-03-04 00:30:08,702 - INFO - [VAL] Epoch: 17/30 | Batch: 36/49 (75.5%) | Loss: 0.2339 | Batch time: 0.03s
2025-03-04 00:30:08,752 - INFO - [VAL] Epoch: 17/30 | Batch: 40/49 (83.7%) | Loss: 0.4007 | Batch time: 0.01s
2025-03-04 00:30:08,792 - INFO - [VAL] Epoch: 17/30 | Batch: 44/49 (91.8%) | Loss: 0.2336 | Batch time: 0.01s
2025-03-04 00:30:08,841 - INFO - [VAL] Epoch: 17/30 | Batch: 48/49 (100.0%) | Loss: 0.3494 | Batch time: 0.01s
2025-03-04 00:30:08,845 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:08,845 - INFO - Epoch 17/30 completed in 10.48s
2025-03-04 00:30:08,845 - INFO - Training   - Loss: 0.6479, Accuracy: 0.7818, F1: 0.7833
2025-03-04 00:30:08,845 - INFO - Validation - Loss: 0.3101, Accuracy: 0.8882, F1: 0.8894
2025-03-04 00:30:08,845 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:08,845 - INFO - Epoch 18/30
2025-03-04 00:30:08,845 - INFO - ----------------------------------------
2025-03-04 00:30:09,329 - INFO - [TRAIN] Epoch: 18/30 | Batch: 0/226 (0.4%) | Loss: 0.7401 | Batch time: 0.03s
2025-03-04 00:30:10,535 - INFO - [TRAIN] Epoch: 18/30 | Batch: 22/226 (10.2%) | Loss: 0.4854 | Batch time: 0.03s
2025-03-04 00:30:11,398 - INFO - [TRAIN] Epoch: 18/30 | Batch: 44/226 (19.9%) | Loss: 0.7200 | Batch time: 0.03s
2025-03-04 00:30:12,281 - INFO - [TRAIN] Epoch: 18/30 | Batch: 66/226 (29.6%) | Loss: 0.6116 | Batch time: 0.04s
2025-03-04 00:30:13,203 - INFO - [TRAIN] Epoch: 18/30 | Batch: 88/226 (39.4%) | Loss: 0.9573 | Batch time: 0.03s
2025-03-04 00:30:14,150 - INFO - [TRAIN] Epoch: 18/30 | Batch: 110/226 (49.1%) | Loss: 0.6561 | Batch time: 0.03s
2025-03-04 00:30:15,056 - INFO - [TRAIN] Epoch: 18/30 | Batch: 132/226 (58.8%) | Loss: 0.5565 | Batch time: 0.07s
2025-03-04 00:30:15,965 - INFO - [TRAIN] Epoch: 18/30 | Batch: 154/226 (68.6%) | Loss: 0.7567 | Batch time: 0.04s
2025-03-04 00:30:16,974 - INFO - [TRAIN] Epoch: 18/30 | Batch: 176/226 (78.3%) | Loss: 0.6130 | Batch time: 0.03s
2025-03-04 00:30:17,799 - INFO - [TRAIN] Epoch: 18/30 | Batch: 198/226 (88.1%) | Loss: 0.3660 | Batch time: 0.03s
2025-03-04 00:30:18,257 - INFO - [TRAIN] Epoch: 18/30 | Batch: 220/226 (97.8%) | Loss: 0.7453 | Batch time: 0.01s
2025-03-04 00:30:18,326 - INFO - [TRAIN] Epoch: 18/30 | Batch: 225/226 (100.0%) | Loss: 0.6449 | Batch time: 0.01s
2025-03-04 00:30:18,539 - INFO - [VAL] Epoch: 18/30 | Batch: 0/49 (2.0%) | Loss: 0.1467 | Batch time: 0.02s
2025-03-04 00:30:18,673 - INFO - [VAL] Epoch: 18/30 | Batch: 4/49 (10.2%) | Loss: 0.2878 | Batch time: 0.01s
2025-03-04 00:30:18,744 - INFO - [VAL] Epoch: 18/30 | Batch: 8/49 (18.4%) | Loss: 0.1676 | Batch time: 0.01s
2025-03-04 00:30:18,801 - INFO - [VAL] Epoch: 18/30 | Batch: 12/49 (26.5%) | Loss: 0.3099 | Batch time: 0.01s
2025-03-04 00:30:18,867 - INFO - [VAL] Epoch: 18/30 | Batch: 16/49 (34.7%) | Loss: 0.2560 | Batch time: 0.02s
2025-03-04 00:30:18,925 - INFO - [VAL] Epoch: 18/30 | Batch: 20/49 (42.9%) | Loss: 0.3758 | Batch time: 0.01s
2025-03-04 00:30:18,971 - INFO - [VAL] Epoch: 18/30 | Batch: 24/49 (51.0%) | Loss: 0.2107 | Batch time: 0.01s
2025-03-04 00:30:19,012 - INFO - [VAL] Epoch: 18/30 | Batch: 28/49 (59.2%) | Loss: 0.5629 | Batch time: 0.01s
2025-03-04 00:30:19,052 - INFO - [VAL] Epoch: 18/30 | Batch: 32/49 (67.3%) | Loss: 0.1993 | Batch time: 0.01s
2025-03-04 00:30:19,093 - INFO - [VAL] Epoch: 18/30 | Batch: 36/49 (75.5%) | Loss: 0.2385 | Batch time: 0.01s
2025-03-04 00:30:19,174 - INFO - [VAL] Epoch: 18/30 | Batch: 40/49 (83.7%) | Loss: 0.4002 | Batch time: 0.02s
2025-03-04 00:30:19,259 - INFO - [VAL] Epoch: 18/30 | Batch: 44/49 (91.8%) | Loss: 0.2331 | Batch time: 0.03s
2025-03-04 00:30:19,354 - INFO - [VAL] Epoch: 18/30 | Batch: 48/49 (100.0%) | Loss: 0.3501 | Batch time: 0.02s
2025-03-04 00:30:19,359 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:19,359 - INFO - Epoch 18/30 completed in 10.51s
2025-03-04 00:30:19,359 - INFO - Training   - Loss: 0.6470, Accuracy: 0.7866, F1: 0.7889
2025-03-04 00:30:19,359 - INFO - Validation - Loss: 0.3096, Accuracy: 0.8876, F1: 0.8887
2025-03-04 00:30:19,359 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:19,359 - INFO - Epoch 19/30
2025-03-04 00:30:19,359 - INFO - ----------------------------------------
2025-03-04 00:30:19,920 - INFO - [TRAIN] Epoch: 19/30 | Batch: 0/226 (0.4%) | Loss: 0.4194 | Batch time: 0.02s
2025-03-04 00:30:21,077 - INFO - [TRAIN] Epoch: 19/30 | Batch: 22/226 (10.2%) | Loss: 0.6468 | Batch time: 0.12s
2025-03-04 00:30:22,067 - INFO - [TRAIN] Epoch: 19/30 | Batch: 44/226 (19.9%) | Loss: 0.6794 | Batch time: 0.03s
2025-03-04 00:30:23,184 - INFO - [TRAIN] Epoch: 19/30 | Batch: 66/226 (29.6%) | Loss: 0.4339 | Batch time: 0.03s
2025-03-04 00:30:24,041 - INFO - [TRAIN] Epoch: 19/30 | Batch: 88/226 (39.4%) | Loss: 0.7481 | Batch time: 0.07s
2025-03-04 00:30:24,935 - INFO - [TRAIN] Epoch: 19/30 | Batch: 110/226 (49.1%) | Loss: 0.5051 | Batch time: 0.03s
2025-03-04 00:30:25,773 - INFO - [TRAIN] Epoch: 19/30 | Batch: 132/226 (58.8%) | Loss: 0.5831 | Batch time: 0.03s
2025-03-04 00:30:26,742 - INFO - [TRAIN] Epoch: 19/30 | Batch: 154/226 (68.6%) | Loss: 0.7051 | Batch time: 0.05s
2025-03-04 00:30:27,722 - INFO - [TRAIN] Epoch: 19/30 | Batch: 176/226 (78.3%) | Loss: 0.4350 | Batch time: 0.03s
2025-03-04 00:30:28,600 - INFO - [TRAIN] Epoch: 19/30 | Batch: 198/226 (88.1%) | Loss: 0.4007 | Batch time: 0.02s
2025-03-04 00:30:28,991 - INFO - [TRAIN] Epoch: 19/30 | Batch: 220/226 (97.8%) | Loss: 0.5658 | Batch time: 0.02s
2025-03-04 00:30:29,136 - INFO - [TRAIN] Epoch: 19/30 | Batch: 225/226 (100.0%) | Loss: 0.5370 | Batch time: 0.03s
2025-03-04 00:30:29,372 - INFO - [VAL] Epoch: 19/30 | Batch: 0/49 (2.0%) | Loss: 0.1542 | Batch time: 0.01s
2025-03-04 00:30:29,440 - INFO - [VAL] Epoch: 19/30 | Batch: 4/49 (10.2%) | Loss: 0.2812 | Batch time: 0.01s
2025-03-04 00:30:29,501 - INFO - [VAL] Epoch: 19/30 | Batch: 8/49 (18.4%) | Loss: 0.1682 | Batch time: 0.01s
2025-03-04 00:30:29,562 - INFO - [VAL] Epoch: 19/30 | Batch: 12/49 (26.5%) | Loss: 0.3118 | Batch time: 0.02s
2025-03-04 00:30:29,623 - INFO - [VAL] Epoch: 19/30 | Batch: 16/49 (34.7%) | Loss: 0.2592 | Batch time: 0.01s
2025-03-04 00:30:29,682 - INFO - [VAL] Epoch: 19/30 | Batch: 20/49 (42.9%) | Loss: 0.3856 | Batch time: 0.01s
2025-03-04 00:30:29,738 - INFO - [VAL] Epoch: 19/30 | Batch: 24/49 (51.0%) | Loss: 0.2141 | Batch time: 0.02s
2025-03-04 00:30:29,813 - INFO - [VAL] Epoch: 19/30 | Batch: 28/49 (59.2%) | Loss: 0.5646 | Batch time: 0.02s
2025-03-04 00:30:29,916 - INFO - [VAL] Epoch: 19/30 | Batch: 32/49 (67.3%) | Loss: 0.1996 | Batch time: 0.03s
2025-03-04 00:30:29,995 - INFO - [VAL] Epoch: 19/30 | Batch: 36/49 (75.5%) | Loss: 0.2375 | Batch time: 0.01s
2025-03-04 00:30:30,035 - INFO - [VAL] Epoch: 19/30 | Batch: 40/49 (83.7%) | Loss: 0.3926 | Batch time: 0.01s
2025-03-04 00:30:30,076 - INFO - [VAL] Epoch: 19/30 | Batch: 44/49 (91.8%) | Loss: 0.2326 | Batch time: 0.01s
2025-03-04 00:30:30,115 - INFO - [VAL] Epoch: 19/30 | Batch: 48/49 (100.0%) | Loss: 0.3472 | Batch time: 0.01s
2025-03-04 00:30:30,119 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:30,119 - INFO - Epoch 19/30 completed in 10.76s
2025-03-04 00:30:30,119 - INFO - Training   - Loss: 0.6640, Accuracy: 0.7789, F1: 0.7811
2025-03-04 00:30:30,119 - INFO - Validation - Loss: 0.3098, Accuracy: 0.8876, F1: 0.8889
2025-03-04 00:30:30,119 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:30,119 - INFO - Epoch 20/30
2025-03-04 00:30:30,119 - INFO - ----------------------------------------
2025-03-04 00:30:30,786 - INFO - [TRAIN] Epoch: 20/30 | Batch: 0/226 (0.4%) | Loss: 0.6989 | Batch time: 0.04s
2025-03-04 00:30:31,784 - INFO - [TRAIN] Epoch: 20/30 | Batch: 22/226 (10.2%) | Loss: 0.6679 | Batch time: 0.04s
2025-03-04 00:30:32,776 - INFO - [TRAIN] Epoch: 20/30 | Batch: 44/226 (19.9%) | Loss: 0.4969 | Batch time: 0.03s
2025-03-04 00:30:33,782 - INFO - [TRAIN] Epoch: 20/30 | Batch: 66/226 (29.6%) | Loss: 0.6848 | Batch time: 0.05s
2025-03-04 00:30:34,520 - INFO - [TRAIN] Epoch: 20/30 | Batch: 88/226 (39.4%) | Loss: 0.7785 | Batch time: 0.03s
2025-03-04 00:30:35,427 - INFO - [TRAIN] Epoch: 20/30 | Batch: 110/226 (49.1%) | Loss: 0.5134 | Batch time: 0.03s
2025-03-04 00:30:36,361 - INFO - [TRAIN] Epoch: 20/30 | Batch: 132/226 (58.8%) | Loss: 0.8190 | Batch time: 0.02s
2025-03-04 00:30:37,169 - INFO - [TRAIN] Epoch: 20/30 | Batch: 154/226 (68.6%) | Loss: 0.8268 | Batch time: 0.03s
2025-03-04 00:30:38,076 - INFO - [TRAIN] Epoch: 20/30 | Batch: 176/226 (78.3%) | Loss: 0.6563 | Batch time: 0.03s
2025-03-04 00:30:38,967 - INFO - [TRAIN] Epoch: 20/30 | Batch: 198/226 (88.1%) | Loss: 0.6750 | Batch time: 0.02s
2025-03-04 00:30:39,313 - INFO - [TRAIN] Epoch: 20/30 | Batch: 220/226 (97.8%) | Loss: 0.3903 | Batch time: 0.01s
2025-03-04 00:30:39,437 - INFO - [TRAIN] Epoch: 20/30 | Batch: 225/226 (100.0%) | Loss: 0.8722 | Batch time: 0.02s
2025-03-04 00:30:39,644 - INFO - [VAL] Epoch: 20/30 | Batch: 0/49 (2.0%) | Loss: 0.1500 | Batch time: 0.02s
2025-03-04 00:30:39,777 - INFO - [VAL] Epoch: 20/30 | Batch: 4/49 (10.2%) | Loss: 0.2786 | Batch time: 0.01s
2025-03-04 00:30:39,829 - INFO - [VAL] Epoch: 20/30 | Batch: 8/49 (18.4%) | Loss: 0.1702 | Batch time: 0.01s
2025-03-04 00:30:39,881 - INFO - [VAL] Epoch: 20/30 | Batch: 12/49 (26.5%) | Loss: 0.3109 | Batch time: 0.01s
2025-03-04 00:30:39,947 - INFO - [VAL] Epoch: 20/30 | Batch: 16/49 (34.7%) | Loss: 0.2615 | Batch time: 0.02s
2025-03-04 00:30:40,000 - INFO - [VAL] Epoch: 20/30 | Batch: 20/49 (42.9%) | Loss: 0.3879 | Batch time: 0.01s
2025-03-04 00:30:40,044 - INFO - [VAL] Epoch: 20/30 | Batch: 24/49 (51.0%) | Loss: 0.2185 | Batch time: 0.01s
2025-03-04 00:30:40,116 - INFO - [VAL] Epoch: 20/30 | Batch: 28/49 (59.2%) | Loss: 0.5604 | Batch time: 0.02s
2025-03-04 00:30:40,191 - INFO - [VAL] Epoch: 20/30 | Batch: 32/49 (67.3%) | Loss: 0.1966 | Batch time: 0.02s
2025-03-04 00:30:40,299 - INFO - [VAL] Epoch: 20/30 | Batch: 36/49 (75.5%) | Loss: 0.2387 | Batch time: 0.02s
2025-03-04 00:30:40,359 - INFO - [VAL] Epoch: 20/30 | Batch: 40/49 (83.7%) | Loss: 0.4020 | Batch time: 0.01s
2025-03-04 00:30:40,399 - INFO - [VAL] Epoch: 20/30 | Batch: 44/49 (91.8%) | Loss: 0.2324 | Batch time: 0.01s
2025-03-04 00:30:40,437 - INFO - [VAL] Epoch: 20/30 | Batch: 48/49 (100.0%) | Loss: 0.3530 | Batch time: 0.01s
2025-03-04 00:30:40,441 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:40,441 - INFO - Epoch 20/30 completed in 10.32s
2025-03-04 00:30:40,441 - INFO - Training   - Loss: 0.6430, Accuracy: 0.7824, F1: 0.7845
2025-03-04 00:30:40,441 - INFO - Validation - Loss: 0.3113, Accuracy: 0.8853, F1: 0.8867
2025-03-04 00:30:40,441 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:40,486 - INFO - Checkpoint saved: checkpoint_epoch_20.pth (Epoch 20)
2025-03-04 00:30:40,487 - INFO - Epoch 21/30
2025-03-04 00:30:40,487 - INFO - ----------------------------------------
2025-03-04 00:30:41,054 - INFO - [TRAIN] Epoch: 21/30 | Batch: 0/226 (0.4%) | Loss: 0.4479 | Batch time: 0.05s
2025-03-04 00:30:41,947 - INFO - [TRAIN] Epoch: 21/30 | Batch: 22/226 (10.2%) | Loss: 0.5395 | Batch time: 0.04s
2025-03-04 00:30:42,975 - INFO - [TRAIN] Epoch: 21/30 | Batch: 44/226 (19.9%) | Loss: 0.4500 | Batch time: 0.02s
2025-03-04 00:30:44,047 - INFO - [TRAIN] Epoch: 21/30 | Batch: 66/226 (29.6%) | Loss: 0.4705 | Batch time: 0.03s
2025-03-04 00:30:44,796 - INFO - [TRAIN] Epoch: 21/30 | Batch: 88/226 (39.4%) | Loss: 0.6293 | Batch time: 0.05s
2025-03-04 00:30:45,669 - INFO - [TRAIN] Epoch: 21/30 | Batch: 110/226 (49.1%) | Loss: 0.6275 | Batch time: 0.03s
2025-03-04 00:30:46,665 - INFO - [TRAIN] Epoch: 21/30 | Batch: 132/226 (58.8%) | Loss: 0.4714 | Batch time: 0.02s
2025-03-04 00:30:47,546 - INFO - [TRAIN] Epoch: 21/30 | Batch: 154/226 (68.6%) | Loss: 0.4863 | Batch time: 0.05s
2025-03-04 00:30:48,373 - INFO - [TRAIN] Epoch: 21/30 | Batch: 176/226 (78.3%) | Loss: 0.5720 | Batch time: 0.04s
2025-03-04 00:30:49,340 - INFO - [TRAIN] Epoch: 21/30 | Batch: 198/226 (88.1%) | Loss: 0.4143 | Batch time: 0.02s
2025-03-04 00:30:49,800 - INFO - [TRAIN] Epoch: 21/30 | Batch: 220/226 (97.8%) | Loss: 0.5644 | Batch time: 0.03s
2025-03-04 00:30:49,897 - INFO - [TRAIN] Epoch: 21/30 | Batch: 225/226 (100.0%) | Loss: 0.5298 | Batch time: 0.01s
2025-03-04 00:30:50,120 - INFO - [VAL] Epoch: 21/30 | Batch: 0/49 (2.0%) | Loss: 0.1477 | Batch time: 0.02s
2025-03-04 00:30:50,191 - INFO - [VAL] Epoch: 21/30 | Batch: 4/49 (10.2%) | Loss: 0.2699 | Batch time: 0.02s
2025-03-04 00:30:50,253 - INFO - [VAL] Epoch: 21/30 | Batch: 8/49 (18.4%) | Loss: 0.1632 | Batch time: 0.01s
2025-03-04 00:30:50,304 - INFO - [VAL] Epoch: 21/30 | Batch: 12/49 (26.5%) | Loss: 0.3049 | Batch time: 0.01s
2025-03-04 00:30:50,398 - INFO - [VAL] Epoch: 21/30 | Batch: 16/49 (34.7%) | Loss: 0.2574 | Batch time: 0.04s
2025-03-04 00:30:50,463 - INFO - [VAL] Epoch: 21/30 | Batch: 20/49 (42.9%) | Loss: 0.3802 | Batch time: 0.01s
2025-03-04 00:30:50,549 - INFO - [VAL] Epoch: 21/30 | Batch: 24/49 (51.0%) | Loss: 0.2105 | Batch time: 0.03s
2025-03-04 00:30:50,653 - INFO - [VAL] Epoch: 21/30 | Batch: 28/49 (59.2%) | Loss: 0.5471 | Batch time: 0.02s
2025-03-04 00:30:50,693 - INFO - [VAL] Epoch: 21/30 | Batch: 32/49 (67.3%) | Loss: 0.1952 | Batch time: 0.01s
2025-03-04 00:30:50,734 - INFO - [VAL] Epoch: 21/30 | Batch: 36/49 (75.5%) | Loss: 0.2326 | Batch time: 0.01s
2025-03-04 00:30:50,772 - INFO - [VAL] Epoch: 21/30 | Batch: 40/49 (83.7%) | Loss: 0.3972 | Batch time: 0.01s
2025-03-04 00:30:50,813 - INFO - [VAL] Epoch: 21/30 | Batch: 44/49 (91.8%) | Loss: 0.2243 | Batch time: 0.01s
2025-03-04 00:30:50,850 - INFO - [VAL] Epoch: 21/30 | Batch: 48/49 (100.0%) | Loss: 0.3612 | Batch time: 0.01s
2025-03-04 00:30:50,854 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:50,854 - INFO - Epoch 21/30 completed in 10.37s
2025-03-04 00:30:50,854 - INFO - Training   - Loss: 0.6511, Accuracy: 0.7867, F1: 0.7887
2025-03-04 00:30:50,854 - INFO - Validation - Loss: 0.3050, Accuracy: 0.8895, F1: 0.8909
2025-03-04 00:30:50,854 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:30:50,854 - INFO - Epoch 22/30
2025-03-04 00:30:50,854 - INFO - ----------------------------------------
2025-03-04 00:30:51,459 - INFO - [TRAIN] Epoch: 22/30 | Batch: 0/226 (0.4%) | Loss: 0.6274 | Batch time: 0.03s
2025-03-04 00:30:52,425 - INFO - [TRAIN] Epoch: 22/30 | Batch: 22/226 (10.2%) | Loss: 0.8594 | Batch time: 0.08s
2025-03-04 00:30:53,351 - INFO - [TRAIN] Epoch: 22/30 | Batch: 44/226 (19.9%) | Loss: 0.5617 | Batch time: 0.02s
2025-03-04 00:30:54,425 - INFO - [TRAIN] Epoch: 22/30 | Batch: 66/226 (29.6%) | Loss: 0.3564 | Batch time: 0.02s
2025-03-04 00:30:55,193 - INFO - [TRAIN] Epoch: 22/30 | Batch: 88/226 (39.4%) | Loss: 0.6830 | Batch time: 0.03s
2025-03-04 00:30:56,003 - INFO - [TRAIN] Epoch: 22/30 | Batch: 110/226 (49.1%) | Loss: 0.7381 | Batch time: 0.03s
2025-03-04 00:30:56,978 - INFO - [TRAIN] Epoch: 22/30 | Batch: 132/226 (58.8%) | Loss: 0.7347 | Batch time: 0.03s
2025-03-04 00:30:57,961 - INFO - [TRAIN] Epoch: 22/30 | Batch: 154/226 (68.6%) | Loss: 0.4558 | Batch time: 0.05s
2025-03-04 00:30:58,816 - INFO - [TRAIN] Epoch: 22/30 | Batch: 176/226 (78.3%) | Loss: 1.0683 | Batch time: 0.03s
2025-03-04 00:30:59,805 - INFO - [TRAIN] Epoch: 22/30 | Batch: 198/226 (88.1%) | Loss: 0.9304 | Batch time: 0.02s
2025-03-04 00:31:00,299 - INFO - [TRAIN] Epoch: 22/30 | Batch: 220/226 (97.8%) | Loss: 0.6988 | Batch time: 0.03s
2025-03-04 00:31:00,374 - INFO - [TRAIN] Epoch: 22/30 | Batch: 225/226 (100.0%) | Loss: 0.7055 | Batch time: 0.01s
2025-03-04 00:31:00,637 - INFO - [VAL] Epoch: 22/30 | Batch: 0/49 (2.0%) | Loss: 0.1464 | Batch time: 0.01s
2025-03-04 00:31:00,700 - INFO - [VAL] Epoch: 22/30 | Batch: 4/49 (10.2%) | Loss: 0.2753 | Batch time: 0.01s
2025-03-04 00:31:00,791 - INFO - [VAL] Epoch: 22/30 | Batch: 8/49 (18.4%) | Loss: 0.1638 | Batch time: 0.02s
2025-03-04 00:31:00,878 - INFO - [VAL] Epoch: 22/30 | Batch: 12/49 (26.5%) | Loss: 0.3049 | Batch time: 0.03s
2025-03-04 00:31:01,021 - INFO - [VAL] Epoch: 22/30 | Batch: 16/49 (34.7%) | Loss: 0.2571 | Batch time: 0.03s
2025-03-04 00:31:01,086 - INFO - [VAL] Epoch: 22/30 | Batch: 20/49 (42.9%) | Loss: 0.3798 | Batch time: 0.01s
2025-03-04 00:31:01,128 - INFO - [VAL] Epoch: 22/30 | Batch: 24/49 (51.0%) | Loss: 0.2120 | Batch time: 0.01s
2025-03-04 00:31:01,170 - INFO - [VAL] Epoch: 22/30 | Batch: 28/49 (59.2%) | Loss: 0.5479 | Batch time: 0.01s
2025-03-04 00:31:01,212 - INFO - [VAL] Epoch: 22/30 | Batch: 32/49 (67.3%) | Loss: 0.1933 | Batch time: 0.01s
2025-03-04 00:31:01,253 - INFO - [VAL] Epoch: 22/30 | Batch: 36/49 (75.5%) | Loss: 0.2375 | Batch time: 0.01s
2025-03-04 00:31:01,293 - INFO - [VAL] Epoch: 22/30 | Batch: 40/49 (83.7%) | Loss: 0.3957 | Batch time: 0.01s
2025-03-04 00:31:01,332 - INFO - [VAL] Epoch: 22/30 | Batch: 44/49 (91.8%) | Loss: 0.2260 | Batch time: 0.01s
2025-03-04 00:31:01,413 - INFO - [VAL] Epoch: 22/30 | Batch: 48/49 (100.0%) | Loss: 0.3572 | Batch time: 0.01s
2025-03-04 00:31:01,417 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:01,417 - INFO - Epoch 22/30 completed in 10.56s
2025-03-04 00:31:01,417 - INFO - Training   - Loss: 0.6622, Accuracy: 0.7821, F1: 0.7845
2025-03-04 00:31:01,417 - INFO - Validation - Loss: 0.3053, Accuracy: 0.8895, F1: 0.8908
2025-03-04 00:31:01,417 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:01,417 - INFO - Epoch 23/30
2025-03-04 00:31:01,417 - INFO - ----------------------------------------
2025-03-04 00:31:02,056 - INFO - [TRAIN] Epoch: 23/30 | Batch: 0/226 (0.4%) | Loss: 0.5186 | Batch time: 0.03s
2025-03-04 00:31:03,194 - INFO - [TRAIN] Epoch: 23/30 | Batch: 22/226 (10.2%) | Loss: 0.4235 | Batch time: 0.04s
2025-03-04 00:31:03,975 - INFO - [TRAIN] Epoch: 23/30 | Batch: 44/226 (19.9%) | Loss: 0.7412 | Batch time: 0.06s
2025-03-04 00:31:04,928 - INFO - [TRAIN] Epoch: 23/30 | Batch: 66/226 (29.6%) | Loss: 0.5081 | Batch time: 0.05s
2025-03-04 00:31:05,861 - INFO - [TRAIN] Epoch: 23/30 | Batch: 88/226 (39.4%) | Loss: 0.6638 | Batch time: 0.03s
2025-03-04 00:31:06,804 - INFO - [TRAIN] Epoch: 23/30 | Batch: 110/226 (49.1%) | Loss: 0.7152 | Batch time: 0.10s
2025-03-04 00:31:07,744 - INFO - [TRAIN] Epoch: 23/30 | Batch: 132/226 (58.8%) | Loss: 0.6651 | Batch time: 0.03s
2025-03-04 00:31:08,703 - INFO - [TRAIN] Epoch: 23/30 | Batch: 154/226 (68.6%) | Loss: 0.5297 | Batch time: 0.02s
2025-03-04 00:31:09,506 - INFO - [TRAIN] Epoch: 23/30 | Batch: 176/226 (78.3%) | Loss: 0.5783 | Batch time: 0.04s
2025-03-04 00:31:10,294 - INFO - [TRAIN] Epoch: 23/30 | Batch: 198/226 (88.1%) | Loss: 0.6115 | Batch time: 0.02s
2025-03-04 00:31:10,793 - INFO - [TRAIN] Epoch: 23/30 | Batch: 220/226 (97.8%) | Loss: 0.5715 | Batch time: 0.01s
2025-03-04 00:31:10,861 - INFO - [TRAIN] Epoch: 23/30 | Batch: 225/226 (100.0%) | Loss: 0.7697 | Batch time: 0.01s
2025-03-04 00:31:11,117 - INFO - [VAL] Epoch: 23/30 | Batch: 0/49 (2.0%) | Loss: 0.1491 | Batch time: 0.03s
2025-03-04 00:31:11,197 - INFO - [VAL] Epoch: 23/30 | Batch: 4/49 (10.2%) | Loss: 0.2790 | Batch time: 0.02s
2025-03-04 00:31:11,306 - INFO - [VAL] Epoch: 23/30 | Batch: 8/49 (18.4%) | Loss: 0.1658 | Batch time: 0.03s
2025-03-04 00:31:11,418 - INFO - [VAL] Epoch: 23/30 | Batch: 12/49 (26.5%) | Loss: 0.3002 | Batch time: 0.02s
2025-03-04 00:31:11,479 - INFO - [VAL] Epoch: 23/30 | Batch: 16/49 (34.7%) | Loss: 0.2557 | Batch time: 0.01s
2025-03-04 00:31:11,524 - INFO - [VAL] Epoch: 23/30 | Batch: 20/49 (42.9%) | Loss: 0.3832 | Batch time: 0.01s
2025-03-04 00:31:11,568 - INFO - [VAL] Epoch: 23/30 | Batch: 24/49 (51.0%) | Loss: 0.2110 | Batch time: 0.01s
2025-03-04 00:31:11,607 - INFO - [VAL] Epoch: 23/30 | Batch: 28/49 (59.2%) | Loss: 0.5515 | Batch time: 0.01s
2025-03-04 00:31:11,648 - INFO - [VAL] Epoch: 23/30 | Batch: 32/49 (67.3%) | Loss: 0.1973 | Batch time: 0.01s
2025-03-04 00:31:11,688 - INFO - [VAL] Epoch: 23/30 | Batch: 36/49 (75.5%) | Loss: 0.2347 | Batch time: 0.01s
2025-03-04 00:31:11,727 - INFO - [VAL] Epoch: 23/30 | Batch: 40/49 (83.7%) | Loss: 0.3980 | Batch time: 0.01s
2025-03-04 00:31:11,802 - INFO - [VAL] Epoch: 23/30 | Batch: 44/49 (91.8%) | Loss: 0.2242 | Batch time: 0.02s
2025-03-04 00:31:11,876 - INFO - [VAL] Epoch: 23/30 | Batch: 48/49 (100.0%) | Loss: 0.3522 | Batch time: 0.02s
2025-03-04 00:31:11,881 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:11,881 - INFO - Epoch 23/30 completed in 10.46s
2025-03-04 00:31:11,881 - INFO - Training   - Loss: 0.6539, Accuracy: 0.7818, F1: 0.7845
2025-03-04 00:31:11,881 - INFO - Validation - Loss: 0.3055, Accuracy: 0.8895, F1: 0.8908
2025-03-04 00:31:11,881 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:11,881 - INFO - Epoch 24/30
2025-03-04 00:31:11,881 - INFO - ----------------------------------------
2025-03-04 00:31:12,552 - INFO - [TRAIN] Epoch: 24/30 | Batch: 0/226 (0.4%) | Loss: 0.8164 | Batch time: 0.04s
2025-03-04 00:31:13,744 - INFO - [TRAIN] Epoch: 24/30 | Batch: 22/226 (10.2%) | Loss: 0.5392 | Batch time: 0.06s
2025-03-04 00:31:14,556 - INFO - [TRAIN] Epoch: 24/30 | Batch: 44/226 (19.9%) | Loss: 0.5770 | Batch time: 0.02s
2025-03-04 00:31:15,623 - INFO - [TRAIN] Epoch: 24/30 | Batch: 66/226 (29.6%) | Loss: 0.9462 | Batch time: 0.03s
2025-03-04 00:31:16,573 - INFO - [TRAIN] Epoch: 24/30 | Batch: 88/226 (39.4%) | Loss: 1.0348 | Batch time: 0.03s
2025-03-04 00:31:17,460 - INFO - [TRAIN] Epoch: 24/30 | Batch: 110/226 (49.1%) | Loss: 0.5998 | Batch time: 0.04s
2025-03-04 00:31:18,378 - INFO - [TRAIN] Epoch: 24/30 | Batch: 132/226 (58.8%) | Loss: 0.7270 | Batch time: 0.03s
2025-03-04 00:31:19,345 - INFO - [TRAIN] Epoch: 24/30 | Batch: 154/226 (68.6%) | Loss: 0.6474 | Batch time: 0.04s
2025-03-04 00:31:20,113 - INFO - [TRAIN] Epoch: 24/30 | Batch: 176/226 (78.3%) | Loss: 0.5348 | Batch time: 0.05s
2025-03-04 00:31:21,025 - INFO - [TRAIN] Epoch: 24/30 | Batch: 198/226 (88.1%) | Loss: 0.4723 | Batch time: 0.02s
2025-03-04 00:31:21,579 - INFO - [TRAIN] Epoch: 24/30 | Batch: 220/226 (97.8%) | Loss: 0.8581 | Batch time: 0.03s
2025-03-04 00:31:21,674 - INFO - [TRAIN] Epoch: 24/30 | Batch: 225/226 (100.0%) | Loss: 0.4626 | Batch time: 0.01s
2025-03-04 00:31:21,942 - INFO - [VAL] Epoch: 24/30 | Batch: 0/49 (2.0%) | Loss: 0.1494 | Batch time: 0.01s
2025-03-04 00:31:22,008 - INFO - [VAL] Epoch: 24/30 | Batch: 4/49 (10.2%) | Loss: 0.2795 | Batch time: 0.01s
2025-03-04 00:31:22,109 - INFO - [VAL] Epoch: 24/30 | Batch: 8/49 (18.4%) | Loss: 0.1634 | Batch time: 0.02s
2025-03-04 00:31:22,178 - INFO - [VAL] Epoch: 24/30 | Batch: 12/49 (26.5%) | Loss: 0.3038 | Batch time: 0.02s
2025-03-04 00:31:22,336 - INFO - [VAL] Epoch: 24/30 | Batch: 16/49 (34.7%) | Loss: 0.2531 | Batch time: 0.03s
2025-03-04 00:31:22,388 - INFO - [VAL] Epoch: 24/30 | Batch: 20/49 (42.9%) | Loss: 0.3835 | Batch time: 0.01s
2025-03-04 00:31:22,429 - INFO - [VAL] Epoch: 24/30 | Batch: 24/49 (51.0%) | Loss: 0.2106 | Batch time: 0.01s
2025-03-04 00:31:22,469 - INFO - [VAL] Epoch: 24/30 | Batch: 28/49 (59.2%) | Loss: 0.5480 | Batch time: 0.01s
2025-03-04 00:31:22,510 - INFO - [VAL] Epoch: 24/30 | Batch: 32/49 (67.3%) | Loss: 0.1935 | Batch time: 0.01s
2025-03-04 00:31:22,549 - INFO - [VAL] Epoch: 24/30 | Batch: 36/49 (75.5%) | Loss: 0.2365 | Batch time: 0.01s
2025-03-04 00:31:22,591 - INFO - [VAL] Epoch: 24/30 | Batch: 40/49 (83.7%) | Loss: 0.3915 | Batch time: 0.01s
2025-03-04 00:31:22,669 - INFO - [VAL] Epoch: 24/30 | Batch: 44/49 (91.8%) | Loss: 0.2265 | Batch time: 0.02s
2025-03-04 00:31:22,747 - INFO - [VAL] Epoch: 24/30 | Batch: 48/49 (100.0%) | Loss: 0.3492 | Batch time: 0.01s
2025-03-04 00:31:22,752 - INFO - Early stopping triggered after 24 epochs
2025-03-04 00:31:22,752 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:22,752 - INFO - Epoch 24/30 completed in 10.87s
2025-03-04 00:31:22,752 - INFO - Training   - Loss: 0.6543, Accuracy: 0.7828, F1: 0.7846
2025-03-04 00:31:22,752 - INFO - Validation - Loss: 0.3047, Accuracy: 0.8908, F1: 0.8921
2025-03-04 00:31:22,752 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:22,752 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:22,752 - INFO - Training completed in 0h 5m 34.02s
2025-03-04 00:31:22,752 - INFO - Best validation F1: 0.8930 (Epoch 14)
2025-03-04 00:31:22,752 - INFO - --------------------------------------------------------------------------------
2025-03-04 00:31:23,132 - INFO - Final model saved to models/mobilenet_v3_small_v1/models/mobilenet_v3_small_v1_final.pth
2025-03-04 00:31:23,146 - INFO - Model registered in models/model_registry.json
2025-03-04 00:31:23,146 - INFO - Generating visualizations...
2025-03-04 00:31:23,146 - INFO - Generating standard visualizations and GradCAM
2025-03-04 00:32:11,375 - INFO - t-SNE visualization saved to models/mobilenet_v3_small_v1/visualizations
2025-03-04 00:32:11,375 - INFO - Training and visualization finished!

2025-03-05 00:12:04,333 - INFO - Starting experiment: mobilenet_v2
2025-03-05 00:12:04,334 - INFO - Command line arguments: Namespace(data_dir='data/raw', output_dir='models/mobilenet_v2_v3', model='mobilenet', img_size=224, batch_size=32, num_workers=16, epochs=30, lr=0.001, weight_decay=0.0001, use_weights=True, freeze_backbone=True, no_cuda=False, no_mps=False, use_mps=True, use_amp=False, memory_efficient=True, cache_dataset=True, mps_graph=True, mps_fallback=False, pin_memory=False, optimize_for_m_series=True, patience=10, keep_top_k=3, version=None, find_lr=False, experiment_name='mobilenet_v2', resnet_version=50)
2025-03-05 00:12:04,334 - INFO - Processing dataset...
2025-03-05 00:12:04,666 - INFO - Class distribution:
2025-03-05 00:12:04,666 - INFO -   Strawberry___healthy: 1000 images
2025-03-05 00:12:04,666 - INFO -   Grape___Black_rot: 1180 images
2025-03-05 00:12:04,666 - INFO -   Potato___Early_blight: 1000 images
2025-03-05 00:12:04,667 - INFO -   Blueberry___healthy: 1502 images
2025-03-05 00:12:04,667 - INFO -   Cherry___Powdery_mildew: 1052 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Target_Spot: 1404 images
2025-03-05 00:12:04,667 - INFO -   Peach___healthy: 1000 images
2025-03-05 00:12:04,667 - INFO -   Potato___Late_blight: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Late_blight: 1909 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Tomato_mosaic_virus: 1000 images
2025-03-05 00:12:04,667 - INFO -   Pepper,_bell___healthy: 1478 images
2025-03-05 00:12:04,667 - INFO -   Orange___Haunglongbing_(Citrus_greening): 5507 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Leaf_Mold: 1000 images
2025-03-05 00:12:04,667 - INFO -   Grape___Leaf_blight_(Isariopsis_Leaf_Spot): 1076 images
2025-03-05 00:12:04,667 - INFO -   Apple___Cedar_apple_rust: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Bacterial_spot: 2127 images
2025-03-05 00:12:04,667 - INFO -   Grape___healthy: 1000 images
2025-03-05 00:12:04,667 - INFO -   Corn___Cercospora_leaf_spot Gray_leaf_spot: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Early_blight: 1000 images
2025-03-05 00:12:04,667 - INFO -   Grape___Esca_(Black_Measles): 1383 images
2025-03-05 00:12:04,667 - INFO -   Raspberry___healthy: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___healthy: 1591 images
2025-03-05 00:12:04,667 - INFO -   Corn___Northern_Leaf_Blight: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Tomato_Yellow_Leaf_Curl_Virus: 5357 images
2025-03-05 00:12:04,667 - INFO -   Cherry___healthy: 1000 images
2025-03-05 00:12:04,667 - INFO -   Apple___Apple_scab: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Spider_mites Two-spotted_spider_mite: 1676 images
2025-03-05 00:12:04,667 - INFO -   Corn___Common_rust: 1192 images
2025-03-05 00:12:04,667 - INFO -   Background_without_leaves: 1143 images
2025-03-05 00:12:04,667 - INFO -   Peach___Bacterial_spot: 2297 images
2025-03-05 00:12:04,667 - INFO -   Pepper,_bell___Bacterial_spot: 1000 images
2025-03-05 00:12:04,667 - INFO -   Tomato___Septoria_leaf_spot: 1771 images
2025-03-05 00:12:04,667 - INFO -   Corn___healthy: 1162 images
2025-03-05 00:12:04,667 - INFO -   Squash___Powdery_mildew: 1835 images
2025-03-05 00:12:04,667 - INFO -   Apple___Black_rot: 1000 images
2025-03-05 00:12:04,667 - INFO -   Apple___healthy: 1645 images
2025-03-05 00:12:04,667 - INFO -   Strawberry___Leaf_scorch: 1109 images
2025-03-05 00:12:04,667 - INFO -   Potato___healthy: 1000 images
2025-03-05 00:12:04,667 - INFO -   Soybean___healthy: 5090 images
2025-03-05 00:12:04,667 - INFO - Creating model: mobilenet with 39 classes
2025-03-05 00:12:04,751 - INFO - Model architecture:
MobileNetV2(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Conv2dNormActivation(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=True)
    (1): Linear(in_features=1280, out_features=39, bias=True)
  )
)
2025-03-05 00:12:04,752 - INFO - Using class weights: [1.2614028  1.0689855  1.2614028  0.83981544 1.1990521  0.89843506
 1.2614028  1.2614028  0.66076624 1.2614028  0.8534525  0.22905444
 1.2614028  1.1723075  1.2614028  0.59304315 1.2614028  1.2614028
 1.2614028  0.91207725 1.2614028  0.7928365  1.2614028  0.23546813
 1.2614028  1.2614028  0.75262696 1.0582238  1.1035895  0.5491523
 1.2614028  0.7122546  1.0855446  0.687413   1.2614028  0.76681024
 1.1374236  1.2614028  0.24781981]
2025-03-05 00:12:04,752 - INFO - Training only 2 parameters (classifier)
2025-03-05 00:12:04,752 - INFO - Starting training for 30 epochs
2025-03-05 00:12:04,752 - INFO - Using Automatic Mixed Precision: False
2025-03-05 00:12:04,752 - INFO - Early stopping patience: 10
2025-03-05 00:12:04,752 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:12:04,752 - INFO - Starting training: mobilenet_v2
2025-03-05 00:12:04,753 - INFO - Total epochs: 30
2025-03-05 00:12:04,753 - INFO - Training batches per epoch: 1345
2025-03-05 00:12:04,753 - INFO - Validation batches per epoch: 289
2025-03-05 00:12:04,753 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:12:04,753 - INFO - Training model: mobilenet_v2_v1
2025-03-05 00:12:04,753 - INFO - Epoch 1/30
2025-03-05 00:12:04,753 - INFO - ----------------------------------------
2025-03-05 00:12:42,825 - INFO - [TRAIN] Epoch: 1/30 | Batch: 0/1345 (0.1%) | Loss: 3.8546 | Batch time: 0.99s
2025-03-05 00:12:47,132 - INFO - [TRAIN] Epoch: 1/30 | Batch: 134/1345 (10.0%) | Loss: 1.9527 | Batch time: 0.03s
2025-03-05 00:12:50,732 - INFO - [TRAIN] Epoch: 1/30 | Batch: 268/1345 (20.0%) | Loss: 1.7389 | Batch time: 0.03s
2025-03-05 00:12:54,412 - INFO - [TRAIN] Epoch: 1/30 | Batch: 402/1345 (30.0%) | Loss: 0.9188 | Batch time: 0.03s
2025-03-05 00:12:58,496 - INFO - [TRAIN] Epoch: 1/30 | Batch: 536/1345 (39.9%) | Loss: 1.5873 | Batch time: 0.03s
2025-03-05 00:13:02,006 - INFO - [TRAIN] Epoch: 1/30 | Batch: 670/1345 (49.9%) | Loss: 1.1249 | Batch time: 0.03s
2025-03-05 00:13:05,919 - INFO - [TRAIN] Epoch: 1/30 | Batch: 804/1345 (59.9%) | Loss: 1.1084 | Batch time: 0.03s
2025-03-05 00:13:10,190 - INFO - [TRAIN] Epoch: 1/30 | Batch: 938/1345 (69.8%) | Loss: 1.3467 | Batch time: 0.03s
2025-03-05 00:13:13,969 - INFO - [TRAIN] Epoch: 1/30 | Batch: 1072/1345 (79.8%) | Loss: 1.2404 | Batch time: 0.03s
2025-03-05 00:13:18,412 - INFO - [TRAIN] Epoch: 1/30 | Batch: 1206/1345 (89.7%) | Loss: 1.0836 | Batch time: 0.03s
2025-03-05 00:13:22,078 - INFO - [TRAIN] Epoch: 1/30 | Batch: 1340/1345 (99.7%) | Loss: 1.1696 | Batch time: 0.02s
2025-03-05 00:13:22,162 - INFO - [TRAIN] Epoch: 1/30 | Batch: 1344/1345 (100.0%) | Loss: 1.3659 | Batch time: 0.02s
2025-03-05 00:14:02,341 - INFO - [VAL] Epoch: 1/30 | Batch: 0/289 (0.3%) | Loss: 0.6979 | Batch time: 0.81s
2025-03-05 00:14:02,981 - INFO - [VAL] Epoch: 1/30 | Batch: 28/289 (10.0%) | Loss: 0.5783 | Batch time: 0.02s
2025-03-05 00:14:03,588 - INFO - [VAL] Epoch: 1/30 | Batch: 56/289 (19.7%) | Loss: 1.0763 | Batch time: 0.01s
2025-03-05 00:14:04,044 - INFO - [VAL] Epoch: 1/30 | Batch: 84/289 (29.4%) | Loss: 0.5538 | Batch time: 0.02s
2025-03-05 00:14:04,522 - INFO - [VAL] Epoch: 1/30 | Batch: 112/289 (39.1%) | Loss: 0.6474 | Batch time: 0.02s
2025-03-05 00:14:04,938 - INFO - [VAL] Epoch: 1/30 | Batch: 140/289 (48.8%) | Loss: 0.5999 | Batch time: 0.01s
2025-03-05 00:14:05,430 - INFO - [VAL] Epoch: 1/30 | Batch: 168/289 (58.5%) | Loss: 0.5147 | Batch time: 0.02s
2025-03-05 00:14:05,982 - INFO - [VAL] Epoch: 1/30 | Batch: 196/289 (68.2%) | Loss: 0.4036 | Batch time: 0.02s
2025-03-05 00:14:06,607 - INFO - [VAL] Epoch: 1/30 | Batch: 224/289 (77.9%) | Loss: 0.4661 | Batch time: 0.02s
2025-03-05 00:14:07,117 - INFO - [VAL] Epoch: 1/30 | Batch: 252/289 (87.5%) | Loss: 0.8446 | Batch time: 0.01s
2025-03-05 00:14:07,539 - INFO - [VAL] Epoch: 1/30 | Batch: 280/289 (97.2%) | Loss: 0.7453 | Batch time: 0.01s
2025-03-05 00:14:07,855 - INFO - [VAL] Epoch: 1/30 | Batch: 288/289 (100.0%) | Loss: 0.6773 | Batch time: 0.19s
2025-03-05 00:14:07,999 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 1)
2025-03-05 00:14:07,999 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:14:07,999 - INFO - Epoch 1/30 completed in 123.25s
2025-03-05 00:14:07,999 - INFO - Training   - Loss: 1.4246, Accuracy: 0.6283, F1: 0.6319
2025-03-05 00:14:07,999 - INFO - Validation - Loss: 0.6061, Accuracy: 0.8255, F1: 0.8297
2025-03-05 00:14:07,999 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:14:08,000 - INFO - Epoch 2/30
2025-03-05 00:14:08,000 - INFO - ----------------------------------------
2025-03-05 00:14:08,378 - INFO - [TRAIN] Epoch: 2/30 | Batch: 0/1345 (0.1%) | Loss: 1.0439 | Batch time: 0.10s
2025-03-05 00:14:11,725 - INFO - [TRAIN] Epoch: 2/30 | Batch: 134/1345 (10.0%) | Loss: 1.0614 | Batch time: 0.02s
2025-03-05 00:14:15,394 - INFO - [TRAIN] Epoch: 2/30 | Batch: 268/1345 (20.0%) | Loss: 0.8460 | Batch time: 0.02s
2025-03-05 00:14:18,821 - INFO - [TRAIN] Epoch: 2/30 | Batch: 402/1345 (30.0%) | Loss: 0.8290 | Batch time: 0.03s
2025-03-05 00:14:22,437 - INFO - [TRAIN] Epoch: 2/30 | Batch: 536/1345 (39.9%) | Loss: 1.4100 | Batch time: 0.03s
2025-03-05 00:14:26,262 - INFO - [TRAIN] Epoch: 2/30 | Batch: 670/1345 (49.9%) | Loss: 0.8879 | Batch time: 0.03s
2025-03-05 00:14:29,988 - INFO - [TRAIN] Epoch: 2/30 | Batch: 804/1345 (59.9%) | Loss: 0.7941 | Batch time: 0.03s
2025-03-05 00:14:33,696 - INFO - [TRAIN] Epoch: 2/30 | Batch: 938/1345 (69.8%) | Loss: 0.8563 | Batch time: 0.02s
2025-03-05 00:14:37,360 - INFO - [TRAIN] Epoch: 2/30 | Batch: 1072/1345 (79.8%) | Loss: 1.2044 | Batch time: 0.03s
2025-03-05 00:14:41,089 - INFO - [TRAIN] Epoch: 2/30 | Batch: 1206/1345 (89.7%) | Loss: 1.6315 | Batch time: 0.02s
2025-03-05 00:14:44,834 - INFO - [TRAIN] Epoch: 2/30 | Batch: 1340/1345 (99.7%) | Loss: 1.3874 | Batch time: 0.02s
2025-03-05 00:14:44,946 - INFO - [TRAIN] Epoch: 2/30 | Batch: 1344/1345 (100.0%) | Loss: 0.9342 | Batch time: 0.02s
2025-03-05 00:14:45,439 - INFO - [VAL] Epoch: 2/30 | Batch: 0/289 (0.3%) | Loss: 0.4284 | Batch time: 0.04s
2025-03-05 00:14:45,944 - INFO - [VAL] Epoch: 2/30 | Batch: 28/289 (10.0%) | Loss: 0.4049 | Batch time: 0.01s
2025-03-05 00:14:46,389 - INFO - [VAL] Epoch: 2/30 | Batch: 56/289 (19.7%) | Loss: 1.0181 | Batch time: 0.01s
2025-03-05 00:14:46,928 - INFO - [VAL] Epoch: 2/30 | Batch: 84/289 (29.4%) | Loss: 0.4228 | Batch time: 0.02s
2025-03-05 00:14:47,573 - INFO - [VAL] Epoch: 2/30 | Batch: 112/289 (39.1%) | Loss: 0.5527 | Batch time: 0.02s
2025-03-05 00:14:48,050 - INFO - [VAL] Epoch: 2/30 | Batch: 140/289 (48.8%) | Loss: 0.6965 | Batch time: 0.01s
2025-03-05 00:14:48,476 - INFO - [VAL] Epoch: 2/30 | Batch: 168/289 (58.5%) | Loss: 0.4257 | Batch time: 0.01s
2025-03-05 00:14:48,899 - INFO - [VAL] Epoch: 2/30 | Batch: 196/289 (68.2%) | Loss: 0.4577 | Batch time: 0.01s
2025-03-05 00:14:49,323 - INFO - [VAL] Epoch: 2/30 | Batch: 224/289 (77.9%) | Loss: 0.4213 | Batch time: 0.01s
2025-03-05 00:14:49,748 - INFO - [VAL] Epoch: 2/30 | Batch: 252/289 (87.5%) | Loss: 0.8591 | Batch time: 0.01s
2025-03-05 00:14:50,249 - INFO - [VAL] Epoch: 2/30 | Batch: 280/289 (97.2%) | Loss: 0.5505 | Batch time: 0.01s
2025-03-05 00:14:50,386 - INFO - [VAL] Epoch: 2/30 | Batch: 288/289 (100.0%) | Loss: 0.6369 | Batch time: 0.01s
2025-03-05 00:14:50,551 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 2)
2025-03-05 00:14:50,551 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:14:50,551 - INFO - Epoch 2/30 completed in 42.55s
2025-03-05 00:14:50,551 - INFO - Training   - Loss: 1.0465, Accuracy: 0.7004, F1: 0.7034
2025-03-05 00:14:50,551 - INFO - Validation - Loss: 0.4975, Accuracy: 0.8592, F1: 0.8588
2025-03-05 00:14:50,552 - INFO - Validation F1 improved from 0.8297 to 0.8588
2025-03-05 00:14:50,552 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:14:50,552 - INFO - Epoch 3/30
2025-03-05 00:14:50,552 - INFO - ----------------------------------------
2025-03-05 00:14:51,017 - INFO - [TRAIN] Epoch: 3/30 | Batch: 0/1345 (0.1%) | Loss: 1.0693 | Batch time: 0.05s
2025-03-05 00:14:55,032 - INFO - [TRAIN] Epoch: 3/30 | Batch: 134/1345 (10.0%) | Loss: 1.1947 | Batch time: 0.03s
2025-03-05 00:14:58,479 - INFO - [TRAIN] Epoch: 3/30 | Batch: 268/1345 (20.0%) | Loss: 1.2959 | Batch time: 0.02s
2025-03-05 00:15:01,978 - INFO - [TRAIN] Epoch: 3/30 | Batch: 402/1345 (30.0%) | Loss: 1.2980 | Batch time: 0.03s
2025-03-05 00:15:05,669 - INFO - [TRAIN] Epoch: 3/30 | Batch: 536/1345 (39.9%) | Loss: 0.9155 | Batch time: 0.03s
2025-03-05 00:15:09,831 - INFO - [TRAIN] Epoch: 3/30 | Batch: 670/1345 (49.9%) | Loss: 0.7947 | Batch time: 0.02s
2025-03-05 00:15:13,520 - INFO - [TRAIN] Epoch: 3/30 | Batch: 804/1345 (59.9%) | Loss: 1.4015 | Batch time: 0.05s
2025-03-05 00:15:17,574 - INFO - [TRAIN] Epoch: 3/30 | Batch: 938/1345 (69.8%) | Loss: 0.9748 | Batch time: 0.02s
2025-03-05 00:15:21,080 - INFO - [TRAIN] Epoch: 3/30 | Batch: 1072/1345 (79.8%) | Loss: 1.5203 | Batch time: 0.03s
2025-03-05 00:15:24,941 - INFO - [TRAIN] Epoch: 3/30 | Batch: 1206/1345 (89.7%) | Loss: 0.7976 | Batch time: 0.02s
2025-03-05 00:15:29,356 - INFO - [TRAIN] Epoch: 3/30 | Batch: 1340/1345 (99.7%) | Loss: 1.3548 | Batch time: 0.02s
2025-03-05 00:15:29,449 - INFO - [TRAIN] Epoch: 3/30 | Batch: 1344/1345 (100.0%) | Loss: 1.3319 | Batch time: 0.02s
2025-03-05 00:15:29,812 - INFO - [VAL] Epoch: 3/30 | Batch: 0/289 (0.3%) | Loss: 0.5192 | Batch time: 0.06s
2025-03-05 00:15:30,317 - INFO - [VAL] Epoch: 3/30 | Batch: 28/289 (10.0%) | Loss: 0.3221 | Batch time: 0.01s
2025-03-05 00:15:30,791 - INFO - [VAL] Epoch: 3/30 | Batch: 56/289 (19.7%) | Loss: 1.0105 | Batch time: 0.01s
2025-03-05 00:15:31,211 - INFO - [VAL] Epoch: 3/30 | Batch: 84/289 (29.4%) | Loss: 0.2498 | Batch time: 0.01s
2025-03-05 00:15:31,614 - INFO - [VAL] Epoch: 3/30 | Batch: 112/289 (39.1%) | Loss: 0.3683 | Batch time: 0.01s
2025-03-05 00:15:32,021 - INFO - [VAL] Epoch: 3/30 | Batch: 140/289 (48.8%) | Loss: 0.3152 | Batch time: 0.01s
2025-03-05 00:15:32,489 - INFO - [VAL] Epoch: 3/30 | Batch: 168/289 (58.5%) | Loss: 0.2258 | Batch time: 0.03s
2025-03-05 00:15:33,004 - INFO - [VAL] Epoch: 3/30 | Batch: 196/289 (68.2%) | Loss: 0.2821 | Batch time: 0.02s
2025-03-05 00:15:33,468 - INFO - [VAL] Epoch: 3/30 | Batch: 224/289 (77.9%) | Loss: 0.3793 | Batch time: 0.01s
2025-03-05 00:15:33,932 - INFO - [VAL] Epoch: 3/30 | Batch: 252/289 (87.5%) | Loss: 0.5412 | Batch time: 0.02s
2025-03-05 00:15:34,364 - INFO - [VAL] Epoch: 3/30 | Batch: 280/289 (97.2%) | Loss: 0.5290 | Batch time: 0.02s
2025-03-05 00:15:34,480 - INFO - [VAL] Epoch: 3/30 | Batch: 288/289 (100.0%) | Loss: 0.8390 | Batch time: 0.01s
2025-03-05 00:15:34,600 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 3)
2025-03-05 00:15:34,600 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:15:34,600 - INFO - Epoch 3/30 completed in 44.05s
2025-03-05 00:15:34,600 - INFO - Training   - Loss: 1.0021, Accuracy: 0.7145, F1: 0.7176
2025-03-05 00:15:34,600 - INFO - Validation - Loss: 0.4216, Accuracy: 0.8706, F1: 0.8739
2025-03-05 00:15:34,600 - INFO - Validation F1 improved from 0.8588 to 0.8739
2025-03-05 00:15:34,600 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:15:34,600 - INFO - Epoch 4/30
2025-03-05 00:15:34,600 - INFO - ----------------------------------------
2025-03-05 00:15:35,031 - INFO - [TRAIN] Epoch: 4/30 | Batch: 0/1345 (0.1%) | Loss: 0.5421 | Batch time: 0.08s
2025-03-05 00:15:39,007 - INFO - [TRAIN] Epoch: 4/30 | Batch: 134/1345 (10.0%) | Loss: 0.7590 | Batch time: 0.02s
2025-03-05 00:15:42,970 - INFO - [TRAIN] Epoch: 4/30 | Batch: 268/1345 (20.0%) | Loss: 1.0761 | Batch time: 0.03s
2025-03-05 00:15:47,632 - INFO - [TRAIN] Epoch: 4/30 | Batch: 402/1345 (30.0%) | Loss: 1.2940 | Batch time: 0.04s
2025-03-05 00:15:52,052 - INFO - [TRAIN] Epoch: 4/30 | Batch: 536/1345 (39.9%) | Loss: 0.6845 | Batch time: 0.03s
2025-03-05 00:15:56,138 - INFO - [TRAIN] Epoch: 4/30 | Batch: 670/1345 (49.9%) | Loss: 0.9337 | Batch time: 0.02s
2025-03-05 00:16:00,677 - INFO - [TRAIN] Epoch: 4/30 | Batch: 804/1345 (59.9%) | Loss: 0.7791 | Batch time: 0.03s
2025-03-05 00:16:04,775 - INFO - [TRAIN] Epoch: 4/30 | Batch: 938/1345 (69.8%) | Loss: 0.5671 | Batch time: 0.02s
2025-03-05 00:16:09,657 - INFO - [TRAIN] Epoch: 4/30 | Batch: 1072/1345 (79.8%) | Loss: 1.1076 | Batch time: 0.02s
2025-03-05 00:16:13,745 - INFO - [TRAIN] Epoch: 4/30 | Batch: 1206/1345 (89.7%) | Loss: 1.0355 | Batch time: 0.02s
2025-03-05 00:16:17,645 - INFO - [TRAIN] Epoch: 4/30 | Batch: 1340/1345 (99.7%) | Loss: 0.7563 | Batch time: 0.02s
2025-03-05 00:16:17,738 - INFO - [TRAIN] Epoch: 4/30 | Batch: 1344/1345 (100.0%) | Loss: 1.0655 | Batch time: 0.03s
2025-03-05 00:16:17,935 - INFO - [VAL] Epoch: 4/30 | Batch: 0/289 (0.3%) | Loss: 0.4798 | Batch time: 0.06s
2025-03-05 00:16:18,650 - INFO - [VAL] Epoch: 4/30 | Batch: 28/289 (10.0%) | Loss: 0.2245 | Batch time: 0.03s
2025-03-05 00:16:19,316 - INFO - [VAL] Epoch: 4/30 | Batch: 56/289 (19.7%) | Loss: 0.8610 | Batch time: 0.01s
2025-03-05 00:16:19,750 - INFO - [VAL] Epoch: 4/30 | Batch: 84/289 (29.4%) | Loss: 0.2878 | Batch time: 0.02s
2025-03-05 00:16:20,185 - INFO - [VAL] Epoch: 4/30 | Batch: 112/289 (39.1%) | Loss: 0.3794 | Batch time: 0.01s
2025-03-05 00:16:20,800 - INFO - [VAL] Epoch: 4/30 | Batch: 140/289 (48.8%) | Loss: 0.4644 | Batch time: 0.02s
2025-03-05 00:16:21,573 - INFO - [VAL] Epoch: 4/30 | Batch: 168/289 (58.5%) | Loss: 0.3321 | Batch time: 0.01s
2025-03-05 00:16:22,018 - INFO - [VAL] Epoch: 4/30 | Batch: 196/289 (68.2%) | Loss: 0.2439 | Batch time: 0.02s
2025-03-05 00:16:22,467 - INFO - [VAL] Epoch: 4/30 | Batch: 224/289 (77.9%) | Loss: 0.2795 | Batch time: 0.02s
2025-03-05 00:16:23,023 - INFO - [VAL] Epoch: 4/30 | Batch: 252/289 (87.5%) | Loss: 0.6188 | Batch time: 0.04s
2025-03-05 00:16:23,698 - INFO - [VAL] Epoch: 4/30 | Batch: 280/289 (97.2%) | Loss: 0.4063 | Batch time: 0.03s
2025-03-05 00:16:23,959 - INFO - [VAL] Epoch: 4/30 | Batch: 288/289 (100.0%) | Loss: 0.5403 | Batch time: 0.01s
2025-03-05 00:16:23,967 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:16:23,967 - INFO - Epoch 4/30 completed in 49.37s
2025-03-05 00:16:23,967 - INFO - Training   - Loss: 0.9894, Accuracy: 0.7148, F1: 0.7178
2025-03-05 00:16:23,967 - INFO - Validation - Loss: 0.4224, Accuracy: 0.8457, F1: 0.8526
2025-03-05 00:16:23,967 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:16:23,967 - INFO - Epoch 5/30
2025-03-05 00:16:23,967 - INFO - ----------------------------------------
2025-03-05 00:16:24,219 - INFO - [TRAIN] Epoch: 5/30 | Batch: 0/1345 (0.1%) | Loss: 0.9433 | Batch time: 0.03s
2025-03-05 00:16:28,252 - INFO - [TRAIN] Epoch: 5/30 | Batch: 134/1345 (10.0%) | Loss: 1.2259 | Batch time: 0.04s
2025-03-05 00:16:32,160 - INFO - [TRAIN] Epoch: 5/30 | Batch: 268/1345 (20.0%) | Loss: 1.2603 | Batch time: 0.05s
2025-03-05 00:16:36,213 - INFO - [TRAIN] Epoch: 5/30 | Batch: 402/1345 (30.0%) | Loss: 0.7815 | Batch time: 0.02s
2025-03-05 00:16:40,180 - INFO - [TRAIN] Epoch: 5/30 | Batch: 536/1345 (39.9%) | Loss: 1.3361 | Batch time: 0.03s
2025-03-05 00:16:44,076 - INFO - [TRAIN] Epoch: 5/30 | Batch: 670/1345 (49.9%) | Loss: 1.3470 | Batch time: 0.02s
2025-03-05 00:16:47,747 - INFO - [TRAIN] Epoch: 5/30 | Batch: 804/1345 (59.9%) | Loss: 0.8910 | Batch time: 0.03s
2025-03-05 00:16:51,373 - INFO - [TRAIN] Epoch: 5/30 | Batch: 938/1345 (69.8%) | Loss: 0.5371 | Batch time: 0.02s
2025-03-05 00:16:54,686 - INFO - [TRAIN] Epoch: 5/30 | Batch: 1072/1345 (79.8%) | Loss: 0.9499 | Batch time: 0.03s
2025-03-05 00:16:57,980 - INFO - [TRAIN] Epoch: 5/30 | Batch: 1206/1345 (89.7%) | Loss: 0.7758 | Batch time: 0.02s
2025-03-05 00:17:01,169 - INFO - [TRAIN] Epoch: 5/30 | Batch: 1340/1345 (99.7%) | Loss: 0.9611 | Batch time: 0.02s
2025-03-05 00:17:01,243 - INFO - [TRAIN] Epoch: 5/30 | Batch: 1344/1345 (100.0%) | Loss: 1.1675 | Batch time: 0.02s
2025-03-05 00:17:01,446 - INFO - [VAL] Epoch: 5/30 | Batch: 0/289 (0.3%) | Loss: 0.6082 | Batch time: 0.02s
2025-03-05 00:17:01,881 - INFO - [VAL] Epoch: 5/30 | Batch: 28/289 (10.0%) | Loss: 0.3165 | Batch time: 0.01s
2025-03-05 00:17:02,302 - INFO - [VAL] Epoch: 5/30 | Batch: 56/289 (19.7%) | Loss: 0.9719 | Batch time: 0.02s
2025-03-05 00:17:02,812 - INFO - [VAL] Epoch: 5/30 | Batch: 84/289 (29.4%) | Loss: 0.3590 | Batch time: 0.02s
2025-03-05 00:17:03,307 - INFO - [VAL] Epoch: 5/30 | Batch: 112/289 (39.1%) | Loss: 0.4285 | Batch time: 0.01s
2025-03-05 00:17:03,783 - INFO - [VAL] Epoch: 5/30 | Batch: 140/289 (48.8%) | Loss: 0.5242 | Batch time: 0.01s
2025-03-05 00:17:04,287 - INFO - [VAL] Epoch: 5/30 | Batch: 168/289 (58.5%) | Loss: 0.4376 | Batch time: 0.01s
2025-03-05 00:17:04,730 - INFO - [VAL] Epoch: 5/30 | Batch: 196/289 (68.2%) | Loss: 0.3343 | Batch time: 0.01s
2025-03-05 00:17:05,249 - INFO - [VAL] Epoch: 5/30 | Batch: 224/289 (77.9%) | Loss: 0.4306 | Batch time: 0.02s
2025-03-05 00:17:05,759 - INFO - [VAL] Epoch: 5/30 | Batch: 252/289 (87.5%) | Loss: 0.5474 | Batch time: 0.01s
2025-03-05 00:17:06,215 - INFO - [VAL] Epoch: 5/30 | Batch: 280/289 (97.2%) | Loss: 0.3646 | Batch time: 0.01s
2025-03-05 00:17:06,329 - INFO - [VAL] Epoch: 5/30 | Batch: 288/289 (100.0%) | Loss: 1.1074 | Batch time: 0.01s
2025-03-05 00:17:06,337 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:17:06,337 - INFO - Epoch 5/30 completed in 42.37s
2025-03-05 00:17:06,337 - INFO - Training   - Loss: 0.9567, Accuracy: 0.7219, F1: 0.7250
2025-03-05 00:17:06,337 - INFO - Validation - Loss: 0.4364, Accuracy: 0.8637, F1: 0.8680
2025-03-05 00:17:06,337 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:17:06,405 - INFO - Checkpoint saved: checkpoint_epoch_5.pth (Epoch 5)
2025-03-05 00:17:06,405 - INFO - Epoch 6/30
2025-03-05 00:17:06,405 - INFO - ----------------------------------------
2025-03-05 00:17:06,790 - INFO - [TRAIN] Epoch: 6/30 | Batch: 0/1345 (0.1%) | Loss: 0.5623 | Batch time: 0.06s
2025-03-05 00:17:10,575 - INFO - [TRAIN] Epoch: 6/30 | Batch: 134/1345 (10.0%) | Loss: 1.6539 | Batch time: 0.02s
2025-03-05 00:17:13,503 - INFO - [TRAIN] Epoch: 6/30 | Batch: 268/1345 (20.0%) | Loss: 0.5334 | Batch time: 0.02s
2025-03-05 00:17:16,525 - INFO - [TRAIN] Epoch: 6/30 | Batch: 402/1345 (30.0%) | Loss: 1.1038 | Batch time: 0.02s
2025-03-05 00:17:19,450 - INFO - [TRAIN] Epoch: 6/30 | Batch: 536/1345 (39.9%) | Loss: 1.2089 | Batch time: 0.02s
2025-03-05 00:17:22,421 - INFO - [TRAIN] Epoch: 6/30 | Batch: 670/1345 (49.9%) | Loss: 0.6933 | Batch time: 0.02s
2025-03-05 00:17:25,401 - INFO - [TRAIN] Epoch: 6/30 | Batch: 804/1345 (59.9%) | Loss: 0.6853 | Batch time: 0.03s
2025-03-05 00:17:28,343 - INFO - [TRAIN] Epoch: 6/30 | Batch: 938/1345 (69.8%) | Loss: 1.1747 | Batch time: 0.02s
2025-03-05 00:17:31,362 - INFO - [TRAIN] Epoch: 6/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6597 | Batch time: 0.03s
2025-03-05 00:17:34,493 - INFO - [TRAIN] Epoch: 6/30 | Batch: 1206/1345 (89.7%) | Loss: 0.9486 | Batch time: 0.02s
2025-03-05 00:17:37,478 - INFO - [TRAIN] Epoch: 6/30 | Batch: 1340/1345 (99.7%) | Loss: 1.9026 | Batch time: 0.02s
2025-03-05 00:17:37,552 - INFO - [TRAIN] Epoch: 6/30 | Batch: 1344/1345 (100.0%) | Loss: 0.9943 | Batch time: 0.02s
2025-03-05 00:17:37,677 - INFO - [VAL] Epoch: 6/30 | Batch: 0/289 (0.3%) | Loss: 0.3494 | Batch time: 0.03s
2025-03-05 00:17:38,066 - INFO - [VAL] Epoch: 6/30 | Batch: 28/289 (10.0%) | Loss: 0.5186 | Batch time: 0.01s
2025-03-05 00:17:38,466 - INFO - [VAL] Epoch: 6/30 | Batch: 56/289 (19.7%) | Loss: 0.8572 | Batch time: 0.01s
2025-03-05 00:17:38,861 - INFO - [VAL] Epoch: 6/30 | Batch: 84/289 (29.4%) | Loss: 0.3755 | Batch time: 0.01s
2025-03-05 00:17:39,257 - INFO - [VAL] Epoch: 6/30 | Batch: 112/289 (39.1%) | Loss: 0.4057 | Batch time: 0.01s
2025-03-05 00:17:39,647 - INFO - [VAL] Epoch: 6/30 | Batch: 140/289 (48.8%) | Loss: 0.4076 | Batch time: 0.01s
2025-03-05 00:17:40,046 - INFO - [VAL] Epoch: 6/30 | Batch: 168/289 (58.5%) | Loss: 0.2271 | Batch time: 0.01s
2025-03-05 00:17:40,453 - INFO - [VAL] Epoch: 6/30 | Batch: 196/289 (68.2%) | Loss: 0.3481 | Batch time: 0.01s
2025-03-05 00:17:40,852 - INFO - [VAL] Epoch: 6/30 | Batch: 224/289 (77.9%) | Loss: 0.3310 | Batch time: 0.01s
2025-03-05 00:17:41,250 - INFO - [VAL] Epoch: 6/30 | Batch: 252/289 (87.5%) | Loss: 0.6433 | Batch time: 0.01s
2025-03-05 00:17:41,641 - INFO - [VAL] Epoch: 6/30 | Batch: 280/289 (97.2%) | Loss: 0.5089 | Batch time: 0.01s
2025-03-05 00:17:41,746 - INFO - [VAL] Epoch: 6/30 | Batch: 288/289 (100.0%) | Loss: 0.4330 | Batch time: 0.01s
2025-03-05 00:17:41,880 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 6)
2025-03-05 00:17:41,880 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:17:41,880 - INFO - Epoch 6/30 completed in 35.48s
2025-03-05 00:17:41,880 - INFO - Training   - Loss: 0.9681, Accuracy: 0.7218, F1: 0.7249
2025-03-05 00:17:41,880 - INFO - Validation - Loss: 0.4228, Accuracy: 0.8744, F1: 0.8739
2025-03-05 00:17:41,880 - INFO - Validation F1 improved from 0.8739 to 0.8739
2025-03-05 00:17:41,880 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:17:41,880 - INFO - Epoch 7/30
2025-03-05 00:17:41,880 - INFO - ----------------------------------------
2025-03-05 00:17:42,143 - INFO - [TRAIN] Epoch: 7/30 | Batch: 0/1345 (0.1%) | Loss: 1.0662 | Batch time: 0.05s
2025-03-05 00:17:45,056 - INFO - [TRAIN] Epoch: 7/30 | Batch: 134/1345 (10.0%) | Loss: 1.3784 | Batch time: 0.02s
2025-03-05 00:17:48,204 - INFO - [TRAIN] Epoch: 7/30 | Batch: 268/1345 (20.0%) | Loss: 1.0396 | Batch time: 0.02s
2025-03-05 00:17:51,302 - INFO - [TRAIN] Epoch: 7/30 | Batch: 402/1345 (30.0%) | Loss: 1.3577 | Batch time: 0.02s
2025-03-05 00:17:54,340 - INFO - [TRAIN] Epoch: 7/30 | Batch: 536/1345 (39.9%) | Loss: 0.4872 | Batch time: 0.03s
2025-03-05 00:17:57,428 - INFO - [TRAIN] Epoch: 7/30 | Batch: 670/1345 (49.9%) | Loss: 1.3309 | Batch time: 0.02s
2025-03-05 00:18:00,339 - INFO - [TRAIN] Epoch: 7/30 | Batch: 804/1345 (59.9%) | Loss: 1.0217 | Batch time: 0.02s
2025-03-05 00:18:03,252 - INFO - [TRAIN] Epoch: 7/30 | Batch: 938/1345 (69.8%) | Loss: 0.9589 | Batch time: 0.02s
2025-03-05 00:18:06,282 - INFO - [TRAIN] Epoch: 7/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6108 | Batch time: 0.02s
2025-03-05 00:18:09,219 - INFO - [TRAIN] Epoch: 7/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8975 | Batch time: 0.02s
2025-03-05 00:18:12,073 - INFO - [TRAIN] Epoch: 7/30 | Batch: 1340/1345 (99.7%) | Loss: 0.7927 | Batch time: 0.02s
2025-03-05 00:18:12,147 - INFO - [TRAIN] Epoch: 7/30 | Batch: 1344/1345 (100.0%) | Loss: 1.7352 | Batch time: 0.02s
2025-03-05 00:18:12,294 - INFO - [VAL] Epoch: 7/30 | Batch: 0/289 (0.3%) | Loss: 0.4010 | Batch time: 0.02s
2025-03-05 00:18:12,742 - INFO - [VAL] Epoch: 7/30 | Batch: 28/289 (10.0%) | Loss: 0.3322 | Batch time: 0.01s
2025-03-05 00:18:13,139 - INFO - [VAL] Epoch: 7/30 | Batch: 56/289 (19.7%) | Loss: 0.7596 | Batch time: 0.01s
2025-03-05 00:18:13,556 - INFO - [VAL] Epoch: 7/30 | Batch: 84/289 (29.4%) | Loss: 0.2383 | Batch time: 0.01s
2025-03-05 00:18:13,957 - INFO - [VAL] Epoch: 7/30 | Batch: 112/289 (39.1%) | Loss: 0.3608 | Batch time: 0.01s
2025-03-05 00:18:14,354 - INFO - [VAL] Epoch: 7/30 | Batch: 140/289 (48.8%) | Loss: 0.4444 | Batch time: 0.01s
2025-03-05 00:18:14,764 - INFO - [VAL] Epoch: 7/30 | Batch: 168/289 (58.5%) | Loss: 0.3206 | Batch time: 0.01s
2025-03-05 00:18:15,163 - INFO - [VAL] Epoch: 7/30 | Batch: 196/289 (68.2%) | Loss: 0.3241 | Batch time: 0.01s
2025-03-05 00:18:15,559 - INFO - [VAL] Epoch: 7/30 | Batch: 224/289 (77.9%) | Loss: 0.3599 | Batch time: 0.01s
2025-03-05 00:18:15,949 - INFO - [VAL] Epoch: 7/30 | Batch: 252/289 (87.5%) | Loss: 0.5927 | Batch time: 0.01s
2025-03-05 00:18:16,328 - INFO - [VAL] Epoch: 7/30 | Batch: 280/289 (97.2%) | Loss: 0.4357 | Batch time: 0.01s
2025-03-05 00:18:16,430 - INFO - [VAL] Epoch: 7/30 | Batch: 288/289 (100.0%) | Loss: 0.9703 | Batch time: 0.01s
2025-03-05 00:18:16,542 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 7)
2025-03-05 00:18:16,542 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:18:16,543 - INFO - Epoch 7/30 completed in 34.66s
2025-03-05 00:18:16,543 - INFO - Training   - Loss: 0.9664, Accuracy: 0.7217, F1: 0.7243
2025-03-05 00:18:16,543 - INFO - Validation - Loss: 0.3817, Accuracy: 0.8793, F1: 0.8824
2025-03-05 00:18:16,543 - INFO - Validation F1 improved from 0.8739 to 0.8824
2025-03-05 00:18:16,543 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:18:16,543 - INFO - Epoch 8/30
2025-03-05 00:18:16,543 - INFO - ----------------------------------------
2025-03-05 00:18:16,766 - INFO - [TRAIN] Epoch: 8/30 | Batch: 0/1345 (0.1%) | Loss: 1.3702 | Batch time: 0.04s
2025-03-05 00:18:19,584 - INFO - [TRAIN] Epoch: 8/30 | Batch: 134/1345 (10.0%) | Loss: 0.7601 | Batch time: 0.02s
2025-03-05 00:18:22,479 - INFO - [TRAIN] Epoch: 8/30 | Batch: 268/1345 (20.0%) | Loss: 1.5964 | Batch time: 0.02s
2025-03-05 00:18:25,473 - INFO - [TRAIN] Epoch: 8/30 | Batch: 402/1345 (30.0%) | Loss: 0.8362 | Batch time: 0.02s
2025-03-05 00:18:28,481 - INFO - [TRAIN] Epoch: 8/30 | Batch: 536/1345 (39.9%) | Loss: 0.8646 | Batch time: 0.02s
2025-03-05 00:18:31,362 - INFO - [TRAIN] Epoch: 8/30 | Batch: 670/1345 (49.9%) | Loss: 1.1303 | Batch time: 0.02s
2025-03-05 00:18:34,538 - INFO - [TRAIN] Epoch: 8/30 | Batch: 804/1345 (59.9%) | Loss: 1.2944 | Batch time: 0.02s
2025-03-05 00:18:37,441 - INFO - [TRAIN] Epoch: 8/30 | Batch: 938/1345 (69.8%) | Loss: 1.4428 | Batch time: 0.02s
2025-03-05 00:18:40,304 - INFO - [TRAIN] Epoch: 8/30 | Batch: 1072/1345 (79.8%) | Loss: 1.0632 | Batch time: 0.02s
2025-03-05 00:18:43,172 - INFO - [TRAIN] Epoch: 8/30 | Batch: 1206/1345 (89.7%) | Loss: 0.7725 | Batch time: 0.02s
2025-03-05 00:18:45,967 - INFO - [TRAIN] Epoch: 8/30 | Batch: 1340/1345 (99.7%) | Loss: 1.0848 | Batch time: 0.02s
2025-03-05 00:18:46,039 - INFO - [TRAIN] Epoch: 8/30 | Batch: 1344/1345 (100.0%) | Loss: 1.1194 | Batch time: 0.02s
2025-03-05 00:18:46,143 - INFO - [VAL] Epoch: 8/30 | Batch: 0/289 (0.3%) | Loss: 0.3653 | Batch time: 0.03s
2025-03-05 00:18:46,540 - INFO - [VAL] Epoch: 8/30 | Batch: 28/289 (10.0%) | Loss: 0.2618 | Batch time: 0.01s
2025-03-05 00:18:46,930 - INFO - [VAL] Epoch: 8/30 | Batch: 56/289 (19.7%) | Loss: 0.7524 | Batch time: 0.01s
2025-03-05 00:18:47,321 - INFO - [VAL] Epoch: 8/30 | Batch: 84/289 (29.4%) | Loss: 0.2589 | Batch time: 0.01s
2025-03-05 00:18:47,716 - INFO - [VAL] Epoch: 8/30 | Batch: 112/289 (39.1%) | Loss: 0.2513 | Batch time: 0.01s
2025-03-05 00:18:48,107 - INFO - [VAL] Epoch: 8/30 | Batch: 140/289 (48.8%) | Loss: 0.3040 | Batch time: 0.01s
2025-03-05 00:18:48,498 - INFO - [VAL] Epoch: 8/30 | Batch: 168/289 (58.5%) | Loss: 0.2506 | Batch time: 0.01s
2025-03-05 00:18:48,933 - INFO - [VAL] Epoch: 8/30 | Batch: 196/289 (68.2%) | Loss: 0.2778 | Batch time: 0.01s
2025-03-05 00:18:49,328 - INFO - [VAL] Epoch: 8/30 | Batch: 224/289 (77.9%) | Loss: 0.3032 | Batch time: 0.01s
2025-03-05 00:18:49,726 - INFO - [VAL] Epoch: 8/30 | Batch: 252/289 (87.5%) | Loss: 0.4902 | Batch time: 0.01s
2025-03-05 00:18:50,112 - INFO - [VAL] Epoch: 8/30 | Batch: 280/289 (97.2%) | Loss: 0.3356 | Batch time: 0.01s
2025-03-05 00:18:50,219 - INFO - [VAL] Epoch: 8/30 | Batch: 288/289 (100.0%) | Loss: 0.4818 | Batch time: 0.01s
2025-03-05 00:18:50,348 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 8)
2025-03-05 00:18:50,348 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:18:50,348 - INFO - Epoch 8/30 completed in 33.81s
2025-03-05 00:18:50,348 - INFO - Training   - Loss: 0.8793, Accuracy: 0.7427, F1: 0.7451
2025-03-05 00:18:50,348 - INFO - Validation - Loss: 0.3247, Accuracy: 0.9066, F1: 0.9071
2025-03-05 00:18:50,348 - INFO - Validation F1 improved from 0.8824 to 0.9071
2025-03-05 00:18:50,348 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:18:50,348 - INFO - Epoch 9/30
2025-03-05 00:18:50,348 - INFO - ----------------------------------------
2025-03-05 00:18:50,596 - INFO - [TRAIN] Epoch: 9/30 | Batch: 0/1345 (0.1%) | Loss: 0.5680 | Batch time: 0.05s
2025-03-05 00:18:53,588 - INFO - [TRAIN] Epoch: 9/30 | Batch: 134/1345 (10.0%) | Loss: 1.5398 | Batch time: 0.02s
2025-03-05 00:18:56,613 - INFO - [TRAIN] Epoch: 9/30 | Batch: 268/1345 (20.0%) | Loss: 0.8098 | Batch time: 0.02s
2025-03-05 00:18:59,539 - INFO - [TRAIN] Epoch: 9/30 | Batch: 402/1345 (30.0%) | Loss: 0.7545 | Batch time: 0.02s
2025-03-05 00:19:02,398 - INFO - [TRAIN] Epoch: 9/30 | Batch: 536/1345 (39.9%) | Loss: 1.0148 | Batch time: 0.02s
2025-03-05 00:19:05,293 - INFO - [TRAIN] Epoch: 9/30 | Batch: 670/1345 (49.9%) | Loss: 0.7096 | Batch time: 0.02s
2025-03-05 00:19:08,260 - INFO - [TRAIN] Epoch: 9/30 | Batch: 804/1345 (59.9%) | Loss: 0.8617 | Batch time: 0.02s
2025-03-05 00:19:11,279 - INFO - [TRAIN] Epoch: 9/30 | Batch: 938/1345 (69.8%) | Loss: 0.7262 | Batch time: 0.02s
2025-03-05 00:19:14,594 - INFO - [TRAIN] Epoch: 9/30 | Batch: 1072/1345 (79.8%) | Loss: 1.0844 | Batch time: 0.02s
2025-03-05 00:19:17,464 - INFO - [TRAIN] Epoch: 9/30 | Batch: 1206/1345 (89.7%) | Loss: 0.6975 | Batch time: 0.02s
2025-03-05 00:19:20,273 - INFO - [TRAIN] Epoch: 9/30 | Batch: 1340/1345 (99.7%) | Loss: 1.5059 | Batch time: 0.02s
2025-03-05 00:19:20,345 - INFO - [TRAIN] Epoch: 9/30 | Batch: 1344/1345 (100.0%) | Loss: 0.7106 | Batch time: 0.02s
2025-03-05 00:19:20,460 - INFO - [VAL] Epoch: 9/30 | Batch: 0/289 (0.3%) | Loss: 0.3454 | Batch time: 0.02s
2025-03-05 00:19:20,847 - INFO - [VAL] Epoch: 9/30 | Batch: 28/289 (10.0%) | Loss: 0.3207 | Batch time: 0.01s
2025-03-05 00:19:21,240 - INFO - [VAL] Epoch: 9/30 | Batch: 56/289 (19.7%) | Loss: 0.7864 | Batch time: 0.01s
2025-03-05 00:19:21,632 - INFO - [VAL] Epoch: 9/30 | Batch: 84/289 (29.4%) | Loss: 0.2565 | Batch time: 0.01s
2025-03-05 00:19:22,025 - INFO - [VAL] Epoch: 9/30 | Batch: 112/289 (39.1%) | Loss: 0.2849 | Batch time: 0.01s
2025-03-05 00:19:22,416 - INFO - [VAL] Epoch: 9/30 | Batch: 140/289 (48.8%) | Loss: 0.3635 | Batch time: 0.01s
2025-03-05 00:19:22,805 - INFO - [VAL] Epoch: 9/30 | Batch: 168/289 (58.5%) | Loss: 0.2752 | Batch time: 0.01s
2025-03-05 00:19:23,214 - INFO - [VAL] Epoch: 9/30 | Batch: 196/289 (68.2%) | Loss: 0.2696 | Batch time: 0.01s
2025-03-05 00:19:23,614 - INFO - [VAL] Epoch: 9/30 | Batch: 224/289 (77.9%) | Loss: 0.3353 | Batch time: 0.01s
2025-03-05 00:19:24,007 - INFO - [VAL] Epoch: 9/30 | Batch: 252/289 (87.5%) | Loss: 0.4931 | Batch time: 0.01s
2025-03-05 00:19:24,397 - INFO - [VAL] Epoch: 9/30 | Batch: 280/289 (97.2%) | Loss: 0.3319 | Batch time: 0.01s
2025-03-05 00:19:24,499 - INFO - [VAL] Epoch: 9/30 | Batch: 288/289 (100.0%) | Loss: 0.6308 | Batch time: 0.01s
2025-03-05 00:19:24,506 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:19:24,507 - INFO - Epoch 9/30 completed in 34.16s
2025-03-05 00:19:24,507 - INFO - Training   - Loss: 0.8588, Accuracy: 0.7505, F1: 0.7526
2025-03-05 00:19:24,507 - INFO - Validation - Loss: 0.3404, Accuracy: 0.9001, F1: 0.9008
2025-03-05 00:19:24,507 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:19:24,507 - INFO - Epoch 10/30
2025-03-05 00:19:24,507 - INFO - ----------------------------------------
2025-03-05 00:19:24,772 - INFO - [TRAIN] Epoch: 10/30 | Batch: 0/1345 (0.1%) | Loss: 1.1467 | Batch time: 0.03s
2025-03-05 00:19:27,946 - INFO - [TRAIN] Epoch: 10/30 | Batch: 134/1345 (10.0%) | Loss: 0.5705 | Batch time: 0.02s
2025-03-05 00:19:30,902 - INFO - [TRAIN] Epoch: 10/30 | Batch: 268/1345 (20.0%) | Loss: 0.6751 | Batch time: 0.02s
2025-03-05 00:19:33,738 - INFO - [TRAIN] Epoch: 10/30 | Batch: 402/1345 (30.0%) | Loss: 0.6968 | Batch time: 0.02s
2025-03-05 00:19:36,819 - INFO - [TRAIN] Epoch: 10/30 | Batch: 536/1345 (39.9%) | Loss: 0.8148 | Batch time: 0.02s
2025-03-05 00:19:39,813 - INFO - [TRAIN] Epoch: 10/30 | Batch: 670/1345 (49.9%) | Loss: 1.1495 | Batch time: 0.02s
2025-03-05 00:19:42,635 - INFO - [TRAIN] Epoch: 10/30 | Batch: 804/1345 (59.9%) | Loss: 0.7740 | Batch time: 0.02s
2025-03-05 00:19:45,711 - INFO - [TRAIN] Epoch: 10/30 | Batch: 938/1345 (69.8%) | Loss: 0.7751 | Batch time: 0.02s
2025-03-05 00:19:48,745 - INFO - [TRAIN] Epoch: 10/30 | Batch: 1072/1345 (79.8%) | Loss: 0.9820 | Batch time: 0.02s
2025-03-05 00:19:51,948 - INFO - [TRAIN] Epoch: 10/30 | Batch: 1206/1345 (89.7%) | Loss: 0.7103 | Batch time: 0.02s
2025-03-05 00:19:55,717 - INFO - [TRAIN] Epoch: 10/30 | Batch: 1340/1345 (99.7%) | Loss: 0.6339 | Batch time: 0.02s
2025-03-05 00:19:55,797 - INFO - [TRAIN] Epoch: 10/30 | Batch: 1344/1345 (100.0%) | Loss: 1.0354 | Batch time: 0.02s
2025-03-05 00:19:55,961 - INFO - [VAL] Epoch: 10/30 | Batch: 0/289 (0.3%) | Loss: 0.3724 | Batch time: 0.02s
2025-03-05 00:19:56,447 - INFO - [VAL] Epoch: 10/30 | Batch: 28/289 (10.0%) | Loss: 0.2577 | Batch time: 0.02s
2025-03-05 00:19:56,918 - INFO - [VAL] Epoch: 10/30 | Batch: 56/289 (19.7%) | Loss: 0.8049 | Batch time: 0.02s
2025-03-05 00:19:57,398 - INFO - [VAL] Epoch: 10/30 | Batch: 84/289 (29.4%) | Loss: 0.2614 | Batch time: 0.01s
2025-03-05 00:19:57,892 - INFO - [VAL] Epoch: 10/30 | Batch: 112/289 (39.1%) | Loss: 0.2636 | Batch time: 0.02s
2025-03-05 00:19:58,400 - INFO - [VAL] Epoch: 10/30 | Batch: 140/289 (48.8%) | Loss: 0.2987 | Batch time: 0.02s
2025-03-05 00:19:58,932 - INFO - [VAL] Epoch: 10/30 | Batch: 168/289 (58.5%) | Loss: 0.2706 | Batch time: 0.02s
2025-03-05 00:19:59,470 - INFO - [VAL] Epoch: 10/30 | Batch: 196/289 (68.2%) | Loss: 0.2581 | Batch time: 0.02s
2025-03-05 00:20:00,016 - INFO - [VAL] Epoch: 10/30 | Batch: 224/289 (77.9%) | Loss: 0.2806 | Batch time: 0.02s
2025-03-05 00:20:00,506 - INFO - [VAL] Epoch: 10/30 | Batch: 252/289 (87.5%) | Loss: 0.4385 | Batch time: 0.01s
2025-03-05 00:20:00,930 - INFO - [VAL] Epoch: 10/30 | Batch: 280/289 (97.2%) | Loss: 0.3488 | Batch time: 0.02s
2025-03-05 00:20:01,054 - INFO - [VAL] Epoch: 10/30 | Batch: 288/289 (100.0%) | Loss: 0.3328 | Batch time: 0.01s
2025-03-05 00:20:01,063 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:20:01,063 - INFO - Epoch 10/30 completed in 36.56s
2025-03-05 00:20:01,063 - INFO - Training   - Loss: 0.8630, Accuracy: 0.7487, F1: 0.7510
2025-03-05 00:20:01,063 - INFO - Validation - Loss: 0.3194, Accuracy: 0.9045, F1: 0.9049
2025-03-05 00:20:01,063 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:20:01,195 - INFO - Checkpoint saved: checkpoint_epoch_10.pth (Epoch 10)
2025-03-05 00:20:01,195 - INFO - Epoch 11/30
2025-03-05 00:20:01,195 - INFO - ----------------------------------------
2025-03-05 00:20:01,594 - INFO - [TRAIN] Epoch: 11/30 | Batch: 0/1345 (0.1%) | Loss: 0.9005 | Batch time: 0.07s
2025-03-05 00:20:05,346 - INFO - [TRAIN] Epoch: 11/30 | Batch: 134/1345 (10.0%) | Loss: 0.9910 | Batch time: 0.02s
2025-03-05 00:20:08,210 - INFO - [TRAIN] Epoch: 11/30 | Batch: 268/1345 (20.0%) | Loss: 0.7168 | Batch time: 0.03s
2025-03-05 00:20:11,021 - INFO - [TRAIN] Epoch: 11/30 | Batch: 402/1345 (30.0%) | Loss: 0.5040 | Batch time: 0.02s
2025-03-05 00:20:13,932 - INFO - [TRAIN] Epoch: 11/30 | Batch: 536/1345 (39.9%) | Loss: 0.9915 | Batch time: 0.02s
2025-03-05 00:20:16,998 - INFO - [TRAIN] Epoch: 11/30 | Batch: 670/1345 (49.9%) | Loss: 0.5852 | Batch time: 0.02s
2025-03-05 00:20:20,091 - INFO - [TRAIN] Epoch: 11/30 | Batch: 804/1345 (59.9%) | Loss: 0.6971 | Batch time: 0.03s
2025-03-05 00:20:23,151 - INFO - [TRAIN] Epoch: 11/30 | Batch: 938/1345 (69.8%) | Loss: 1.0344 | Batch time: 0.02s
2025-03-05 00:20:26,318 - INFO - [TRAIN] Epoch: 11/30 | Batch: 1072/1345 (79.8%) | Loss: 0.8861 | Batch time: 0.02s
2025-03-05 00:20:29,411 - INFO - [TRAIN] Epoch: 11/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8587 | Batch time: 0.02s
2025-03-05 00:20:32,284 - INFO - [TRAIN] Epoch: 11/30 | Batch: 1340/1345 (99.7%) | Loss: 0.8123 | Batch time: 0.02s
2025-03-05 00:20:32,359 - INFO - [TRAIN] Epoch: 11/30 | Batch: 1344/1345 (100.0%) | Loss: 1.1539 | Batch time: 0.02s
2025-03-05 00:20:32,472 - INFO - [VAL] Epoch: 11/30 | Batch: 0/289 (0.3%) | Loss: 0.3755 | Batch time: 0.02s
2025-03-05 00:20:32,878 - INFO - [VAL] Epoch: 11/30 | Batch: 28/289 (10.0%) | Loss: 0.2160 | Batch time: 0.01s
2025-03-05 00:20:33,279 - INFO - [VAL] Epoch: 11/30 | Batch: 56/289 (19.7%) | Loss: 0.7542 | Batch time: 0.01s
2025-03-05 00:20:33,692 - INFO - [VAL] Epoch: 11/30 | Batch: 84/289 (29.4%) | Loss: 0.2171 | Batch time: 0.01s
2025-03-05 00:20:34,098 - INFO - [VAL] Epoch: 11/30 | Batch: 112/289 (39.1%) | Loss: 0.2622 | Batch time: 0.01s
2025-03-05 00:20:34,505 - INFO - [VAL] Epoch: 11/30 | Batch: 140/289 (48.8%) | Loss: 0.3127 | Batch time: 0.01s
2025-03-05 00:20:34,914 - INFO - [VAL] Epoch: 11/30 | Batch: 168/289 (58.5%) | Loss: 0.2334 | Batch time: 0.01s
2025-03-05 00:20:35,319 - INFO - [VAL] Epoch: 11/30 | Batch: 196/289 (68.2%) | Loss: 0.2285 | Batch time: 0.01s
2025-03-05 00:20:35,727 - INFO - [VAL] Epoch: 11/30 | Batch: 224/289 (77.9%) | Loss: 0.2553 | Batch time: 0.01s
2025-03-05 00:20:36,131 - INFO - [VAL] Epoch: 11/30 | Batch: 252/289 (87.5%) | Loss: 0.4311 | Batch time: 0.01s
2025-03-05 00:20:36,523 - INFO - [VAL] Epoch: 11/30 | Batch: 280/289 (97.2%) | Loss: 0.3369 | Batch time: 0.01s
2025-03-05 00:20:36,627 - INFO - [VAL] Epoch: 11/30 | Batch: 288/289 (100.0%) | Loss: 0.3969 | Batch time: 0.01s
2025-03-05 00:20:36,634 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:20:36,634 - INFO - Epoch 11/30 completed in 35.44s
2025-03-05 00:20:36,634 - INFO - Training   - Loss: 0.8524, Accuracy: 0.7501, F1: 0.7525
2025-03-05 00:20:36,634 - INFO - Validation - Loss: 0.3214, Accuracy: 0.9061, F1: 0.9067
2025-03-05 00:20:36,634 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:20:36,634 - INFO - Epoch 12/30
2025-03-05 00:20:36,634 - INFO - ----------------------------------------
2025-03-05 00:20:36,888 - INFO - [TRAIN] Epoch: 12/30 | Batch: 0/1345 (0.1%) | Loss: 1.3098 | Batch time: 0.05s
2025-03-05 00:20:39,960 - INFO - [TRAIN] Epoch: 12/30 | Batch: 134/1345 (10.0%) | Loss: 0.7484 | Batch time: 0.02s
2025-03-05 00:20:42,872 - INFO - [TRAIN] Epoch: 12/30 | Batch: 268/1345 (20.0%) | Loss: 1.1814 | Batch time: 0.02s
2025-03-05 00:20:45,780 - INFO - [TRAIN] Epoch: 12/30 | Batch: 402/1345 (30.0%) | Loss: 0.9779 | Batch time: 0.02s
2025-03-05 00:20:48,820 - INFO - [TRAIN] Epoch: 12/30 | Batch: 536/1345 (39.9%) | Loss: 0.6179 | Batch time: 0.02s
2025-03-05 00:20:51,814 - INFO - [TRAIN] Epoch: 12/30 | Batch: 670/1345 (49.9%) | Loss: 0.8430 | Batch time: 0.02s
2025-03-05 00:20:54,817 - INFO - [TRAIN] Epoch: 12/30 | Batch: 804/1345 (59.9%) | Loss: 0.4656 | Batch time: 0.02s
2025-03-05 00:20:57,765 - INFO - [TRAIN] Epoch: 12/30 | Batch: 938/1345 (69.8%) | Loss: 1.0198 | Batch time: 0.02s
2025-03-05 00:21:00,716 - INFO - [TRAIN] Epoch: 12/30 | Batch: 1072/1345 (79.8%) | Loss: 1.0543 | Batch time: 0.02s
2025-03-05 00:21:03,631 - INFO - [TRAIN] Epoch: 12/30 | Batch: 1206/1345 (89.7%) | Loss: 0.5425 | Batch time: 0.03s
2025-03-05 00:21:06,491 - INFO - [TRAIN] Epoch: 12/30 | Batch: 1340/1345 (99.7%) | Loss: 0.4480 | Batch time: 0.02s
2025-03-05 00:21:06,562 - INFO - [TRAIN] Epoch: 12/30 | Batch: 1344/1345 (100.0%) | Loss: 1.2652 | Batch time: 0.02s
2025-03-05 00:21:06,677 - INFO - [VAL] Epoch: 12/30 | Batch: 0/289 (0.3%) | Loss: 0.3282 | Batch time: 0.03s
2025-03-05 00:21:07,057 - INFO - [VAL] Epoch: 12/30 | Batch: 28/289 (10.0%) | Loss: 0.2453 | Batch time: 0.01s
2025-03-05 00:21:07,445 - INFO - [VAL] Epoch: 12/30 | Batch: 56/289 (19.7%) | Loss: 0.7428 | Batch time: 0.01s
2025-03-05 00:21:07,839 - INFO - [VAL] Epoch: 12/30 | Batch: 84/289 (29.4%) | Loss: 0.2760 | Batch time: 0.01s
2025-03-05 00:21:08,241 - INFO - [VAL] Epoch: 12/30 | Batch: 112/289 (39.1%) | Loss: 0.2265 | Batch time: 0.01s
2025-03-05 00:21:08,628 - INFO - [VAL] Epoch: 12/30 | Batch: 140/289 (48.8%) | Loss: 0.2863 | Batch time: 0.01s
2025-03-05 00:21:09,014 - INFO - [VAL] Epoch: 12/30 | Batch: 168/289 (58.5%) | Loss: 0.3150 | Batch time: 0.01s
2025-03-05 00:21:09,399 - INFO - [VAL] Epoch: 12/30 | Batch: 196/289 (68.2%) | Loss: 0.2996 | Batch time: 0.01s
2025-03-05 00:21:09,787 - INFO - [VAL] Epoch: 12/30 | Batch: 224/289 (77.9%) | Loss: 0.2798 | Batch time: 0.01s
2025-03-05 00:21:10,171 - INFO - [VAL] Epoch: 12/30 | Batch: 252/289 (87.5%) | Loss: 0.4272 | Batch time: 0.01s
2025-03-05 00:21:10,541 - INFO - [VAL] Epoch: 12/30 | Batch: 280/289 (97.2%) | Loss: 0.3301 | Batch time: 0.01s
2025-03-05 00:21:10,640 - INFO - [VAL] Epoch: 12/30 | Batch: 288/289 (100.0%) | Loss: 0.2757 | Batch time: 0.01s
2025-03-05 00:21:10,646 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:21:10,647 - INFO - Epoch 12/30 completed in 34.01s
2025-03-05 00:21:10,647 - INFO - Training   - Loss: 0.8453, Accuracy: 0.7540, F1: 0.7561
2025-03-05 00:21:10,647 - INFO - Validation - Loss: 0.3202, Accuracy: 0.9049, F1: 0.9060
2025-03-05 00:21:10,647 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:21:10,647 - INFO - Epoch 13/30
2025-03-05 00:21:10,647 - INFO - ----------------------------------------
2025-03-05 00:21:10,895 - INFO - [TRAIN] Epoch: 13/30 | Batch: 0/1345 (0.1%) | Loss: 0.6310 | Batch time: 0.04s
2025-03-05 00:21:13,799 - INFO - [TRAIN] Epoch: 13/30 | Batch: 134/1345 (10.0%) | Loss: 0.7830 | Batch time: 0.02s
2025-03-05 00:21:17,044 - INFO - [TRAIN] Epoch: 13/30 | Batch: 268/1345 (20.0%) | Loss: 1.1054 | Batch time: 0.02s
2025-03-05 00:21:20,318 - INFO - [TRAIN] Epoch: 13/30 | Batch: 402/1345 (30.0%) | Loss: 1.0425 | Batch time: 0.02s
2025-03-05 00:21:23,400 - INFO - [TRAIN] Epoch: 13/30 | Batch: 536/1345 (39.9%) | Loss: 0.5280 | Batch time: 0.02s
2025-03-05 00:21:26,536 - INFO - [TRAIN] Epoch: 13/30 | Batch: 670/1345 (49.9%) | Loss: 0.9618 | Batch time: 0.02s
2025-03-05 00:21:29,537 - INFO - [TRAIN] Epoch: 13/30 | Batch: 804/1345 (59.9%) | Loss: 0.6462 | Batch time: 0.02s
2025-03-05 00:21:32,755 - INFO - [TRAIN] Epoch: 13/30 | Batch: 938/1345 (69.8%) | Loss: 1.1598 | Batch time: 0.02s
2025-03-05 00:21:35,725 - INFO - [TRAIN] Epoch: 13/30 | Batch: 1072/1345 (79.8%) | Loss: 0.7747 | Batch time: 0.02s
2025-03-05 00:21:38,881 - INFO - [TRAIN] Epoch: 13/30 | Batch: 1206/1345 (89.7%) | Loss: 0.5180 | Batch time: 0.02s
2025-03-05 00:21:41,841 - INFO - [TRAIN] Epoch: 13/30 | Batch: 1340/1345 (99.7%) | Loss: 0.6989 | Batch time: 0.02s
2025-03-05 00:21:41,917 - INFO - [TRAIN] Epoch: 13/30 | Batch: 1344/1345 (100.0%) | Loss: 0.7785 | Batch time: 0.02s
2025-03-05 00:21:42,085 - INFO - [VAL] Epoch: 13/30 | Batch: 0/289 (0.3%) | Loss: 0.3567 | Batch time: 0.02s
2025-03-05 00:21:42,481 - INFO - [VAL] Epoch: 13/30 | Batch: 28/289 (10.0%) | Loss: 0.2374 | Batch time: 0.01s
2025-03-05 00:21:42,880 - INFO - [VAL] Epoch: 13/30 | Batch: 56/289 (19.7%) | Loss: 0.7783 | Batch time: 0.01s
2025-03-05 00:21:43,284 - INFO - [VAL] Epoch: 13/30 | Batch: 84/289 (29.4%) | Loss: 0.2746 | Batch time: 0.01s
2025-03-05 00:21:43,688 - INFO - [VAL] Epoch: 13/30 | Batch: 112/289 (39.1%) | Loss: 0.2905 | Batch time: 0.01s
2025-03-05 00:21:44,096 - INFO - [VAL] Epoch: 13/30 | Batch: 140/289 (48.8%) | Loss: 0.3163 | Batch time: 0.01s
2025-03-05 00:21:44,506 - INFO - [VAL] Epoch: 13/30 | Batch: 168/289 (58.5%) | Loss: 0.1853 | Batch time: 0.01s
2025-03-05 00:21:44,917 - INFO - [VAL] Epoch: 13/30 | Batch: 196/289 (68.2%) | Loss: 0.2842 | Batch time: 0.01s
2025-03-05 00:21:45,323 - INFO - [VAL] Epoch: 13/30 | Batch: 224/289 (77.9%) | Loss: 0.2303 | Batch time: 0.01s
2025-03-05 00:21:45,727 - INFO - [VAL] Epoch: 13/30 | Batch: 252/289 (87.5%) | Loss: 0.4214 | Batch time: 0.01s
2025-03-05 00:21:46,122 - INFO - [VAL] Epoch: 13/30 | Batch: 280/289 (97.2%) | Loss: 0.3485 | Batch time: 0.01s
2025-03-05 00:21:46,227 - INFO - [VAL] Epoch: 13/30 | Batch: 288/289 (100.0%) | Loss: 0.3304 | Batch time: 0.01s
2025-03-05 00:21:46,235 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:21:46,235 - INFO - Epoch 13/30 completed in 35.59s
2025-03-05 00:21:46,235 - INFO - Training   - Loss: 0.8472, Accuracy: 0.7540, F1: 0.7564
2025-03-05 00:21:46,235 - INFO - Validation - Loss: 0.3312, Accuracy: 0.9026, F1: 0.9034
2025-03-05 00:21:46,235 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:21:46,235 - INFO - Epoch 14/30
2025-03-05 00:21:46,235 - INFO - ----------------------------------------
2025-03-05 00:21:46,468 - INFO - [TRAIN] Epoch: 14/30 | Batch: 0/1345 (0.1%) | Loss: 0.6593 | Batch time: 0.04s
2025-03-05 00:21:49,681 - INFO - [TRAIN] Epoch: 14/30 | Batch: 134/1345 (10.0%) | Loss: 0.5796 | Batch time: 0.02s
2025-03-05 00:21:52,961 - INFO - [TRAIN] Epoch: 14/30 | Batch: 268/1345 (20.0%) | Loss: 0.7981 | Batch time: 0.02s
2025-03-05 00:21:56,238 - INFO - [TRAIN] Epoch: 14/30 | Batch: 402/1345 (30.0%) | Loss: 0.8310 | Batch time: 0.02s
2025-03-05 00:21:59,368 - INFO - [TRAIN] Epoch: 14/30 | Batch: 536/1345 (39.9%) | Loss: 0.9492 | Batch time: 0.02s
2025-03-05 00:22:02,560 - INFO - [TRAIN] Epoch: 14/30 | Batch: 670/1345 (49.9%) | Loss: 0.4125 | Batch time: 0.02s
2025-03-05 00:22:05,627 - INFO - [TRAIN] Epoch: 14/30 | Batch: 804/1345 (59.9%) | Loss: 0.9295 | Batch time: 0.02s
2025-03-05 00:22:08,827 - INFO - [TRAIN] Epoch: 14/30 | Batch: 938/1345 (69.8%) | Loss: 0.5420 | Batch time: 0.03s
2025-03-05 00:22:12,051 - INFO - [TRAIN] Epoch: 14/30 | Batch: 1072/1345 (79.8%) | Loss: 0.7150 | Batch time: 0.02s
2025-03-05 00:22:15,167 - INFO - [TRAIN] Epoch: 14/30 | Batch: 1206/1345 (89.7%) | Loss: 0.6771 | Batch time: 0.02s
2025-03-05 00:22:18,084 - INFO - [TRAIN] Epoch: 14/30 | Batch: 1340/1345 (99.7%) | Loss: 1.3289 | Batch time: 0.02s
2025-03-05 00:22:18,159 - INFO - [TRAIN] Epoch: 14/30 | Batch: 1344/1345 (100.0%) | Loss: 0.9234 | Batch time: 0.02s
2025-03-05 00:22:18,264 - INFO - [VAL] Epoch: 14/30 | Batch: 0/289 (0.3%) | Loss: 0.3451 | Batch time: 0.03s
2025-03-05 00:22:18,672 - INFO - [VAL] Epoch: 14/30 | Batch: 28/289 (10.0%) | Loss: 0.2305 | Batch time: 0.01s
2025-03-05 00:22:19,063 - INFO - [VAL] Epoch: 14/30 | Batch: 56/289 (19.7%) | Loss: 0.7270 | Batch time: 0.01s
2025-03-05 00:22:19,467 - INFO - [VAL] Epoch: 14/30 | Batch: 84/289 (29.4%) | Loss: 0.1830 | Batch time: 0.01s
2025-03-05 00:22:19,859 - INFO - [VAL] Epoch: 14/30 | Batch: 112/289 (39.1%) | Loss: 0.2609 | Batch time: 0.01s
2025-03-05 00:22:20,251 - INFO - [VAL] Epoch: 14/30 | Batch: 140/289 (48.8%) | Loss: 0.2844 | Batch time: 0.01s
2025-03-05 00:22:20,643 - INFO - [VAL] Epoch: 14/30 | Batch: 168/289 (58.5%) | Loss: 0.2504 | Batch time: 0.01s
2025-03-05 00:22:21,034 - INFO - [VAL] Epoch: 14/30 | Batch: 196/289 (68.2%) | Loss: 0.2197 | Batch time: 0.01s
2025-03-05 00:22:21,435 - INFO - [VAL] Epoch: 14/30 | Batch: 224/289 (77.9%) | Loss: 0.2584 | Batch time: 0.01s
2025-03-05 00:22:21,829 - INFO - [VAL] Epoch: 14/30 | Batch: 252/289 (87.5%) | Loss: 0.4455 | Batch time: 0.01s
2025-03-05 00:22:22,212 - INFO - [VAL] Epoch: 14/30 | Batch: 280/289 (97.2%) | Loss: 0.3308 | Batch time: 0.01s
2025-03-05 00:22:22,318 - INFO - [VAL] Epoch: 14/30 | Batch: 288/289 (100.0%) | Loss: 0.6178 | Batch time: 0.01s
2025-03-05 00:22:22,434 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 14)
2025-03-05 00:22:22,434 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:22:22,434 - INFO - Epoch 14/30 completed in 36.20s
2025-03-05 00:22:22,434 - INFO - Training   - Loss: 0.8434, Accuracy: 0.7522, F1: 0.7544
2025-03-05 00:22:22,434 - INFO - Validation - Loss: 0.3086, Accuracy: 0.9108, F1: 0.9117
2025-03-05 00:22:22,434 - INFO - Validation F1 improved from 0.9071 to 0.9117
2025-03-05 00:22:22,434 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:22:22,434 - INFO - Epoch 15/30
2025-03-05 00:22:22,434 - INFO - ----------------------------------------
2025-03-05 00:22:22,716 - INFO - [TRAIN] Epoch: 15/30 | Batch: 0/1345 (0.1%) | Loss: 0.4823 | Batch time: 0.05s
2025-03-05 00:22:25,822 - INFO - [TRAIN] Epoch: 15/30 | Batch: 134/1345 (10.0%) | Loss: 0.5175 | Batch time: 0.02s
2025-03-05 00:22:28,856 - INFO - [TRAIN] Epoch: 15/30 | Batch: 268/1345 (20.0%) | Loss: 0.8011 | Batch time: 0.02s
2025-03-05 00:22:31,787 - INFO - [TRAIN] Epoch: 15/30 | Batch: 402/1345 (30.0%) | Loss: 0.8358 | Batch time: 0.02s
2025-03-05 00:22:34,795 - INFO - [TRAIN] Epoch: 15/30 | Batch: 536/1345 (39.9%) | Loss: 0.9319 | Batch time: 0.02s
2025-03-05 00:22:37,737 - INFO - [TRAIN] Epoch: 15/30 | Batch: 670/1345 (49.9%) | Loss: 1.1523 | Batch time: 0.02s
2025-03-05 00:22:40,629 - INFO - [TRAIN] Epoch: 15/30 | Batch: 804/1345 (59.9%) | Loss: 0.8144 | Batch time: 0.02s
2025-03-05 00:22:43,494 - INFO - [TRAIN] Epoch: 15/30 | Batch: 938/1345 (69.8%) | Loss: 0.4853 | Batch time: 0.02s
2025-03-05 00:22:46,485 - INFO - [TRAIN] Epoch: 15/30 | Batch: 1072/1345 (79.8%) | Loss: 0.4587 | Batch time: 0.03s
2025-03-05 00:22:49,510 - INFO - [TRAIN] Epoch: 15/30 | Batch: 1206/1345 (89.7%) | Loss: 0.3852 | Batch time: 0.03s
2025-03-05 00:22:52,582 - INFO - [TRAIN] Epoch: 15/30 | Batch: 1340/1345 (99.7%) | Loss: 0.8711 | Batch time: 0.02s
2025-03-05 00:22:52,655 - INFO - [TRAIN] Epoch: 15/30 | Batch: 1344/1345 (100.0%) | Loss: 0.5435 | Batch time: 0.02s
2025-03-05 00:22:52,749 - INFO - [VAL] Epoch: 15/30 | Batch: 0/289 (0.3%) | Loss: 0.3674 | Batch time: 0.02s
2025-03-05 00:22:53,143 - INFO - [VAL] Epoch: 15/30 | Batch: 28/289 (10.0%) | Loss: 0.2713 | Batch time: 0.01s
2025-03-05 00:22:53,529 - INFO - [VAL] Epoch: 15/30 | Batch: 56/289 (19.7%) | Loss: 0.7237 | Batch time: 0.01s
2025-03-05 00:22:53,913 - INFO - [VAL] Epoch: 15/30 | Batch: 84/289 (29.4%) | Loss: 0.2474 | Batch time: 0.01s
2025-03-05 00:22:54,297 - INFO - [VAL] Epoch: 15/30 | Batch: 112/289 (39.1%) | Loss: 0.2435 | Batch time: 0.01s
2025-03-05 00:22:54,686 - INFO - [VAL] Epoch: 15/30 | Batch: 140/289 (48.8%) | Loss: 0.3136 | Batch time: 0.01s
2025-03-05 00:22:55,069 - INFO - [VAL] Epoch: 15/30 | Batch: 168/289 (58.5%) | Loss: 0.2584 | Batch time: 0.01s
2025-03-05 00:22:55,451 - INFO - [VAL] Epoch: 15/30 | Batch: 196/289 (68.2%) | Loss: 0.3129 | Batch time: 0.01s
2025-03-05 00:22:55,844 - INFO - [VAL] Epoch: 15/30 | Batch: 224/289 (77.9%) | Loss: 0.2767 | Batch time: 0.01s
2025-03-05 00:22:56,235 - INFO - [VAL] Epoch: 15/30 | Batch: 252/289 (87.5%) | Loss: 0.4432 | Batch time: 0.01s
2025-03-05 00:22:56,620 - INFO - [VAL] Epoch: 15/30 | Batch: 280/289 (97.2%) | Loss: 0.3673 | Batch time: 0.01s
2025-03-05 00:22:56,720 - INFO - [VAL] Epoch: 15/30 | Batch: 288/289 (100.0%) | Loss: 0.4591 | Batch time: 0.01s
2025-03-05 00:22:56,727 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:22:56,727 - INFO - Epoch 15/30 completed in 34.29s
2025-03-05 00:22:56,727 - INFO - Training   - Loss: 0.8300, Accuracy: 0.7529, F1: 0.7553
2025-03-05 00:22:56,727 - INFO - Validation - Loss: 0.3277, Accuracy: 0.9035, F1: 0.9040
2025-03-05 00:22:56,727 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:22:56,787 - INFO - Checkpoint saved: checkpoint_epoch_15.pth (Epoch 15)
2025-03-05 00:22:56,788 - INFO - Epoch 16/30
2025-03-05 00:22:56,788 - INFO - ----------------------------------------
2025-03-05 00:22:57,058 - INFO - [TRAIN] Epoch: 16/30 | Batch: 0/1345 (0.1%) | Loss: 0.6024 | Batch time: 0.03s
2025-03-05 00:22:59,949 - INFO - [TRAIN] Epoch: 16/30 | Batch: 134/1345 (10.0%) | Loss: 0.7057 | Batch time: 0.02s
2025-03-05 00:23:02,997 - INFO - [TRAIN] Epoch: 16/30 | Batch: 268/1345 (20.0%) | Loss: 0.6971 | Batch time: 0.02s
2025-03-05 00:23:06,046 - INFO - [TRAIN] Epoch: 16/30 | Batch: 402/1345 (30.0%) | Loss: 1.1914 | Batch time: 0.02s
2025-03-05 00:23:09,205 - INFO - [TRAIN] Epoch: 16/30 | Batch: 536/1345 (39.9%) | Loss: 0.8381 | Batch time: 0.02s
2025-03-05 00:23:12,493 - INFO - [TRAIN] Epoch: 16/30 | Batch: 670/1345 (49.9%) | Loss: 0.7615 | Batch time: 0.02s
2025-03-05 00:23:15,620 - INFO - [TRAIN] Epoch: 16/30 | Batch: 804/1345 (59.9%) | Loss: 0.6568 | Batch time: 0.02s
2025-03-05 00:23:18,679 - INFO - [TRAIN] Epoch: 16/30 | Batch: 938/1345 (69.8%) | Loss: 0.4980 | Batch time: 0.02s
2025-03-05 00:23:21,664 - INFO - [TRAIN] Epoch: 16/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6452 | Batch time: 0.02s
2025-03-05 00:23:24,779 - INFO - [TRAIN] Epoch: 16/30 | Batch: 1206/1345 (89.7%) | Loss: 1.4234 | Batch time: 0.03s
2025-03-05 00:23:27,661 - INFO - [TRAIN] Epoch: 16/30 | Batch: 1340/1345 (99.7%) | Loss: 0.3512 | Batch time: 0.02s
2025-03-05 00:23:27,733 - INFO - [TRAIN] Epoch: 16/30 | Batch: 1344/1345 (100.0%) | Loss: 0.8101 | Batch time: 0.02s
2025-03-05 00:23:27,836 - INFO - [VAL] Epoch: 16/30 | Batch: 0/289 (0.3%) | Loss: 0.3642 | Batch time: 0.04s
2025-03-05 00:23:28,228 - INFO - [VAL] Epoch: 16/30 | Batch: 28/289 (10.0%) | Loss: 0.2298 | Batch time: 0.01s
2025-03-05 00:23:28,616 - INFO - [VAL] Epoch: 16/30 | Batch: 56/289 (19.7%) | Loss: 0.7167 | Batch time: 0.01s
2025-03-05 00:23:29,001 - INFO - [VAL] Epoch: 16/30 | Batch: 84/289 (29.4%) | Loss: 0.2474 | Batch time: 0.01s
2025-03-05 00:23:29,392 - INFO - [VAL] Epoch: 16/30 | Batch: 112/289 (39.1%) | Loss: 0.2397 | Batch time: 0.01s
2025-03-05 00:23:29,775 - INFO - [VAL] Epoch: 16/30 | Batch: 140/289 (48.8%) | Loss: 0.2815 | Batch time: 0.01s
2025-03-05 00:23:30,163 - INFO - [VAL] Epoch: 16/30 | Batch: 168/289 (58.5%) | Loss: 0.2500 | Batch time: 0.01s
2025-03-05 00:23:30,549 - INFO - [VAL] Epoch: 16/30 | Batch: 196/289 (68.2%) | Loss: 0.2402 | Batch time: 0.01s
2025-03-05 00:23:30,938 - INFO - [VAL] Epoch: 16/30 | Batch: 224/289 (77.9%) | Loss: 0.2495 | Batch time: 0.01s
2025-03-05 00:23:31,320 - INFO - [VAL] Epoch: 16/30 | Batch: 252/289 (87.5%) | Loss: 0.4687 | Batch time: 0.01s
2025-03-05 00:23:31,695 - INFO - [VAL] Epoch: 16/30 | Batch: 280/289 (97.2%) | Loss: 0.3374 | Batch time: 0.01s
2025-03-05 00:23:31,793 - INFO - [VAL] Epoch: 16/30 | Batch: 288/289 (100.0%) | Loss: 0.3793 | Batch time: 0.01s
2025-03-05 00:23:31,800 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:23:31,800 - INFO - Epoch 16/30 completed in 35.01s
2025-03-05 00:23:31,800 - INFO - Training   - Loss: 0.8262, Accuracy: 0.7564, F1: 0.7585
2025-03-05 00:23:31,800 - INFO - Validation - Loss: 0.3156, Accuracy: 0.9076, F1: 0.9084
2025-03-05 00:23:31,800 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:23:31,800 - INFO - Epoch 17/30
2025-03-05 00:23:31,800 - INFO - ----------------------------------------
2025-03-05 00:23:32,033 - INFO - [TRAIN] Epoch: 17/30 | Batch: 0/1345 (0.1%) | Loss: 0.8551 | Batch time: 0.04s
2025-03-05 00:23:34,785 - INFO - [TRAIN] Epoch: 17/30 | Batch: 134/1345 (10.0%) | Loss: 0.9690 | Batch time: 0.02s
2025-03-05 00:23:37,840 - INFO - [TRAIN] Epoch: 17/30 | Batch: 268/1345 (20.0%) | Loss: 0.5125 | Batch time: 0.02s
2025-03-05 00:23:40,970 - INFO - [TRAIN] Epoch: 17/30 | Batch: 402/1345 (30.0%) | Loss: 1.0478 | Batch time: 0.02s
2025-03-05 00:23:43,982 - INFO - [TRAIN] Epoch: 17/30 | Batch: 536/1345 (39.9%) | Loss: 1.1884 | Batch time: 0.02s
2025-03-05 00:23:47,000 - INFO - [TRAIN] Epoch: 17/30 | Batch: 670/1345 (49.9%) | Loss: 0.7811 | Batch time: 0.02s
2025-03-05 00:23:50,161 - INFO - [TRAIN] Epoch: 17/30 | Batch: 804/1345 (59.9%) | Loss: 0.8195 | Batch time: 0.02s
2025-03-05 00:23:53,092 - INFO - [TRAIN] Epoch: 17/30 | Batch: 938/1345 (69.8%) | Loss: 0.9942 | Batch time: 0.03s
2025-03-05 00:23:56,329 - INFO - [TRAIN] Epoch: 17/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6827 | Batch time: 0.02s
2025-03-05 00:23:59,310 - INFO - [TRAIN] Epoch: 17/30 | Batch: 1206/1345 (89.7%) | Loss: 0.7453 | Batch time: 0.02s
2025-03-05 00:24:02,205 - INFO - [TRAIN] Epoch: 17/30 | Batch: 1340/1345 (99.7%) | Loss: 0.8532 | Batch time: 0.02s
2025-03-05 00:24:02,277 - INFO - [TRAIN] Epoch: 17/30 | Batch: 1344/1345 (100.0%) | Loss: 0.5719 | Batch time: 0.02s
2025-03-05 00:24:02,373 - INFO - [VAL] Epoch: 17/30 | Batch: 0/289 (0.3%) | Loss: 0.3478 | Batch time: 0.02s
2025-03-05 00:24:02,787 - INFO - [VAL] Epoch: 17/30 | Batch: 28/289 (10.0%) | Loss: 0.2500 | Batch time: 0.01s
2025-03-05 00:24:03,179 - INFO - [VAL] Epoch: 17/30 | Batch: 56/289 (19.7%) | Loss: 0.7553 | Batch time: 0.01s
2025-03-05 00:24:03,572 - INFO - [VAL] Epoch: 17/30 | Batch: 84/289 (29.4%) | Loss: 0.2581 | Batch time: 0.01s
2025-03-05 00:24:03,966 - INFO - [VAL] Epoch: 17/30 | Batch: 112/289 (39.1%) | Loss: 0.2524 | Batch time: 0.01s
2025-03-05 00:24:04,368 - INFO - [VAL] Epoch: 17/30 | Batch: 140/289 (48.8%) | Loss: 0.2830 | Batch time: 0.01s
2025-03-05 00:24:04,766 - INFO - [VAL] Epoch: 17/30 | Batch: 168/289 (58.5%) | Loss: 0.2544 | Batch time: 0.01s
2025-03-05 00:24:05,165 - INFO - [VAL] Epoch: 17/30 | Batch: 196/289 (68.2%) | Loss: 0.2697 | Batch time: 0.01s
2025-03-05 00:24:05,563 - INFO - [VAL] Epoch: 17/30 | Batch: 224/289 (77.9%) | Loss: 0.2635 | Batch time: 0.01s
2025-03-05 00:24:05,952 - INFO - [VAL] Epoch: 17/30 | Batch: 252/289 (87.5%) | Loss: 0.4345 | Batch time: 0.01s
2025-03-05 00:24:06,323 - INFO - [VAL] Epoch: 17/30 | Batch: 280/289 (97.2%) | Loss: 0.3680 | Batch time: 0.01s
2025-03-05 00:24:06,422 - INFO - [VAL] Epoch: 17/30 | Batch: 288/289 (100.0%) | Loss: 0.4927 | Batch time: 0.01s
2025-03-05 00:24:06,429 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:24:06,429 - INFO - Epoch 17/30 completed in 34.63s
2025-03-05 00:24:06,429 - INFO - Training   - Loss: 0.8277, Accuracy: 0.7569, F1: 0.7588
2025-03-05 00:24:06,429 - INFO - Validation - Loss: 0.3154, Accuracy: 0.9064, F1: 0.9072
2025-03-05 00:24:06,429 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:24:06,429 - INFO - Epoch 18/30
2025-03-05 00:24:06,429 - INFO - ----------------------------------------
2025-03-05 00:24:06,709 - INFO - [TRAIN] Epoch: 18/30 | Batch: 0/1345 (0.1%) | Loss: 0.4723 | Batch time: 0.04s
2025-03-05 00:24:09,766 - INFO - [TRAIN] Epoch: 18/30 | Batch: 134/1345 (10.0%) | Loss: 0.5311 | Batch time: 0.02s
2025-03-05 00:24:12,957 - INFO - [TRAIN] Epoch: 18/30 | Batch: 268/1345 (20.0%) | Loss: 0.6683 | Batch time: 0.02s
2025-03-05 00:24:16,224 - INFO - [TRAIN] Epoch: 18/30 | Batch: 402/1345 (30.0%) | Loss: 1.1703 | Batch time: 0.02s
2025-03-05 00:24:19,249 - INFO - [TRAIN] Epoch: 18/30 | Batch: 536/1345 (39.9%) | Loss: 0.2877 | Batch time: 0.02s
2025-03-05 00:24:22,320 - INFO - [TRAIN] Epoch: 18/30 | Batch: 670/1345 (49.9%) | Loss: 0.7175 | Batch time: 0.02s
2025-03-05 00:24:25,215 - INFO - [TRAIN] Epoch: 18/30 | Batch: 804/1345 (59.9%) | Loss: 0.5390 | Batch time: 0.02s
2025-03-05 00:24:28,287 - INFO - [TRAIN] Epoch: 18/30 | Batch: 938/1345 (69.8%) | Loss: 0.6235 | Batch time: 0.02s
2025-03-05 00:24:31,465 - INFO - [TRAIN] Epoch: 18/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6272 | Batch time: 0.02s
2025-03-05 00:24:34,364 - INFO - [TRAIN] Epoch: 18/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8489 | Batch time: 0.02s
2025-03-05 00:24:37,135 - INFO - [TRAIN] Epoch: 18/30 | Batch: 1340/1345 (99.7%) | Loss: 0.8724 | Batch time: 0.02s
2025-03-05 00:24:37,206 - INFO - [TRAIN] Epoch: 18/30 | Batch: 1344/1345 (100.0%) | Loss: 0.8564 | Batch time: 0.02s
2025-03-05 00:24:37,318 - INFO - [VAL] Epoch: 18/30 | Batch: 0/289 (0.3%) | Loss: 0.3278 | Batch time: 0.02s
2025-03-05 00:24:37,690 - INFO - [VAL] Epoch: 18/30 | Batch: 28/289 (10.0%) | Loss: 0.2461 | Batch time: 0.01s
2025-03-05 00:24:38,067 - INFO - [VAL] Epoch: 18/30 | Batch: 56/289 (19.7%) | Loss: 0.7033 | Batch time: 0.01s
2025-03-05 00:24:38,462 - INFO - [VAL] Epoch: 18/30 | Batch: 84/289 (29.4%) | Loss: 0.2410 | Batch time: 0.01s
2025-03-05 00:24:38,850 - INFO - [VAL] Epoch: 18/30 | Batch: 112/289 (39.1%) | Loss: 0.2642 | Batch time: 0.01s
2025-03-05 00:24:39,238 - INFO - [VAL] Epoch: 18/30 | Batch: 140/289 (48.8%) | Loss: 0.2858 | Batch time: 0.01s
2025-03-05 00:24:39,628 - INFO - [VAL] Epoch: 18/30 | Batch: 168/289 (58.5%) | Loss: 0.2144 | Batch time: 0.01s
2025-03-05 00:24:40,016 - INFO - [VAL] Epoch: 18/30 | Batch: 196/289 (68.2%) | Loss: 0.2448 | Batch time: 0.01s
2025-03-05 00:24:40,401 - INFO - [VAL] Epoch: 18/30 | Batch: 224/289 (77.9%) | Loss: 0.2481 | Batch time: 0.01s
2025-03-05 00:24:40,785 - INFO - [VAL] Epoch: 18/30 | Batch: 252/289 (87.5%) | Loss: 0.4261 | Batch time: 0.01s
2025-03-05 00:24:41,161 - INFO - [VAL] Epoch: 18/30 | Batch: 280/289 (97.2%) | Loss: 0.3544 | Batch time: 0.01s
2025-03-05 00:24:41,262 - INFO - [VAL] Epoch: 18/30 | Batch: 288/289 (100.0%) | Loss: 0.3497 | Batch time: 0.01s
2025-03-05 00:24:41,269 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:24:41,269 - INFO - Epoch 18/30 completed in 34.84s
2025-03-05 00:24:41,269 - INFO - Training   - Loss: 0.8198, Accuracy: 0.7601, F1: 0.7620
2025-03-05 00:24:41,269 - INFO - Validation - Loss: 0.3104, Accuracy: 0.9100, F1: 0.9107
2025-03-05 00:24:41,269 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:24:41,269 - INFO - Epoch 19/30
2025-03-05 00:24:41,269 - INFO - ----------------------------------------
2025-03-05 00:24:41,495 - INFO - [TRAIN] Epoch: 19/30 | Batch: 0/1345 (0.1%) | Loss: 0.8809 | Batch time: 0.04s
2025-03-05 00:24:44,543 - INFO - [TRAIN] Epoch: 19/30 | Batch: 134/1345 (10.0%) | Loss: 0.7462 | Batch time: 0.02s
2025-03-05 00:24:47,525 - INFO - [TRAIN] Epoch: 19/30 | Batch: 268/1345 (20.0%) | Loss: 0.8668 | Batch time: 0.02s
2025-03-05 00:24:50,518 - INFO - [TRAIN] Epoch: 19/30 | Batch: 402/1345 (30.0%) | Loss: 0.7534 | Batch time: 0.03s
2025-03-05 00:24:53,454 - INFO - [TRAIN] Epoch: 19/30 | Batch: 536/1345 (39.9%) | Loss: 0.7667 | Batch time: 0.02s
2025-03-05 00:24:56,297 - INFO - [TRAIN] Epoch: 19/30 | Batch: 670/1345 (49.9%) | Loss: 0.5022 | Batch time: 0.02s
2025-03-05 00:24:59,198 - INFO - [TRAIN] Epoch: 19/30 | Batch: 804/1345 (59.9%) | Loss: 0.9851 | Batch time: 0.02s
2025-03-05 00:25:02,087 - INFO - [TRAIN] Epoch: 19/30 | Batch: 938/1345 (69.8%) | Loss: 0.7516 | Batch time: 0.02s
2025-03-05 00:25:05,066 - INFO - [TRAIN] Epoch: 19/30 | Batch: 1072/1345 (79.8%) | Loss: 0.7514 | Batch time: 0.02s
2025-03-05 00:25:08,112 - INFO - [TRAIN] Epoch: 19/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8789 | Batch time: 0.02s
2025-03-05 00:25:11,069 - INFO - [TRAIN] Epoch: 19/30 | Batch: 1340/1345 (99.7%) | Loss: 0.5306 | Batch time: 0.02s
2025-03-05 00:25:11,142 - INFO - [TRAIN] Epoch: 19/30 | Batch: 1344/1345 (100.0%) | Loss: 0.6098 | Batch time: 0.02s
2025-03-05 00:25:11,240 - INFO - [VAL] Epoch: 19/30 | Batch: 0/289 (0.3%) | Loss: 0.3416 | Batch time: 0.02s
2025-03-05 00:25:11,639 - INFO - [VAL] Epoch: 19/30 | Batch: 28/289 (10.0%) | Loss: 0.2418 | Batch time: 0.01s
2025-03-05 00:25:12,028 - INFO - [VAL] Epoch: 19/30 | Batch: 56/289 (19.7%) | Loss: 0.7431 | Batch time: 0.01s
2025-03-05 00:25:12,417 - INFO - [VAL] Epoch: 19/30 | Batch: 84/289 (29.4%) | Loss: 0.2383 | Batch time: 0.01s
2025-03-05 00:25:12,805 - INFO - [VAL] Epoch: 19/30 | Batch: 112/289 (39.1%) | Loss: 0.2628 | Batch time: 0.01s
2025-03-05 00:25:13,191 - INFO - [VAL] Epoch: 19/30 | Batch: 140/289 (48.8%) | Loss: 0.2794 | Batch time: 0.01s
2025-03-05 00:25:13,580 - INFO - [VAL] Epoch: 19/30 | Batch: 168/289 (58.5%) | Loss: 0.2432 | Batch time: 0.01s
2025-03-05 00:25:13,976 - INFO - [VAL] Epoch: 19/30 | Batch: 196/289 (68.2%) | Loss: 0.2788 | Batch time: 0.01s
2025-03-05 00:25:14,366 - INFO - [VAL] Epoch: 19/30 | Batch: 224/289 (77.9%) | Loss: 0.2701 | Batch time: 0.01s
2025-03-05 00:25:14,757 - INFO - [VAL] Epoch: 19/30 | Batch: 252/289 (87.5%) | Loss: 0.4255 | Batch time: 0.01s
2025-03-05 00:25:15,135 - INFO - [VAL] Epoch: 19/30 | Batch: 280/289 (97.2%) | Loss: 0.3365 | Batch time: 0.01s
2025-03-05 00:25:15,236 - INFO - [VAL] Epoch: 19/30 | Batch: 288/289 (100.0%) | Loss: 0.4290 | Batch time: 0.01s
2025-03-05 00:25:15,243 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:25:15,243 - INFO - Epoch 19/30 completed in 33.97s
2025-03-05 00:25:15,243 - INFO - Training   - Loss: 0.8354, Accuracy: 0.7560, F1: 0.7584
2025-03-05 00:25:15,243 - INFO - Validation - Loss: 0.3141, Accuracy: 0.9073, F1: 0.9080
2025-03-05 00:25:15,243 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:25:15,243 - INFO - Epoch 20/30
2025-03-05 00:25:15,243 - INFO - ----------------------------------------
2025-03-05 00:25:15,496 - INFO - [TRAIN] Epoch: 20/30 | Batch: 0/1345 (0.1%) | Loss: 0.4580 | Batch time: 0.06s
2025-03-05 00:25:18,574 - INFO - [TRAIN] Epoch: 20/30 | Batch: 134/1345 (10.0%) | Loss: 0.9782 | Batch time: 0.02s
2025-03-05 00:25:21,631 - INFO - [TRAIN] Epoch: 20/30 | Batch: 268/1345 (20.0%) | Loss: 0.9357 | Batch time: 0.02s
2025-03-05 00:25:24,634 - INFO - [TRAIN] Epoch: 20/30 | Batch: 402/1345 (30.0%) | Loss: 0.9482 | Batch time: 0.02s
2025-03-05 00:25:27,728 - INFO - [TRAIN] Epoch: 20/30 | Batch: 536/1345 (39.9%) | Loss: 0.7600 | Batch time: 0.02s
2025-03-05 00:25:30,719 - INFO - [TRAIN] Epoch: 20/30 | Batch: 670/1345 (49.9%) | Loss: 0.8184 | Batch time: 0.02s
2025-03-05 00:25:33,705 - INFO - [TRAIN] Epoch: 20/30 | Batch: 804/1345 (59.9%) | Loss: 0.5492 | Batch time: 0.02s
2025-03-05 00:25:36,651 - INFO - [TRAIN] Epoch: 20/30 | Batch: 938/1345 (69.8%) | Loss: 0.8256 | Batch time: 0.02s
2025-03-05 00:25:39,736 - INFO - [TRAIN] Epoch: 20/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6502 | Batch time: 0.02s
2025-03-05 00:25:42,782 - INFO - [TRAIN] Epoch: 20/30 | Batch: 1206/1345 (89.7%) | Loss: 1.1219 | Batch time: 0.02s
2025-03-05 00:25:45,698 - INFO - [TRAIN] Epoch: 20/30 | Batch: 1340/1345 (99.7%) | Loss: 1.3639 | Batch time: 0.02s
2025-03-05 00:25:45,770 - INFO - [TRAIN] Epoch: 20/30 | Batch: 1344/1345 (100.0%) | Loss: 0.6680 | Batch time: 0.02s
2025-03-05 00:25:45,869 - INFO - [VAL] Epoch: 20/30 | Batch: 0/289 (0.3%) | Loss: 0.3597 | Batch time: 0.04s
2025-03-05 00:25:46,254 - INFO - [VAL] Epoch: 20/30 | Batch: 28/289 (10.0%) | Loss: 0.2349 | Batch time: 0.01s
2025-03-05 00:25:46,648 - INFO - [VAL] Epoch: 20/30 | Batch: 56/289 (19.7%) | Loss: 0.7147 | Batch time: 0.01s
2025-03-05 00:25:47,032 - INFO - [VAL] Epoch: 20/30 | Batch: 84/289 (29.4%) | Loss: 0.2422 | Batch time: 0.01s
2025-03-05 00:25:47,419 - INFO - [VAL] Epoch: 20/30 | Batch: 112/289 (39.1%) | Loss: 0.2333 | Batch time: 0.01s
2025-03-05 00:25:47,819 - INFO - [VAL] Epoch: 20/30 | Batch: 140/289 (48.8%) | Loss: 0.2974 | Batch time: 0.01s
2025-03-05 00:25:48,213 - INFO - [VAL] Epoch: 20/30 | Batch: 168/289 (58.5%) | Loss: 0.2516 | Batch time: 0.01s
2025-03-05 00:25:48,601 - INFO - [VAL] Epoch: 20/30 | Batch: 196/289 (68.2%) | Loss: 0.2523 | Batch time: 0.01s
2025-03-05 00:25:48,988 - INFO - [VAL] Epoch: 20/30 | Batch: 224/289 (77.9%) | Loss: 0.2520 | Batch time: 0.01s
2025-03-05 00:25:49,377 - INFO - [VAL] Epoch: 20/30 | Batch: 252/289 (87.5%) | Loss: 0.4366 | Batch time: 0.01s
2025-03-05 00:25:49,764 - INFO - [VAL] Epoch: 20/30 | Batch: 280/289 (97.2%) | Loss: 0.3444 | Batch time: 0.01s
2025-03-05 00:25:49,866 - INFO - [VAL] Epoch: 20/30 | Batch: 288/289 (100.0%) | Loss: 0.2990 | Batch time: 0.01s
2025-03-05 00:25:50,002 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 20)
2025-03-05 00:25:50,002 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:25:50,002 - INFO - Epoch 20/30 completed in 34.76s
2025-03-05 00:25:50,002 - INFO - Training   - Loss: 0.8376, Accuracy: 0.7560, F1: 0.7579
2025-03-05 00:25:50,002 - INFO - Validation - Loss: 0.3003, Accuracy: 0.9111, F1: 0.9119
2025-03-05 00:25:50,002 - INFO - Validation F1 improved from 0.9117 to 0.9119
2025-03-05 00:25:50,002 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:25:50,057 - INFO - Checkpoint saved: checkpoint_epoch_20.pth (Epoch 20)
2025-03-05 00:25:50,057 - INFO - Epoch 21/30
2025-03-05 00:25:50,057 - INFO - ----------------------------------------
2025-03-05 00:25:50,277 - INFO - [TRAIN] Epoch: 21/30 | Batch: 0/1345 (0.1%) | Loss: 0.3904 | Batch time: 0.02s
2025-03-05 00:25:53,277 - INFO - [TRAIN] Epoch: 21/30 | Batch: 134/1345 (10.0%) | Loss: 1.0963 | Batch time: 0.02s
2025-03-05 00:25:56,357 - INFO - [TRAIN] Epoch: 21/30 | Batch: 268/1345 (20.0%) | Loss: 0.7153 | Batch time: 0.02s
2025-03-05 00:25:59,377 - INFO - [TRAIN] Epoch: 21/30 | Batch: 402/1345 (30.0%) | Loss: 1.2530 | Batch time: 0.02s
2025-03-05 00:26:02,260 - INFO - [TRAIN] Epoch: 21/30 | Batch: 536/1345 (39.9%) | Loss: 0.8260 | Batch time: 0.03s
2025-03-05 00:26:05,216 - INFO - [TRAIN] Epoch: 21/30 | Batch: 670/1345 (49.9%) | Loss: 1.2202 | Batch time: 0.02s
2025-03-05 00:26:08,233 - INFO - [TRAIN] Epoch: 21/30 | Batch: 804/1345 (59.9%) | Loss: 0.8874 | Batch time: 0.02s
2025-03-05 00:26:11,419 - INFO - [TRAIN] Epoch: 21/30 | Batch: 938/1345 (69.8%) | Loss: 1.4794 | Batch time: 0.05s
2025-03-05 00:26:14,526 - INFO - [TRAIN] Epoch: 21/30 | Batch: 1072/1345 (79.8%) | Loss: 0.2709 | Batch time: 0.02s
2025-03-05 00:26:17,501 - INFO - [TRAIN] Epoch: 21/30 | Batch: 1206/1345 (89.7%) | Loss: 0.3862 | Batch time: 0.02s
2025-03-05 00:26:20,382 - INFO - [TRAIN] Epoch: 21/30 | Batch: 1340/1345 (99.7%) | Loss: 0.7530 | Batch time: 0.02s
2025-03-05 00:26:20,455 - INFO - [TRAIN] Epoch: 21/30 | Batch: 1344/1345 (100.0%) | Loss: 1.0259 | Batch time: 0.02s
2025-03-05 00:26:20,553 - INFO - [VAL] Epoch: 21/30 | Batch: 0/289 (0.3%) | Loss: 0.3644 | Batch time: 0.02s
2025-03-05 00:26:20,971 - INFO - [VAL] Epoch: 21/30 | Batch: 28/289 (10.0%) | Loss: 0.2216 | Batch time: 0.01s
2025-03-05 00:26:21,357 - INFO - [VAL] Epoch: 21/30 | Batch: 56/289 (19.7%) | Loss: 0.7613 | Batch time: 0.01s
2025-03-05 00:26:21,743 - INFO - [VAL] Epoch: 21/30 | Batch: 84/289 (29.4%) | Loss: 0.2388 | Batch time: 0.01s
2025-03-05 00:26:22,134 - INFO - [VAL] Epoch: 21/30 | Batch: 112/289 (39.1%) | Loss: 0.2434 | Batch time: 0.01s
2025-03-05 00:26:22,522 - INFO - [VAL] Epoch: 21/30 | Batch: 140/289 (48.8%) | Loss: 0.2607 | Batch time: 0.01s
2025-03-05 00:26:22,920 - INFO - [VAL] Epoch: 21/30 | Batch: 168/289 (58.5%) | Loss: 0.2874 | Batch time: 0.01s
2025-03-05 00:26:23,321 - INFO - [VAL] Epoch: 21/30 | Batch: 196/289 (68.2%) | Loss: 0.2349 | Batch time: 0.01s
2025-03-05 00:26:23,717 - INFO - [VAL] Epoch: 21/30 | Batch: 224/289 (77.9%) | Loss: 0.2319 | Batch time: 0.01s
2025-03-05 00:26:24,122 - INFO - [VAL] Epoch: 21/30 | Batch: 252/289 (87.5%) | Loss: 0.4112 | Batch time: 0.01s
2025-03-05 00:26:24,516 - INFO - [VAL] Epoch: 21/30 | Batch: 280/289 (97.2%) | Loss: 0.3368 | Batch time: 0.01s
2025-03-05 00:26:24,620 - INFO - [VAL] Epoch: 21/30 | Batch: 288/289 (100.0%) | Loss: 0.3737 | Batch time: 0.01s
2025-03-05 00:26:24,744 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 21)
2025-03-05 00:26:24,744 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:26:24,744 - INFO - Epoch 21/30 completed in 34.69s
2025-03-05 00:26:24,744 - INFO - Training   - Loss: 0.8329, Accuracy: 0.7547, F1: 0.7569
2025-03-05 00:26:24,744 - INFO - Validation - Loss: 0.3012, Accuracy: 0.9119, F1: 0.9126
2025-03-05 00:26:24,744 - INFO - Validation F1 improved from 0.9119 to 0.9126
2025-03-05 00:26:24,744 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:26:24,744 - INFO - Epoch 22/30
2025-03-05 00:26:24,744 - INFO - ----------------------------------------
2025-03-05 00:26:25,018 - INFO - [TRAIN] Epoch: 22/30 | Batch: 0/1345 (0.1%) | Loss: 0.9276 | Batch time: 0.04s
2025-03-05 00:26:27,998 - INFO - [TRAIN] Epoch: 22/30 | Batch: 134/1345 (10.0%) | Loss: 0.7286 | Batch time: 0.02s
2025-03-05 00:26:31,028 - INFO - [TRAIN] Epoch: 22/30 | Batch: 268/1345 (20.0%) | Loss: 0.5729 | Batch time: 0.02s
2025-03-05 00:26:33,964 - INFO - [TRAIN] Epoch: 22/30 | Batch: 402/1345 (30.0%) | Loss: 0.5257 | Batch time: 0.02s
2025-03-05 00:26:36,933 - INFO - [TRAIN] Epoch: 22/30 | Batch: 536/1345 (39.9%) | Loss: 0.8267 | Batch time: 0.02s
2025-03-05 00:26:39,750 - INFO - [TRAIN] Epoch: 22/30 | Batch: 670/1345 (49.9%) | Loss: 0.7246 | Batch time: 0.02s
2025-03-05 00:26:42,606 - INFO - [TRAIN] Epoch: 22/30 | Batch: 804/1345 (59.9%) | Loss: 0.6254 | Batch time: 0.02s
2025-03-05 00:26:45,632 - INFO - [TRAIN] Epoch: 22/30 | Batch: 938/1345 (69.8%) | Loss: 1.0324 | Batch time: 0.02s
2025-03-05 00:26:48,620 - INFO - [TRAIN] Epoch: 22/30 | Batch: 1072/1345 (79.8%) | Loss: 0.4325 | Batch time: 0.02s
2025-03-05 00:26:51,707 - INFO - [TRAIN] Epoch: 22/30 | Batch: 1206/1345 (89.7%) | Loss: 0.5541 | Batch time: 0.02s
2025-03-05 00:26:54,668 - INFO - [TRAIN] Epoch: 22/30 | Batch: 1340/1345 (99.7%) | Loss: 0.3918 | Batch time: 0.02s
2025-03-05 00:26:54,740 - INFO - [TRAIN] Epoch: 22/30 | Batch: 1344/1345 (100.0%) | Loss: 0.3810 | Batch time: 0.02s
2025-03-05 00:26:54,842 - INFO - [VAL] Epoch: 22/30 | Batch: 0/289 (0.3%) | Loss: 0.3822 | Batch time: 0.03s
2025-03-05 00:26:55,216 - INFO - [VAL] Epoch: 22/30 | Batch: 28/289 (10.0%) | Loss: 0.2311 | Batch time: 0.01s
2025-03-05 00:26:55,601 - INFO - [VAL] Epoch: 22/30 | Batch: 56/289 (19.7%) | Loss: 0.7322 | Batch time: 0.01s
2025-03-05 00:26:55,990 - INFO - [VAL] Epoch: 22/30 | Batch: 84/289 (29.4%) | Loss: 0.2287 | Batch time: 0.01s
2025-03-05 00:26:56,446 - INFO - [VAL] Epoch: 22/30 | Batch: 112/289 (39.1%) | Loss: 0.2367 | Batch time: 0.01s
2025-03-05 00:26:56,847 - INFO - [VAL] Epoch: 22/30 | Batch: 140/289 (48.8%) | Loss: 0.2755 | Batch time: 0.01s
2025-03-05 00:26:57,242 - INFO - [VAL] Epoch: 22/30 | Batch: 168/289 (58.5%) | Loss: 0.2872 | Batch time: 0.01s
2025-03-05 00:26:57,648 - INFO - [VAL] Epoch: 22/30 | Batch: 196/289 (68.2%) | Loss: 0.2629 | Batch time: 0.01s
2025-03-05 00:26:58,038 - INFO - [VAL] Epoch: 22/30 | Batch: 224/289 (77.9%) | Loss: 0.2593 | Batch time: 0.01s
2025-03-05 00:26:58,429 - INFO - [VAL] Epoch: 22/30 | Batch: 252/289 (87.5%) | Loss: 0.4522 | Batch time: 0.01s
2025-03-05 00:26:58,809 - INFO - [VAL] Epoch: 22/30 | Batch: 280/289 (97.2%) | Loss: 0.3344 | Batch time: 0.01s
2025-03-05 00:26:58,912 - INFO - [VAL] Epoch: 22/30 | Batch: 288/289 (100.0%) | Loss: 0.4975 | Batch time: 0.01s
2025-03-05 00:26:58,919 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:26:58,919 - INFO - Epoch 22/30 completed in 34.18s
2025-03-05 00:26:58,919 - INFO - Training   - Loss: 0.8359, Accuracy: 0.7546, F1: 0.7569
2025-03-05 00:26:58,919 - INFO - Validation - Loss: 0.3195, Accuracy: 0.9068, F1: 0.9077
2025-03-05 00:26:58,919 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:26:58,919 - INFO - Epoch 23/30
2025-03-05 00:26:58,919 - INFO - ----------------------------------------
2025-03-05 00:26:59,163 - INFO - [TRAIN] Epoch: 23/30 | Batch: 0/1345 (0.1%) | Loss: 0.8885 | Batch time: 0.03s
2025-03-05 00:27:02,106 - INFO - [TRAIN] Epoch: 23/30 | Batch: 134/1345 (10.0%) | Loss: 0.7163 | Batch time: 0.03s
2025-03-05 00:27:04,951 - INFO - [TRAIN] Epoch: 23/30 | Batch: 268/1345 (20.0%) | Loss: 0.5992 | Batch time: 0.02s
2025-03-05 00:27:07,910 - INFO - [TRAIN] Epoch: 23/30 | Batch: 402/1345 (30.0%) | Loss: 0.7527 | Batch time: 0.02s
2025-03-05 00:27:10,817 - INFO - [TRAIN] Epoch: 23/30 | Batch: 536/1345 (39.9%) | Loss: 0.7007 | Batch time: 0.02s
2025-03-05 00:27:13,770 - INFO - [TRAIN] Epoch: 23/30 | Batch: 670/1345 (49.9%) | Loss: 1.0210 | Batch time: 0.02s
2025-03-05 00:27:16,955 - INFO - [TRAIN] Epoch: 23/30 | Batch: 804/1345 (59.9%) | Loss: 1.3475 | Batch time: 0.02s
2025-03-05 00:27:19,924 - INFO - [TRAIN] Epoch: 23/30 | Batch: 938/1345 (69.8%) | Loss: 0.5887 | Batch time: 0.02s
2025-03-05 00:27:23,163 - INFO - [TRAIN] Epoch: 23/30 | Batch: 1072/1345 (79.8%) | Loss: 1.0157 | Batch time: 0.02s
2025-03-05 00:27:26,321 - INFO - [TRAIN] Epoch: 23/30 | Batch: 1206/1345 (89.7%) | Loss: 0.9433 | Batch time: 0.02s
2025-03-05 00:27:29,506 - INFO - [TRAIN] Epoch: 23/30 | Batch: 1340/1345 (99.7%) | Loss: 1.2506 | Batch time: 0.02s
2025-03-05 00:27:29,580 - INFO - [TRAIN] Epoch: 23/30 | Batch: 1344/1345 (100.0%) | Loss: 1.0377 | Batch time: 0.02s
2025-03-05 00:27:29,681 - INFO - [VAL] Epoch: 23/30 | Batch: 0/289 (0.3%) | Loss: 0.3551 | Batch time: 0.02s
2025-03-05 00:27:30,103 - INFO - [VAL] Epoch: 23/30 | Batch: 28/289 (10.0%) | Loss: 0.2516 | Batch time: 0.01s
2025-03-05 00:27:30,507 - INFO - [VAL] Epoch: 23/30 | Batch: 56/289 (19.7%) | Loss: 0.7427 | Batch time: 0.01s
2025-03-05 00:27:30,911 - INFO - [VAL] Epoch: 23/30 | Batch: 84/289 (29.4%) | Loss: 0.2202 | Batch time: 0.01s
2025-03-05 00:27:31,322 - INFO - [VAL] Epoch: 23/30 | Batch: 112/289 (39.1%) | Loss: 0.2471 | Batch time: 0.01s
2025-03-05 00:27:31,731 - INFO - [VAL] Epoch: 23/30 | Batch: 140/289 (48.8%) | Loss: 0.3186 | Batch time: 0.01s
2025-03-05 00:27:32,140 - INFO - [VAL] Epoch: 23/30 | Batch: 168/289 (58.5%) | Loss: 0.2644 | Batch time: 0.01s
2025-03-05 00:27:32,545 - INFO - [VAL] Epoch: 23/30 | Batch: 196/289 (68.2%) | Loss: 0.2387 | Batch time: 0.01s
2025-03-05 00:27:32,943 - INFO - [VAL] Epoch: 23/30 | Batch: 224/289 (77.9%) | Loss: 0.2468 | Batch time: 0.01s
2025-03-05 00:27:33,367 - INFO - [VAL] Epoch: 23/30 | Batch: 252/289 (87.5%) | Loss: 0.4476 | Batch time: 0.01s
2025-03-05 00:27:33,767 - INFO - [VAL] Epoch: 23/30 | Batch: 280/289 (97.2%) | Loss: 0.3549 | Batch time: 0.01s
2025-03-05 00:27:33,869 - INFO - [VAL] Epoch: 23/30 | Batch: 288/289 (100.0%) | Loss: 0.4796 | Batch time: 0.01s
2025-03-05 00:27:33,877 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:27:33,877 - INFO - Epoch 23/30 completed in 34.96s
2025-03-05 00:27:33,877 - INFO - Training   - Loss: 0.8303, Accuracy: 0.7592, F1: 0.7615
2025-03-05 00:27:33,877 - INFO - Validation - Loss: 0.3123, Accuracy: 0.9092, F1: 0.9101
2025-03-05 00:27:33,877 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:27:33,877 - INFO - Epoch 24/30
2025-03-05 00:27:33,877 - INFO - ----------------------------------------
2025-03-05 00:27:34,140 - INFO - [TRAIN] Epoch: 24/30 | Batch: 0/1345 (0.1%) | Loss: 0.8910 | Batch time: 0.02s
2025-03-05 00:27:37,274 - INFO - [TRAIN] Epoch: 24/30 | Batch: 134/1345 (10.0%) | Loss: 1.1241 | Batch time: 0.03s
2025-03-05 00:27:40,435 - INFO - [TRAIN] Epoch: 24/30 | Batch: 268/1345 (20.0%) | Loss: 1.2500 | Batch time: 0.03s
2025-03-05 00:27:44,124 - INFO - [TRAIN] Epoch: 24/30 | Batch: 402/1345 (30.0%) | Loss: 1.0204 | Batch time: 0.03s
2025-03-05 00:27:47,998 - INFO - [TRAIN] Epoch: 24/30 | Batch: 536/1345 (39.9%) | Loss: 0.5605 | Batch time: 0.03s
2025-03-05 00:27:51,578 - INFO - [TRAIN] Epoch: 24/30 | Batch: 670/1345 (49.9%) | Loss: 1.1064 | Batch time: 0.02s
2025-03-05 00:27:54,580 - INFO - [TRAIN] Epoch: 24/30 | Batch: 804/1345 (59.9%) | Loss: 0.5630 | Batch time: 0.02s
2025-03-05 00:27:57,471 - INFO - [TRAIN] Epoch: 24/30 | Batch: 938/1345 (69.8%) | Loss: 0.4895 | Batch time: 0.02s
2025-03-05 00:28:00,504 - INFO - [TRAIN] Epoch: 24/30 | Batch: 1072/1345 (79.8%) | Loss: 1.3003 | Batch time: 0.02s
2025-03-05 00:28:03,629 - INFO - [TRAIN] Epoch: 24/30 | Batch: 1206/1345 (89.7%) | Loss: 1.0078 | Batch time: 0.02s
2025-03-05 00:28:06,712 - INFO - [TRAIN] Epoch: 24/30 | Batch: 1340/1345 (99.7%) | Loss: 1.2151 | Batch time: 0.02s
2025-03-05 00:28:06,784 - INFO - [TRAIN] Epoch: 24/30 | Batch: 1344/1345 (100.0%) | Loss: 1.0367 | Batch time: 0.02s
2025-03-05 00:28:06,902 - INFO - [VAL] Epoch: 24/30 | Batch: 0/289 (0.3%) | Loss: 0.3593 | Batch time: 0.02s
2025-03-05 00:28:07,303 - INFO - [VAL] Epoch: 24/30 | Batch: 28/289 (10.0%) | Loss: 0.2411 | Batch time: 0.01s
2025-03-05 00:28:07,687 - INFO - [VAL] Epoch: 24/30 | Batch: 56/289 (19.7%) | Loss: 0.6998 | Batch time: 0.01s
2025-03-05 00:28:08,076 - INFO - [VAL] Epoch: 24/30 | Batch: 84/289 (29.4%) | Loss: 0.2488 | Batch time: 0.01s
2025-03-05 00:28:08,470 - INFO - [VAL] Epoch: 24/30 | Batch: 112/289 (39.1%) | Loss: 0.2520 | Batch time: 0.01s
2025-03-05 00:28:08,862 - INFO - [VAL] Epoch: 24/30 | Batch: 140/289 (48.8%) | Loss: 0.2814 | Batch time: 0.01s
2025-03-05 00:28:09,253 - INFO - [VAL] Epoch: 24/30 | Batch: 168/289 (58.5%) | Loss: 0.2576 | Batch time: 0.01s
2025-03-05 00:28:09,641 - INFO - [VAL] Epoch: 24/30 | Batch: 196/289 (68.2%) | Loss: 0.2822 | Batch time: 0.01s
2025-03-05 00:28:10,034 - INFO - [VAL] Epoch: 24/30 | Batch: 224/289 (77.9%) | Loss: 0.2568 | Batch time: 0.01s
2025-03-05 00:28:10,437 - INFO - [VAL] Epoch: 24/30 | Batch: 252/289 (87.5%) | Loss: 0.4302 | Batch time: 0.01s
2025-03-05 00:28:10,838 - INFO - [VAL] Epoch: 24/30 | Batch: 280/289 (97.2%) | Loss: 0.3187 | Batch time: 0.01s
2025-03-05 00:28:10,942 - INFO - [VAL] Epoch: 24/30 | Batch: 288/289 (100.0%) | Loss: 0.4354 | Batch time: 0.01s
2025-03-05 00:28:10,949 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:28:10,949 - INFO - Epoch 24/30 completed in 37.07s
2025-03-05 00:28:10,949 - INFO - Training   - Loss: 0.8254, Accuracy: 0.7571, F1: 0.7594
2025-03-05 00:28:10,949 - INFO - Validation - Loss: 0.3173, Accuracy: 0.9064, F1: 0.9071
2025-03-05 00:28:10,949 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:28:10,949 - INFO - Epoch 25/30
2025-03-05 00:28:10,949 - INFO - ----------------------------------------
2025-03-05 00:28:11,238 - INFO - [TRAIN] Epoch: 25/30 | Batch: 0/1345 (0.1%) | Loss: 0.9923 | Batch time: 0.03s
2025-03-05 00:28:14,598 - INFO - [TRAIN] Epoch: 25/30 | Batch: 134/1345 (10.0%) | Loss: 0.5858 | Batch time: 0.02s
2025-03-05 00:28:17,975 - INFO - [TRAIN] Epoch: 25/30 | Batch: 268/1345 (20.0%) | Loss: 0.7936 | Batch time: 0.02s
2025-03-05 00:28:21,249 - INFO - [TRAIN] Epoch: 25/30 | Batch: 402/1345 (30.0%) | Loss: 0.7263 | Batch time: 0.02s
2025-03-05 00:28:24,497 - INFO - [TRAIN] Epoch: 25/30 | Batch: 536/1345 (39.9%) | Loss: 0.7282 | Batch time: 0.02s
2025-03-05 00:28:27,595 - INFO - [TRAIN] Epoch: 25/30 | Batch: 670/1345 (49.9%) | Loss: 0.5509 | Batch time: 0.02s
2025-03-05 00:28:30,706 - INFO - [TRAIN] Epoch: 25/30 | Batch: 804/1345 (59.9%) | Loss: 1.2438 | Batch time: 0.02s
2025-03-05 00:28:33,811 - INFO - [TRAIN] Epoch: 25/30 | Batch: 938/1345 (69.8%) | Loss: 0.9952 | Batch time: 0.02s
2025-03-05 00:28:36,874 - INFO - [TRAIN] Epoch: 25/30 | Batch: 1072/1345 (79.8%) | Loss: 0.8927 | Batch time: 0.02s
2025-03-05 00:28:39,971 - INFO - [TRAIN] Epoch: 25/30 | Batch: 1206/1345 (89.7%) | Loss: 1.1185 | Batch time: 0.02s
2025-03-05 00:28:42,932 - INFO - [TRAIN] Epoch: 25/30 | Batch: 1340/1345 (99.7%) | Loss: 1.0904 | Batch time: 0.02s
2025-03-05 00:28:43,004 - INFO - [TRAIN] Epoch: 25/30 | Batch: 1344/1345 (100.0%) | Loss: 0.8491 | Batch time: 0.02s
2025-03-05 00:28:43,113 - INFO - [VAL] Epoch: 25/30 | Batch: 0/289 (0.3%) | Loss: 0.3442 | Batch time: 0.02s
2025-03-05 00:28:43,546 - INFO - [VAL] Epoch: 25/30 | Batch: 28/289 (10.0%) | Loss: 0.2443 | Batch time: 0.01s
2025-03-05 00:28:43,943 - INFO - [VAL] Epoch: 25/30 | Batch: 56/289 (19.7%) | Loss: 0.7104 | Batch time: 0.01s
2025-03-05 00:28:44,342 - INFO - [VAL] Epoch: 25/30 | Batch: 84/289 (29.4%) | Loss: 0.2493 | Batch time: 0.01s
2025-03-05 00:28:44,740 - INFO - [VAL] Epoch: 25/30 | Batch: 112/289 (39.1%) | Loss: 0.2606 | Batch time: 0.01s
2025-03-05 00:28:45,141 - INFO - [VAL] Epoch: 25/30 | Batch: 140/289 (48.8%) | Loss: 0.2794 | Batch time: 0.01s
2025-03-05 00:28:45,541 - INFO - [VAL] Epoch: 25/30 | Batch: 168/289 (58.5%) | Loss: 0.2453 | Batch time: 0.01s
2025-03-05 00:28:45,936 - INFO - [VAL] Epoch: 25/30 | Batch: 196/289 (68.2%) | Loss: 0.2433 | Batch time: 0.01s
2025-03-05 00:28:46,345 - INFO - [VAL] Epoch: 25/30 | Batch: 224/289 (77.9%) | Loss: 0.2375 | Batch time: 0.01s
2025-03-05 00:28:46,746 - INFO - [VAL] Epoch: 25/30 | Batch: 252/289 (87.5%) | Loss: 0.4255 | Batch time: 0.01s
2025-03-05 00:28:47,125 - INFO - [VAL] Epoch: 25/30 | Batch: 280/289 (97.2%) | Loss: 0.3424 | Batch time: 0.01s
2025-03-05 00:28:47,225 - INFO - [VAL] Epoch: 25/30 | Batch: 288/289 (100.0%) | Loss: 0.5772 | Batch time: 0.01s
2025-03-05 00:28:47,232 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:28:47,232 - INFO - Epoch 25/30 completed in 36.28s
2025-03-05 00:28:47,232 - INFO - Training   - Loss: 0.8245, Accuracy: 0.7564, F1: 0.7582
2025-03-05 00:28:47,232 - INFO - Validation - Loss: 0.3096, Accuracy: 0.9086, F1: 0.9093
2025-03-05 00:28:47,232 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:28:47,298 - INFO - Checkpoint saved: checkpoint_epoch_25.pth (Epoch 25)
2025-03-05 00:28:47,299 - INFO - Epoch 26/30
2025-03-05 00:28:47,299 - INFO - ----------------------------------------
2025-03-05 00:28:47,535 - INFO - [TRAIN] Epoch: 26/30 | Batch: 0/1345 (0.1%) | Loss: 1.0186 | Batch time: 0.03s
2025-03-05 00:28:50,512 - INFO - [TRAIN] Epoch: 26/30 | Batch: 134/1345 (10.0%) | Loss: 1.1050 | Batch time: 0.02s
2025-03-05 00:28:53,467 - INFO - [TRAIN] Epoch: 26/30 | Batch: 268/1345 (20.0%) | Loss: 1.5599 | Batch time: 0.02s
2025-03-05 00:28:56,362 - INFO - [TRAIN] Epoch: 26/30 | Batch: 402/1345 (30.0%) | Loss: 0.9503 | Batch time: 0.02s
2025-03-05 00:28:59,271 - INFO - [TRAIN] Epoch: 26/30 | Batch: 536/1345 (39.9%) | Loss: 0.7986 | Batch time: 0.02s
2025-03-05 00:29:02,316 - INFO - [TRAIN] Epoch: 26/30 | Batch: 670/1345 (49.9%) | Loss: 0.5054 | Batch time: 0.02s
2025-03-05 00:29:05,214 - INFO - [TRAIN] Epoch: 26/30 | Batch: 804/1345 (59.9%) | Loss: 0.8721 | Batch time: 0.02s
2025-03-05 00:29:08,214 - INFO - [TRAIN] Epoch: 26/30 | Batch: 938/1345 (69.8%) | Loss: 0.9484 | Batch time: 0.03s
2025-03-05 00:29:11,183 - INFO - [TRAIN] Epoch: 26/30 | Batch: 1072/1345 (79.8%) | Loss: 1.0996 | Batch time: 0.02s
2025-03-05 00:29:14,106 - INFO - [TRAIN] Epoch: 26/30 | Batch: 1206/1345 (89.7%) | Loss: 1.0312 | Batch time: 0.02s
2025-03-05 00:29:17,013 - INFO - [TRAIN] Epoch: 26/30 | Batch: 1340/1345 (99.7%) | Loss: 0.9935 | Batch time: 0.02s
2025-03-05 00:29:17,087 - INFO - [TRAIN] Epoch: 26/30 | Batch: 1344/1345 (100.0%) | Loss: 0.4696 | Batch time: 0.02s
2025-03-05 00:29:17,192 - INFO - [VAL] Epoch: 26/30 | Batch: 0/289 (0.3%) | Loss: 0.3390 | Batch time: 0.03s
2025-03-05 00:29:17,587 - INFO - [VAL] Epoch: 26/30 | Batch: 28/289 (10.0%) | Loss: 0.2144 | Batch time: 0.01s
2025-03-05 00:29:17,971 - INFO - [VAL] Epoch: 26/30 | Batch: 56/289 (19.7%) | Loss: 0.7296 | Batch time: 0.01s
2025-03-05 00:29:18,368 - INFO - [VAL] Epoch: 26/30 | Batch: 84/289 (29.4%) | Loss: 0.2394 | Batch time: 0.01s
2025-03-05 00:29:18,768 - INFO - [VAL] Epoch: 26/30 | Batch: 112/289 (39.1%) | Loss: 0.2366 | Batch time: 0.01s
2025-03-05 00:29:19,175 - INFO - [VAL] Epoch: 26/30 | Batch: 140/289 (48.8%) | Loss: 0.2585 | Batch time: 0.01s
2025-03-05 00:29:19,581 - INFO - [VAL] Epoch: 26/30 | Batch: 168/289 (58.5%) | Loss: 0.2480 | Batch time: 0.01s
2025-03-05 00:29:19,984 - INFO - [VAL] Epoch: 26/30 | Batch: 196/289 (68.2%) | Loss: 0.2383 | Batch time: 0.01s
2025-03-05 00:29:20,381 - INFO - [VAL] Epoch: 26/30 | Batch: 224/289 (77.9%) | Loss: 0.2487 | Batch time: 0.01s
2025-03-05 00:29:20,781 - INFO - [VAL] Epoch: 26/30 | Batch: 252/289 (87.5%) | Loss: 0.4131 | Batch time: 0.01s
2025-03-05 00:29:21,165 - INFO - [VAL] Epoch: 26/30 | Batch: 280/289 (97.2%) | Loss: 0.3162 | Batch time: 0.01s
2025-03-05 00:29:21,271 - INFO - [VAL] Epoch: 26/30 | Batch: 288/289 (100.0%) | Loss: 0.3962 | Batch time: 0.01s
2025-03-05 00:29:21,376 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 26)
2025-03-05 00:29:21,376 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:29:21,376 - INFO - Epoch 26/30 completed in 34.08s
2025-03-05 00:29:21,377 - INFO - Training   - Loss: 0.8225, Accuracy: 0.7597, F1: 0.7615
2025-03-05 00:29:21,377 - INFO - Validation - Loss: 0.2966, Accuracy: 0.9127, F1: 0.9135
2025-03-05 00:29:21,377 - INFO - Validation F1 improved from 0.9126 to 0.9135
2025-03-05 00:29:21,377 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:29:21,377 - INFO - Epoch 27/30
2025-03-05 00:29:21,377 - INFO - ----------------------------------------
2025-03-05 00:29:21,608 - INFO - [TRAIN] Epoch: 27/30 | Batch: 0/1345 (0.1%) | Loss: 1.1557 | Batch time: 0.03s
2025-03-05 00:29:24,780 - INFO - [TRAIN] Epoch: 27/30 | Batch: 134/1345 (10.0%) | Loss: 0.7198 | Batch time: 0.02s
2025-03-05 00:29:27,881 - INFO - [TRAIN] Epoch: 27/30 | Batch: 268/1345 (20.0%) | Loss: 0.4359 | Batch time: 0.02s
2025-03-05 00:29:31,101 - INFO - [TRAIN] Epoch: 27/30 | Batch: 402/1345 (30.0%) | Loss: 0.9854 | Batch time: 0.02s
2025-03-05 00:29:34,257 - INFO - [TRAIN] Epoch: 27/30 | Batch: 536/1345 (39.9%) | Loss: 0.5942 | Batch time: 0.02s
2025-03-05 00:29:37,227 - INFO - [TRAIN] Epoch: 27/30 | Batch: 670/1345 (49.9%) | Loss: 0.5586 | Batch time: 0.02s
2025-03-05 00:29:40,157 - INFO - [TRAIN] Epoch: 27/30 | Batch: 804/1345 (59.9%) | Loss: 0.3667 | Batch time: 0.02s
2025-03-05 00:29:43,060 - INFO - [TRAIN] Epoch: 27/30 | Batch: 938/1345 (69.8%) | Loss: 0.5727 | Batch time: 0.02s
2025-03-05 00:29:46,041 - INFO - [TRAIN] Epoch: 27/30 | Batch: 1072/1345 (79.8%) | Loss: 0.6442 | Batch time: 0.02s
2025-03-05 00:29:48,999 - INFO - [TRAIN] Epoch: 27/30 | Batch: 1206/1345 (89.7%) | Loss: 1.1731 | Batch time: 0.02s
2025-03-05 00:29:51,852 - INFO - [TRAIN] Epoch: 27/30 | Batch: 1340/1345 (99.7%) | Loss: 0.6809 | Batch time: 0.02s
2025-03-05 00:29:51,923 - INFO - [TRAIN] Epoch: 27/30 | Batch: 1344/1345 (100.0%) | Loss: 0.5185 | Batch time: 0.02s
2025-03-05 00:29:52,012 - INFO - [VAL] Epoch: 27/30 | Batch: 0/289 (0.3%) | Loss: 0.3492 | Batch time: 0.03s
2025-03-05 00:29:52,397 - INFO - [VAL] Epoch: 27/30 | Batch: 28/289 (10.0%) | Loss: 0.2587 | Batch time: 0.01s
2025-03-05 00:29:52,781 - INFO - [VAL] Epoch: 27/30 | Batch: 56/289 (19.7%) | Loss: 0.7442 | Batch time: 0.01s
2025-03-05 00:29:53,176 - INFO - [VAL] Epoch: 27/30 | Batch: 84/289 (29.4%) | Loss: 0.2371 | Batch time: 0.01s
2025-03-05 00:29:53,568 - INFO - [VAL] Epoch: 27/30 | Batch: 112/289 (39.1%) | Loss: 0.2580 | Batch time: 0.01s
2025-03-05 00:29:53,963 - INFO - [VAL] Epoch: 27/30 | Batch: 140/289 (48.8%) | Loss: 0.3167 | Batch time: 0.01s
2025-03-05 00:29:54,353 - INFO - [VAL] Epoch: 27/30 | Batch: 168/289 (58.5%) | Loss: 0.2304 | Batch time: 0.01s
2025-03-05 00:29:54,739 - INFO - [VAL] Epoch: 27/30 | Batch: 196/289 (68.2%) | Loss: 0.2544 | Batch time: 0.01s
2025-03-05 00:29:55,125 - INFO - [VAL] Epoch: 27/30 | Batch: 224/289 (77.9%) | Loss: 0.2627 | Batch time: 0.01s
2025-03-05 00:29:55,515 - INFO - [VAL] Epoch: 27/30 | Batch: 252/289 (87.5%) | Loss: 0.4154 | Batch time: 0.01s
2025-03-05 00:29:55,888 - INFO - [VAL] Epoch: 27/30 | Batch: 280/289 (97.2%) | Loss: 0.3507 | Batch time: 0.01s
2025-03-05 00:29:55,987 - INFO - [VAL] Epoch: 27/30 | Batch: 288/289 (100.0%) | Loss: 0.4956 | Batch time: 0.01s
2025-03-05 00:29:55,993 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:29:55,994 - INFO - Epoch 27/30 completed in 34.62s
2025-03-05 00:29:55,994 - INFO - Training   - Loss: 0.8331, Accuracy: 0.7556, F1: 0.7577
2025-03-05 00:29:55,994 - INFO - Validation - Loss: 0.3116, Accuracy: 0.9085, F1: 0.9093
2025-03-05 00:29:55,994 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:29:55,994 - INFO - Epoch 28/30
2025-03-05 00:29:55,994 - INFO - ----------------------------------------
2025-03-05 00:29:56,232 - INFO - [TRAIN] Epoch: 28/30 | Batch: 0/1345 (0.1%) | Loss: 0.5896 | Batch time: 0.03s
2025-03-05 00:29:59,134 - INFO - [TRAIN] Epoch: 28/30 | Batch: 134/1345 (10.0%) | Loss: 0.8048 | Batch time: 0.02s
2025-03-05 00:30:02,087 - INFO - [TRAIN] Epoch: 28/30 | Batch: 268/1345 (20.0%) | Loss: 1.2697 | Batch time: 0.02s
2025-03-05 00:30:05,011 - INFO - [TRAIN] Epoch: 28/30 | Batch: 402/1345 (30.0%) | Loss: 0.8790 | Batch time: 0.02s
2025-03-05 00:30:07,975 - INFO - [TRAIN] Epoch: 28/30 | Batch: 536/1345 (39.9%) | Loss: 1.3137 | Batch time: 0.02s
2025-03-05 00:30:10,952 - INFO - [TRAIN] Epoch: 28/30 | Batch: 670/1345 (49.9%) | Loss: 0.8329 | Batch time: 0.02s
2025-03-05 00:30:13,888 - INFO - [TRAIN] Epoch: 28/30 | Batch: 804/1345 (59.9%) | Loss: 0.9115 | Batch time: 0.02s
2025-03-05 00:30:17,174 - INFO - [TRAIN] Epoch: 28/30 | Batch: 938/1345 (69.8%) | Loss: 0.6875 | Batch time: 0.03s
2025-03-05 00:30:20,269 - INFO - [TRAIN] Epoch: 28/30 | Batch: 1072/1345 (79.8%) | Loss: 0.5630 | Batch time: 0.02s
2025-03-05 00:30:23,239 - INFO - [TRAIN] Epoch: 28/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8360 | Batch time: 0.02s
2025-03-05 00:30:26,094 - INFO - [TRAIN] Epoch: 28/30 | Batch: 1340/1345 (99.7%) | Loss: 0.6188 | Batch time: 0.02s
2025-03-05 00:30:26,167 - INFO - [TRAIN] Epoch: 28/30 | Batch: 1344/1345 (100.0%) | Loss: 0.7697 | Batch time: 0.02s
2025-03-05 00:30:26,279 - INFO - [VAL] Epoch: 28/30 | Batch: 0/289 (0.3%) | Loss: 0.3506 | Batch time: 0.03s
2025-03-05 00:30:26,683 - INFO - [VAL] Epoch: 28/30 | Batch: 28/289 (10.0%) | Loss: 0.2722 | Batch time: 0.01s
2025-03-05 00:30:27,072 - INFO - [VAL] Epoch: 28/30 | Batch: 56/289 (19.7%) | Loss: 0.7317 | Batch time: 0.01s
2025-03-05 00:30:27,469 - INFO - [VAL] Epoch: 28/30 | Batch: 84/289 (29.4%) | Loss: 0.2252 | Batch time: 0.01s
2025-03-05 00:30:27,857 - INFO - [VAL] Epoch: 28/30 | Batch: 112/289 (39.1%) | Loss: 0.2600 | Batch time: 0.01s
2025-03-05 00:30:28,245 - INFO - [VAL] Epoch: 28/30 | Batch: 140/289 (48.8%) | Loss: 0.2969 | Batch time: 0.01s
2025-03-05 00:30:28,638 - INFO - [VAL] Epoch: 28/30 | Batch: 168/289 (58.5%) | Loss: 0.2866 | Batch time: 0.01s
2025-03-05 00:30:29,034 - INFO - [VAL] Epoch: 28/30 | Batch: 196/289 (68.2%) | Loss: 0.2845 | Batch time: 0.01s
2025-03-05 00:30:29,433 - INFO - [VAL] Epoch: 28/30 | Batch: 224/289 (77.9%) | Loss: 0.2734 | Batch time: 0.01s
2025-03-05 00:30:29,826 - INFO - [VAL] Epoch: 28/30 | Batch: 252/289 (87.5%) | Loss: 0.4153 | Batch time: 0.01s
2025-03-05 00:30:30,203 - INFO - [VAL] Epoch: 28/30 | Batch: 280/289 (97.2%) | Loss: 0.3627 | Batch time: 0.01s
2025-03-05 00:30:30,303 - INFO - [VAL] Epoch: 28/30 | Batch: 288/289 (100.0%) | Loss: 0.3694 | Batch time: 0.01s
2025-03-05 00:30:30,310 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:30:30,310 - INFO - Epoch 28/30 completed in 34.32s
2025-03-05 00:30:30,310 - INFO - Training   - Loss: 0.8160, Accuracy: 0.7579, F1: 0.7599
2025-03-05 00:30:30,310 - INFO - Validation - Loss: 0.3275, Accuracy: 0.9032, F1: 0.9039
2025-03-05 00:30:30,310 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:30:30,310 - INFO - Epoch 29/30
2025-03-05 00:30:30,310 - INFO - ----------------------------------------
2025-03-05 00:30:30,558 - INFO - [TRAIN] Epoch: 29/30 | Batch: 0/1345 (0.1%) | Loss: 1.0341 | Batch time: 0.06s
2025-03-05 00:30:33,474 - INFO - [TRAIN] Epoch: 29/30 | Batch: 134/1345 (10.0%) | Loss: 0.8981 | Batch time: 0.02s
2025-03-05 00:30:36,404 - INFO - [TRAIN] Epoch: 29/30 | Batch: 268/1345 (20.0%) | Loss: 0.5659 | Batch time: 0.02s
2025-03-05 00:30:39,329 - INFO - [TRAIN] Epoch: 29/30 | Batch: 402/1345 (30.0%) | Loss: 1.3745 | Batch time: 0.02s
2025-03-05 00:30:42,329 - INFO - [TRAIN] Epoch: 29/30 | Batch: 536/1345 (39.9%) | Loss: 1.0036 | Batch time: 0.02s
2025-03-05 00:30:45,244 - INFO - [TRAIN] Epoch: 29/30 | Batch: 670/1345 (49.9%) | Loss: 0.9343 | Batch time: 0.02s
2025-03-05 00:30:48,279 - INFO - [TRAIN] Epoch: 29/30 | Batch: 804/1345 (59.9%) | Loss: 0.7613 | Batch time: 0.02s
2025-03-05 00:30:51,338 - INFO - [TRAIN] Epoch: 29/30 | Batch: 938/1345 (69.8%) | Loss: 0.8752 | Batch time: 0.02s
2025-03-05 00:30:54,529 - INFO - [TRAIN] Epoch: 29/30 | Batch: 1072/1345 (79.8%) | Loss: 1.1485 | Batch time: 0.02s
2025-03-05 00:30:57,515 - INFO - [TRAIN] Epoch: 29/30 | Batch: 1206/1345 (89.7%) | Loss: 0.8471 | Batch time: 0.02s
2025-03-05 00:31:00,401 - INFO - [TRAIN] Epoch: 29/30 | Batch: 1340/1345 (99.7%) | Loss: 0.7415 | Batch time: 0.02s
2025-03-05 00:31:00,473 - INFO - [TRAIN] Epoch: 29/30 | Batch: 1344/1345 (100.0%) | Loss: 0.9590 | Batch time: 0.02s
2025-03-05 00:31:00,566 - INFO - [VAL] Epoch: 29/30 | Batch: 0/289 (0.3%) | Loss: 0.3646 | Batch time: 0.03s
2025-03-05 00:31:00,948 - INFO - [VAL] Epoch: 29/30 | Batch: 28/289 (10.0%) | Loss: 0.2331 | Batch time: 0.01s
2025-03-05 00:31:01,338 - INFO - [VAL] Epoch: 29/30 | Batch: 56/289 (19.7%) | Loss: 0.7406 | Batch time: 0.01s
2025-03-05 00:31:01,724 - INFO - [VAL] Epoch: 29/30 | Batch: 84/289 (29.4%) | Loss: 0.2526 | Batch time: 0.01s
2025-03-05 00:31:02,117 - INFO - [VAL] Epoch: 29/30 | Batch: 112/289 (39.1%) | Loss: 0.2586 | Batch time: 0.01s
2025-03-05 00:31:02,508 - INFO - [VAL] Epoch: 29/30 | Batch: 140/289 (48.8%) | Loss: 0.2901 | Batch time: 0.01s
2025-03-05 00:31:02,890 - INFO - [VAL] Epoch: 29/30 | Batch: 168/289 (58.5%) | Loss: 0.2379 | Batch time: 0.01s
2025-03-05 00:31:03,276 - INFO - [VAL] Epoch: 29/30 | Batch: 196/289 (68.2%) | Loss: 0.2762 | Batch time: 0.01s
2025-03-05 00:31:03,665 - INFO - [VAL] Epoch: 29/30 | Batch: 224/289 (77.9%) | Loss: 0.2627 | Batch time: 0.01s
2025-03-05 00:31:04,062 - INFO - [VAL] Epoch: 29/30 | Batch: 252/289 (87.5%) | Loss: 0.4331 | Batch time: 0.01s
2025-03-05 00:31:04,436 - INFO - [VAL] Epoch: 29/30 | Batch: 280/289 (97.2%) | Loss: 0.3604 | Batch time: 0.01s
2025-03-05 00:31:04,536 - INFO - [VAL] Epoch: 29/30 | Batch: 288/289 (100.0%) | Loss: 0.5046 | Batch time: 0.01s
2025-03-05 00:31:04,542 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:04,542 - INFO - Epoch 29/30 completed in 34.23s
2025-03-05 00:31:04,542 - INFO - Training   - Loss: 0.8318, Accuracy: 0.7557, F1: 0.7577
2025-03-05 00:31:04,542 - INFO - Validation - Loss: 0.3115, Accuracy: 0.9073, F1: 0.9081
2025-03-05 00:31:04,542 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:04,542 - INFO - Epoch 30/30
2025-03-05 00:31:04,542 - INFO - ----------------------------------------
2025-03-05 00:31:04,774 - INFO - [TRAIN] Epoch: 30/30 | Batch: 0/1345 (0.1%) | Loss: 0.8622 | Batch time: 0.04s
2025-03-05 00:31:07,621 - INFO - [TRAIN] Epoch: 30/30 | Batch: 134/1345 (10.0%) | Loss: 0.8013 | Batch time: 0.02s
2025-03-05 00:31:10,496 - INFO - [TRAIN] Epoch: 30/30 | Batch: 268/1345 (20.0%) | Loss: 0.8450 | Batch time: 0.02s
2025-03-05 00:31:13,386 - INFO - [TRAIN] Epoch: 30/30 | Batch: 402/1345 (30.0%) | Loss: 0.7639 | Batch time: 0.02s
2025-03-05 00:31:16,349 - INFO - [TRAIN] Epoch: 30/30 | Batch: 536/1345 (39.9%) | Loss: 0.7633 | Batch time: 0.02s
2025-03-05 00:31:19,337 - INFO - [TRAIN] Epoch: 30/30 | Batch: 670/1345 (49.9%) | Loss: 1.0270 | Batch time: 0.02s
2025-03-05 00:31:22,472 - INFO - [TRAIN] Epoch: 30/30 | Batch: 804/1345 (59.9%) | Loss: 0.8510 | Batch time: 0.02s
2025-03-05 00:31:25,406 - INFO - [TRAIN] Epoch: 30/30 | Batch: 938/1345 (69.8%) | Loss: 0.8689 | Batch time: 0.02s
2025-03-05 00:31:28,375 - INFO - [TRAIN] Epoch: 30/30 | Batch: 1072/1345 (79.8%) | Loss: 1.4931 | Batch time: 0.02s
2025-03-05 00:31:31,314 - INFO - [TRAIN] Epoch: 30/30 | Batch: 1206/1345 (89.7%) | Loss: 0.9812 | Batch time: 0.02s
2025-03-05 00:31:34,447 - INFO - [TRAIN] Epoch: 30/30 | Batch: 1340/1345 (99.7%) | Loss: 1.2130 | Batch time: 0.02s
2025-03-05 00:31:34,521 - INFO - [TRAIN] Epoch: 30/30 | Batch: 1344/1345 (100.0%) | Loss: 1.4408 | Batch time: 0.02s
2025-03-05 00:31:34,632 - INFO - [VAL] Epoch: 30/30 | Batch: 0/289 (0.3%) | Loss: 0.3524 | Batch time: 0.03s
2025-03-05 00:31:35,016 - INFO - [VAL] Epoch: 30/30 | Batch: 28/289 (10.0%) | Loss: 0.2240 | Batch time: 0.01s
2025-03-05 00:31:35,427 - INFO - [VAL] Epoch: 30/30 | Batch: 56/289 (19.7%) | Loss: 0.7068 | Batch time: 0.01s
2025-03-05 00:31:35,832 - INFO - [VAL] Epoch: 30/30 | Batch: 84/289 (29.4%) | Loss: 0.2314 | Batch time: 0.01s
2025-03-05 00:31:36,234 - INFO - [VAL] Epoch: 30/30 | Batch: 112/289 (39.1%) | Loss: 0.2555 | Batch time: 0.01s
2025-03-05 00:31:36,634 - INFO - [VAL] Epoch: 30/30 | Batch: 140/289 (48.8%) | Loss: 0.2773 | Batch time: 0.01s
2025-03-05 00:31:37,022 - INFO - [VAL] Epoch: 30/30 | Batch: 168/289 (58.5%) | Loss: 0.2313 | Batch time: 0.01s
2025-03-05 00:31:37,418 - INFO - [VAL] Epoch: 30/30 | Batch: 196/289 (68.2%) | Loss: 0.2412 | Batch time: 0.01s
2025-03-05 00:31:37,829 - INFO - [VAL] Epoch: 30/30 | Batch: 224/289 (77.9%) | Loss: 0.2599 | Batch time: 0.01s
2025-03-05 00:31:38,223 - INFO - [VAL] Epoch: 30/30 | Batch: 252/289 (87.5%) | Loss: 0.4340 | Batch time: 0.01s
2025-03-05 00:31:38,624 - INFO - [VAL] Epoch: 30/30 | Batch: 280/289 (97.2%) | Loss: 0.3375 | Batch time: 0.01s
2025-03-05 00:31:38,729 - INFO - [VAL] Epoch: 30/30 | Batch: 288/289 (100.0%) | Loss: 0.5148 | Batch time: 0.01s
2025-03-05 00:31:38,736 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:38,736 - INFO - Epoch 30/30 completed in 34.19s
2025-03-05 00:31:38,736 - INFO - Training   - Loss: 0.8328, Accuracy: 0.7554, F1: 0.7576
2025-03-05 00:31:38,736 - INFO - Validation - Loss: 0.3036, Accuracy: 0.9108, F1: 0.9117
2025-03-05 00:31:38,736 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:38,826 - INFO - Checkpoint saved: checkpoint_epoch_30.pth (Epoch 30)
2025-03-05 00:31:38,828 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:38,829 - INFO - Training completed in 0h 19m 34.08s
2025-03-05 00:31:38,829 - INFO - Best validation F1: 0.9135 (Epoch 26)
2025-03-05 00:31:38,829 - INFO - --------------------------------------------------------------------------------
2025-03-05 00:31:39,370 - INFO - Final model saved to models/mobilenet_v2_v3/models/mobilenet_v2_v1_final.pth
2025-03-05 00:31:39,385 - INFO - Model registered in models/model_registry.json
2025-03-05 00:31:39,385 - INFO - Generating visualizations...
2025-03-05 00:31:39,385 - INFO - Generating standard visualizations and GradCAM
2025-03-05 00:32:27,194 - INFO - t-SNE visualization saved to models/mobilenet_v2_v3/visualizations
2025-03-05 00:32:27,194 - INFO - Training and visualization finished!

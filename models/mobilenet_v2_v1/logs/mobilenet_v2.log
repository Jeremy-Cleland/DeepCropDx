2025-03-02 20:58:39,351 - INFO - Starting experiment: mobilenet_v2
2025-03-02 20:58:39,351 - INFO - Command line arguments: Namespace(data_dir='data/raw', output_dir='models/mobilenet_v2_v1', model='mobilenet', img_size=224, batch_size=32, num_workers=16, epochs=30, lr=0.001, weight_decay=0.0001, pretrained=True, freeze_backbone=True, no_cuda=False, no_mps=False, use_mps=True, use_amp=False, memory_efficient=True, cache_dataset=True, mps_graph=True, mps_fallback=True, pin_memory=True, optimize_for_m_series=True, patience=30, keep_top_k=3, version=None, find_lr=False, experiment_name='mobilenet_v2', resnet_version=50)
2025-03-02 20:58:39,351 - INFO - Processing dataset...
2025-03-02 20:58:39,442 - INFO - Class distribution:
2025-03-02 20:58:39,442 - INFO -   Tomato_healthy: 1591 images
2025-03-02 20:58:39,442 - INFO -   Potato___Early_blight: 1000 images
2025-03-02 20:58:39,442 - INFO -   Tomato__Tomato_YellowLeaf__Curl_Virus: 3208 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Early_blight: 1000 images
2025-03-02 20:58:39,442 - INFO -   Tomato__Target_Spot: 1404 images
2025-03-02 20:58:39,442 - INFO -   Potato___Late_blight: 1000 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Leaf_Mold: 952 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Spider_mites_Two_spotted_spider_mite: 1676 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Septoria_leaf_spot: 1771 images
2025-03-02 20:58:39,442 - INFO -   Tomato__Tomato_mosaic_virus: 373 images
2025-03-02 20:58:39,442 - INFO -   Pepper__bell___Bacterial_spot: 997 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Bacterial_spot: 2127 images
2025-03-02 20:58:39,442 - INFO -   Tomato_Late_blight: 1909 images
2025-03-02 20:58:39,442 - INFO -   Pepper__bell___healthy: 1478 images
2025-03-02 20:58:39,442 - INFO -   Potato___healthy: 152 images
2025-03-02 20:58:39,442 - INFO - Creating model: mobilenet with 15 classes
2025-03-02 20:58:39,524 - INFO - Model architecture:
MobileNetV2(
  (features): Sequential(
    (0): Conv2dNormActivation(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (1): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (3): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)
          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (10): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (11): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (12): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (13): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (14): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (15): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (16): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (17): InvertedResidual(
      (conv): Sequential(
        (0): Conv2dNormActivation(
          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (1): Conv2dNormActivation(
          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)
          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (18): Conv2dNormActivation(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
  )
  (classifier): Sequential(
    (0): Dropout(p=0.2, inplace=True)
    (1): Linear(in_features=1280, out_features=15, bias=True)
  )
)
2025-03-02 20:58:39,536 - INFO - Using class weights: [0.5015516  0.7979687  0.24874336 0.7979687  0.5683538  0.7979687
 0.8382024  0.47611496 0.4505752  2.1393263  0.8003698  0.3751616
 0.4180035  0.5398976  5.249794  ]
2025-03-02 20:58:39,536 - INFO - Training only 2 parameters (classifier)
2025-03-02 20:58:39,537 - INFO - Starting training for 30 epochs
2025-03-02 20:58:39,537 - INFO - Using Automatic Mixed Precision: False
2025-03-02 20:58:39,537 - INFO - Early stopping patience: 30
2025-03-02 20:58:39,537 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:58:39,537 - INFO - Starting training: mobilenet_v2
2025-03-02 20:58:39,537 - INFO - Total epochs: 30
2025-03-02 20:58:39,537 - INFO - Training batches per epoch: 452
2025-03-02 20:58:39,537 - INFO - Validation batches per epoch: 97
2025-03-02 20:58:39,537 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:58:39,537 - INFO - Training model: mobilenet_v2_v1
2025-03-02 20:58:39,537 - INFO - Epoch 1/30
2025-03-02 20:58:39,537 - INFO - ----------------------------------------
2025-03-02 20:59:07,104 - INFO - [TRAIN] Epoch: 1/30 | Batch: 0/452 (0.2%) | Loss: 2.7866 | Batch time: 0.36s
2025-03-02 20:59:07,929 - INFO - [TRAIN] Epoch: 1/30 | Batch: 45/452 (10.2%) | Loss: 2.2705 | Batch time: 0.02s
2025-03-02 20:59:08,794 - INFO - [TRAIN] Epoch: 1/30 | Batch: 90/452 (20.1%) | Loss: 1.4044 | Batch time: 0.02s
2025-03-02 20:59:09,718 - INFO - [TRAIN] Epoch: 1/30 | Batch: 135/452 (30.1%) | Loss: 1.6775 | Batch time: 0.02s
2025-03-02 20:59:10,686 - INFO - [TRAIN] Epoch: 1/30 | Batch: 180/452 (40.0%) | Loss: 1.6206 | Batch time: 0.02s
2025-03-02 20:59:11,993 - INFO - [TRAIN] Epoch: 1/30 | Batch: 225/452 (50.0%) | Loss: 1.1872 | Batch time: 0.02s
2025-03-02 20:59:13,087 - INFO - [TRAIN] Epoch: 1/30 | Batch: 270/452 (60.0%) | Loss: 1.1546 | Batch time: 0.03s
2025-03-02 20:59:14,319 - INFO - [TRAIN] Epoch: 1/30 | Batch: 315/452 (69.9%) | Loss: 1.1461 | Batch time: 0.03s
2025-03-02 20:59:15,486 - INFO - [TRAIN] Epoch: 1/30 | Batch: 360/452 (79.9%) | Loss: 1.0753 | Batch time: 0.02s
2025-03-02 20:59:16,523 - INFO - [TRAIN] Epoch: 1/30 | Batch: 405/452 (89.8%) | Loss: 0.9958 | Batch time: 0.02s
2025-03-02 20:59:17,494 - INFO - [TRAIN] Epoch: 1/30 | Batch: 450/452 (99.8%) | Loss: 1.2029 | Batch time: 0.02s
2025-03-02 20:59:17,695 - INFO - [TRAIN] Epoch: 1/30 | Batch: 451/452 (100.0%) | Loss: 1.4275 | Batch time: 0.20s
2025-03-02 20:59:45,750 - INFO - [VAL] Epoch: 1/30 | Batch: 0/97 (1.0%) | Loss: 0.6497 | Batch time: 0.09s
2025-03-02 20:59:45,872 - INFO - [VAL] Epoch: 1/30 | Batch: 9/97 (10.3%) | Loss: 0.8172 | Batch time: 0.01s
2025-03-02 20:59:45,992 - INFO - [VAL] Epoch: 1/30 | Batch: 18/97 (19.6%) | Loss: 0.5559 | Batch time: 0.01s
2025-03-02 20:59:46,111 - INFO - [VAL] Epoch: 1/30 | Batch: 27/97 (28.9%) | Loss: 0.8307 | Batch time: 0.01s
2025-03-02 20:59:46,232 - INFO - [VAL] Epoch: 1/30 | Batch: 36/97 (38.1%) | Loss: 0.7543 | Batch time: 0.01s
2025-03-02 20:59:46,354 - INFO - [VAL] Epoch: 1/30 | Batch: 45/97 (47.4%) | Loss: 0.5626 | Batch time: 0.01s
2025-03-02 20:59:46,475 - INFO - [VAL] Epoch: 1/30 | Batch: 54/97 (56.7%) | Loss: 0.9315 | Batch time: 0.01s
2025-03-02 20:59:46,597 - INFO - [VAL] Epoch: 1/30 | Batch: 63/97 (66.0%) | Loss: 0.8443 | Batch time: 0.01s
2025-03-02 20:59:46,715 - INFO - [VAL] Epoch: 1/30 | Batch: 72/97 (75.3%) | Loss: 0.7846 | Batch time: 0.01s
2025-03-02 20:59:46,832 - INFO - [VAL] Epoch: 1/30 | Batch: 81/97 (84.5%) | Loss: 0.7533 | Batch time: 0.01s
2025-03-02 20:59:46,949 - INFO - [VAL] Epoch: 1/30 | Batch: 90/97 (93.8%) | Loss: 1.0269 | Batch time: 0.01s
2025-03-02 20:59:47,148 - INFO - [VAL] Epoch: 1/30 | Batch: 96/97 (100.0%) | Loss: 0.7967 | Batch time: 0.13s
2025-03-02 20:59:47,265 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 1)
2025-03-02 20:59:47,265 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:59:47,265 - INFO - Epoch 1/30 completed in 67.73s
2025-03-02 20:59:47,265 - INFO - Training   - Loss: 1.4638, Accuracy: 0.5739, F1: 0.5814
2025-03-02 20:59:47,265 - INFO - Validation - Loss: 0.7765, Accuracy: 0.7926, F1: 0.7949
2025-03-02 20:59:47,265 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:59:47,265 - INFO - Epoch 2/30
2025-03-02 20:59:47,265 - INFO - ----------------------------------------
2025-03-02 20:59:47,625 - INFO - [TRAIN] Epoch: 2/30 | Batch: 0/452 (0.2%) | Loss: 1.0277 | Batch time: 0.17s
2025-03-02 20:59:48,546 - INFO - [TRAIN] Epoch: 2/30 | Batch: 45/452 (10.2%) | Loss: 1.2949 | Batch time: 0.02s
2025-03-02 20:59:49,401 - INFO - [TRAIN] Epoch: 2/30 | Batch: 90/452 (20.1%) | Loss: 1.0108 | Batch time: 0.02s
2025-03-02 20:59:50,259 - INFO - [TRAIN] Epoch: 2/30 | Batch: 135/452 (30.1%) | Loss: 0.9862 | Batch time: 0.02s
2025-03-02 20:59:51,192 - INFO - [TRAIN] Epoch: 2/30 | Batch: 180/452 (40.0%) | Loss: 1.1751 | Batch time: 0.02s
2025-03-02 20:59:52,059 - INFO - [TRAIN] Epoch: 2/30 | Batch: 225/452 (50.0%) | Loss: 1.1368 | Batch time: 0.02s
2025-03-02 20:59:52,918 - INFO - [TRAIN] Epoch: 2/30 | Batch: 270/452 (60.0%) | Loss: 0.6101 | Batch time: 0.02s
2025-03-02 20:59:53,771 - INFO - [TRAIN] Epoch: 2/30 | Batch: 315/452 (69.9%) | Loss: 0.9431 | Batch time: 0.02s
2025-03-02 20:59:54,649 - INFO - [TRAIN] Epoch: 2/30 | Batch: 360/452 (79.9%) | Loss: 0.8375 | Batch time: 0.02s
2025-03-02 20:59:55,614 - INFO - [TRAIN] Epoch: 2/30 | Batch: 405/452 (89.8%) | Loss: 1.0876 | Batch time: 0.02s
2025-03-02 20:59:56,449 - INFO - [TRAIN] Epoch: 2/30 | Batch: 450/452 (99.8%) | Loss: 0.7746 | Batch time: 0.02s
2025-03-02 20:59:56,465 - INFO - [TRAIN] Epoch: 2/30 | Batch: 451/452 (100.0%) | Loss: 1.1294 | Batch time: 0.02s
2025-03-02 20:59:56,555 - INFO - [VAL] Epoch: 2/30 | Batch: 0/97 (1.0%) | Loss: 0.4624 | Batch time: 0.02s
2025-03-02 20:59:56,702 - INFO - [VAL] Epoch: 2/30 | Batch: 9/97 (10.3%) | Loss: 0.5715 | Batch time: 0.01s
2025-03-02 20:59:56,827 - INFO - [VAL] Epoch: 2/30 | Batch: 18/97 (19.6%) | Loss: 0.3581 | Batch time: 0.01s
2025-03-02 20:59:56,952 - INFO - [VAL] Epoch: 2/30 | Batch: 27/97 (28.9%) | Loss: 0.5481 | Batch time: 0.01s
2025-03-02 20:59:57,078 - INFO - [VAL] Epoch: 2/30 | Batch: 36/97 (38.1%) | Loss: 0.5323 | Batch time: 0.01s
2025-03-02 20:59:57,201 - INFO - [VAL] Epoch: 2/30 | Batch: 45/97 (47.4%) | Loss: 0.4153 | Batch time: 0.01s
2025-03-02 20:59:57,325 - INFO - [VAL] Epoch: 2/30 | Batch: 54/97 (56.7%) | Loss: 0.6206 | Batch time: 0.01s
2025-03-02 20:59:57,448 - INFO - [VAL] Epoch: 2/30 | Batch: 63/97 (66.0%) | Loss: 0.8647 | Batch time: 0.01s
2025-03-02 20:59:57,568 - INFO - [VAL] Epoch: 2/30 | Batch: 72/97 (75.3%) | Loss: 0.5828 | Batch time: 0.01s
2025-03-02 20:59:57,688 - INFO - [VAL] Epoch: 2/30 | Batch: 81/97 (84.5%) | Loss: 0.3984 | Batch time: 0.01s
2025-03-02 20:59:57,808 - INFO - [VAL] Epoch: 2/30 | Batch: 90/97 (93.8%) | Loss: 0.6283 | Batch time: 0.01s
2025-03-02 20:59:57,883 - INFO - [VAL] Epoch: 2/30 | Batch: 96/97 (100.0%) | Loss: 0.6571 | Batch time: 0.01s
2025-03-02 20:59:57,979 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 2)
2025-03-02 20:59:57,979 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:59:57,979 - INFO - Epoch 2/30 completed in 10.71s
2025-03-02 20:59:57,979 - INFO - Training   - Loss: 1.0660, Accuracy: 0.6648, F1: 0.6692
2025-03-02 20:59:57,979 - INFO - Validation - Loss: 0.6226, Accuracy: 0.8201, F1: 0.8208
2025-03-02 20:59:57,979 - INFO - Validation F1 improved from 0.7949 to 0.8208
2025-03-02 20:59:57,979 - INFO - --------------------------------------------------------------------------------
2025-03-02 20:59:57,979 - INFO - Epoch 3/30
2025-03-02 20:59:57,979 - INFO - ----------------------------------------
2025-03-02 20:59:58,203 - INFO - [TRAIN] Epoch: 3/30 | Batch: 0/452 (0.2%) | Loss: 0.6864 | Batch time: 0.03s
2025-03-02 20:59:59,172 - INFO - [TRAIN] Epoch: 3/30 | Batch: 45/452 (10.2%) | Loss: 1.0542 | Batch time: 0.02s
2025-03-02 21:00:00,030 - INFO - [TRAIN] Epoch: 3/30 | Batch: 90/452 (20.1%) | Loss: 1.2799 | Batch time: 0.02s
2025-03-02 21:00:00,897 - INFO - [TRAIN] Epoch: 3/30 | Batch: 135/452 (30.1%) | Loss: 0.9821 | Batch time: 0.02s
2025-03-02 21:00:01,777 - INFO - [TRAIN] Epoch: 3/30 | Batch: 180/452 (40.0%) | Loss: 1.1441 | Batch time: 0.02s
2025-03-02 21:00:02,643 - INFO - [TRAIN] Epoch: 3/30 | Batch: 225/452 (50.0%) | Loss: 0.7718 | Batch time: 0.02s
2025-03-02 21:00:03,515 - INFO - [TRAIN] Epoch: 3/30 | Batch: 270/452 (60.0%) | Loss: 0.7075 | Batch time: 0.02s
2025-03-02 21:00:04,396 - INFO - [TRAIN] Epoch: 3/30 | Batch: 315/452 (69.9%) | Loss: 1.1149 | Batch time: 0.02s
2025-03-02 21:00:05,296 - INFO - [TRAIN] Epoch: 3/30 | Batch: 360/452 (79.9%) | Loss: 1.4522 | Batch time: 0.02s
2025-03-02 21:00:06,190 - INFO - [TRAIN] Epoch: 3/30 | Batch: 405/452 (89.8%) | Loss: 0.9127 | Batch time: 0.02s
2025-03-02 21:00:07,048 - INFO - [TRAIN] Epoch: 3/30 | Batch: 450/452 (99.8%) | Loss: 1.9212 | Batch time: 0.02s
2025-03-02 21:00:07,060 - INFO - [TRAIN] Epoch: 3/30 | Batch: 451/452 (100.0%) | Loss: 1.7152 | Batch time: 0.01s
2025-03-02 21:00:07,143 - INFO - [VAL] Epoch: 3/30 | Batch: 0/97 (1.0%) | Loss: 0.3782 | Batch time: 0.02s
2025-03-02 21:00:07,276 - INFO - [VAL] Epoch: 3/30 | Batch: 9/97 (10.3%) | Loss: 0.5385 | Batch time: 0.01s
2025-03-02 21:00:07,401 - INFO - [VAL] Epoch: 3/30 | Batch: 18/97 (19.6%) | Loss: 0.3721 | Batch time: 0.01s
2025-03-02 21:00:07,523 - INFO - [VAL] Epoch: 3/30 | Batch: 27/97 (28.9%) | Loss: 0.4880 | Batch time: 0.01s
2025-03-02 21:00:07,650 - INFO - [VAL] Epoch: 3/30 | Batch: 36/97 (38.1%) | Loss: 0.5632 | Batch time: 0.01s
2025-03-02 21:00:07,772 - INFO - [VAL] Epoch: 3/30 | Batch: 45/97 (47.4%) | Loss: 0.3748 | Batch time: 0.01s
2025-03-02 21:00:07,900 - INFO - [VAL] Epoch: 3/30 | Batch: 54/97 (56.7%) | Loss: 0.6835 | Batch time: 0.01s
2025-03-02 21:00:08,022 - INFO - [VAL] Epoch: 3/30 | Batch: 63/97 (66.0%) | Loss: 0.3571 | Batch time: 0.01s
2025-03-02 21:00:08,142 - INFO - [VAL] Epoch: 3/30 | Batch: 72/97 (75.3%) | Loss: 0.6358 | Batch time: 0.01s
2025-03-02 21:00:08,262 - INFO - [VAL] Epoch: 3/30 | Batch: 81/97 (84.5%) | Loss: 0.3608 | Batch time: 0.01s
2025-03-02 21:00:08,382 - INFO - [VAL] Epoch: 3/30 | Batch: 90/97 (93.8%) | Loss: 0.4237 | Batch time: 0.01s
2025-03-02 21:00:08,460 - INFO - [VAL] Epoch: 3/30 | Batch: 96/97 (100.0%) | Loss: 0.6774 | Batch time: 0.01s
2025-03-02 21:00:08,568 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 3)
2025-03-02 21:00:08,568 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:08,568 - INFO - Epoch 3/30 completed in 10.59s
2025-03-02 21:00:08,568 - INFO - Training   - Loss: 0.9841, Accuracy: 0.6857, F1: 0.6897
2025-03-02 21:00:08,568 - INFO - Validation - Loss: 0.5421, Accuracy: 0.8249, F1: 0.8274
2025-03-02 21:00:08,568 - INFO - Validation F1 improved from 0.8208 to 0.8274
2025-03-02 21:00:08,569 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:08,569 - INFO - Epoch 4/30
2025-03-02 21:00:08,569 - INFO - ----------------------------------------
2025-03-02 21:00:08,775 - INFO - [TRAIN] Epoch: 4/30 | Batch: 0/452 (0.2%) | Loss: 0.7085 | Batch time: 0.03s
2025-03-02 21:00:09,725 - INFO - [TRAIN] Epoch: 4/30 | Batch: 45/452 (10.2%) | Loss: 0.9331 | Batch time: 0.02s
2025-03-02 21:00:10,613 - INFO - [TRAIN] Epoch: 4/30 | Batch: 90/452 (20.1%) | Loss: 0.8045 | Batch time: 0.02s
2025-03-02 21:00:11,506 - INFO - [TRAIN] Epoch: 4/30 | Batch: 135/452 (30.1%) | Loss: 0.6150 | Batch time: 0.02s
2025-03-02 21:00:12,388 - INFO - [TRAIN] Epoch: 4/30 | Batch: 180/452 (40.0%) | Loss: 0.8075 | Batch time: 0.02s
2025-03-02 21:00:13,280 - INFO - [TRAIN] Epoch: 4/30 | Batch: 225/452 (50.0%) | Loss: 0.7529 | Batch time: 0.02s
2025-03-02 21:00:14,181 - INFO - [TRAIN] Epoch: 4/30 | Batch: 270/452 (60.0%) | Loss: 0.8662 | Batch time: 0.02s
2025-03-02 21:00:15,114 - INFO - [TRAIN] Epoch: 4/30 | Batch: 315/452 (69.9%) | Loss: 1.1428 | Batch time: 0.02s
2025-03-02 21:00:16,017 - INFO - [TRAIN] Epoch: 4/30 | Batch: 360/452 (79.9%) | Loss: 0.6595 | Batch time: 0.02s
2025-03-02 21:00:16,921 - INFO - [TRAIN] Epoch: 4/30 | Batch: 405/452 (89.8%) | Loss: 0.4695 | Batch time: 0.02s
2025-03-02 21:00:17,781 - INFO - [TRAIN] Epoch: 4/30 | Batch: 450/452 (99.8%) | Loss: 0.9540 | Batch time: 0.02s
2025-03-02 21:00:17,793 - INFO - [TRAIN] Epoch: 4/30 | Batch: 451/452 (100.0%) | Loss: 0.8292 | Batch time: 0.01s
2025-03-02 21:00:17,874 - INFO - [VAL] Epoch: 4/30 | Batch: 0/97 (1.0%) | Loss: 0.3359 | Batch time: 0.02s
2025-03-02 21:00:18,007 - INFO - [VAL] Epoch: 4/30 | Batch: 9/97 (10.3%) | Loss: 0.4178 | Batch time: 0.01s
2025-03-02 21:00:18,129 - INFO - [VAL] Epoch: 4/30 | Batch: 18/97 (19.6%) | Loss: 0.3328 | Batch time: 0.01s
2025-03-02 21:00:18,252 - INFO - [VAL] Epoch: 4/30 | Batch: 27/97 (28.9%) | Loss: 0.4594 | Batch time: 0.01s
2025-03-02 21:00:18,375 - INFO - [VAL] Epoch: 4/30 | Batch: 36/97 (38.1%) | Loss: 0.5007 | Batch time: 0.01s
2025-03-02 21:00:18,499 - INFO - [VAL] Epoch: 4/30 | Batch: 45/97 (47.4%) | Loss: 0.4240 | Batch time: 0.01s
2025-03-02 21:00:18,622 - INFO - [VAL] Epoch: 4/30 | Batch: 54/97 (56.7%) | Loss: 0.5272 | Batch time: 0.01s
2025-03-02 21:00:18,750 - INFO - [VAL] Epoch: 4/30 | Batch: 63/97 (66.0%) | Loss: 0.3596 | Batch time: 0.01s
2025-03-02 21:00:18,872 - INFO - [VAL] Epoch: 4/30 | Batch: 72/97 (75.3%) | Loss: 0.5404 | Batch time: 0.01s
2025-03-02 21:00:18,993 - INFO - [VAL] Epoch: 4/30 | Batch: 81/97 (84.5%) | Loss: 0.3553 | Batch time: 0.01s
2025-03-02 21:00:19,112 - INFO - [VAL] Epoch: 4/30 | Batch: 90/97 (93.8%) | Loss: 0.3639 | Batch time: 0.01s
2025-03-02 21:00:19,189 - INFO - [VAL] Epoch: 4/30 | Batch: 96/97 (100.0%) | Loss: 0.8675 | Batch time: 0.01s
2025-03-02 21:00:19,192 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:19,192 - INFO - Epoch 4/30 completed in 10.62s
2025-03-02 21:00:19,192 - INFO - Training   - Loss: 0.9581, Accuracy: 0.6953, F1: 0.6995
2025-03-02 21:00:19,193 - INFO - Validation - Loss: 0.5730, Accuracy: 0.8136, F1: 0.8186
2025-03-02 21:00:19,193 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:19,193 - INFO - Epoch 5/30
2025-03-02 21:00:19,193 - INFO - ----------------------------------------
2025-03-02 21:00:19,411 - INFO - [TRAIN] Epoch: 5/30 | Batch: 0/452 (0.2%) | Loss: 0.9770 | Batch time: 0.03s
2025-03-02 21:00:20,336 - INFO - [TRAIN] Epoch: 5/30 | Batch: 45/452 (10.2%) | Loss: 0.9566 | Batch time: 0.02s
2025-03-02 21:00:21,217 - INFO - [TRAIN] Epoch: 5/30 | Batch: 90/452 (20.1%) | Loss: 1.5944 | Batch time: 0.02s
2025-03-02 21:00:22,119 - INFO - [TRAIN] Epoch: 5/30 | Batch: 135/452 (30.1%) | Loss: 0.8878 | Batch time: 0.02s
2025-03-02 21:00:23,063 - INFO - [TRAIN] Epoch: 5/30 | Batch: 180/452 (40.0%) | Loss: 0.9897 | Batch time: 0.02s
2025-03-02 21:00:23,982 - INFO - [TRAIN] Epoch: 5/30 | Batch: 225/452 (50.0%) | Loss: 0.7245 | Batch time: 0.02s
2025-03-02 21:00:24,903 - INFO - [TRAIN] Epoch: 5/30 | Batch: 270/452 (60.0%) | Loss: 0.8408 | Batch time: 0.02s
2025-03-02 21:00:25,815 - INFO - [TRAIN] Epoch: 5/30 | Batch: 315/452 (69.9%) | Loss: 0.5732 | Batch time: 0.02s
2025-03-02 21:00:26,723 - INFO - [TRAIN] Epoch: 5/30 | Batch: 360/452 (79.9%) | Loss: 0.8252 | Batch time: 0.02s
2025-03-02 21:00:27,632 - INFO - [TRAIN] Epoch: 5/30 | Batch: 405/452 (89.8%) | Loss: 1.0940 | Batch time: 0.02s
2025-03-02 21:00:28,494 - INFO - [TRAIN] Epoch: 5/30 | Batch: 450/452 (99.8%) | Loss: 0.9592 | Batch time: 0.02s
2025-03-02 21:00:28,506 - INFO - [TRAIN] Epoch: 5/30 | Batch: 451/452 (100.0%) | Loss: 0.8421 | Batch time: 0.01s
2025-03-02 21:00:28,584 - INFO - [VAL] Epoch: 5/30 | Batch: 0/97 (1.0%) | Loss: 0.4094 | Batch time: 0.02s
2025-03-02 21:00:28,718 - INFO - [VAL] Epoch: 5/30 | Batch: 9/97 (10.3%) | Loss: 0.7298 | Batch time: 0.01s
2025-03-02 21:00:28,843 - INFO - [VAL] Epoch: 5/30 | Batch: 18/97 (19.6%) | Loss: 0.2637 | Batch time: 0.01s
2025-03-02 21:00:28,965 - INFO - [VAL] Epoch: 5/30 | Batch: 27/97 (28.9%) | Loss: 0.4373 | Batch time: 0.01s
2025-03-02 21:00:29,087 - INFO - [VAL] Epoch: 5/30 | Batch: 36/97 (38.1%) | Loss: 0.5753 | Batch time: 0.01s
2025-03-02 21:00:29,210 - INFO - [VAL] Epoch: 5/30 | Batch: 45/97 (47.4%) | Loss: 0.4774 | Batch time: 0.01s
2025-03-02 21:00:29,335 - INFO - [VAL] Epoch: 5/30 | Batch: 54/97 (56.7%) | Loss: 0.5509 | Batch time: 0.01s
2025-03-02 21:00:29,458 - INFO - [VAL] Epoch: 5/30 | Batch: 63/97 (66.0%) | Loss: 0.3954 | Batch time: 0.01s
2025-03-02 21:00:29,580 - INFO - [VAL] Epoch: 5/30 | Batch: 72/97 (75.3%) | Loss: 0.5418 | Batch time: 0.01s
2025-03-02 21:00:29,701 - INFO - [VAL] Epoch: 5/30 | Batch: 81/97 (84.5%) | Loss: 0.4891 | Batch time: 0.01s
2025-03-02 21:00:29,822 - INFO - [VAL] Epoch: 5/30 | Batch: 90/97 (93.8%) | Loss: 0.6485 | Batch time: 0.01s
2025-03-02 21:00:29,910 - INFO - [VAL] Epoch: 5/30 | Batch: 96/97 (100.0%) | Loss: 0.6919 | Batch time: 0.01s
2025-03-02 21:00:29,914 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:29,914 - INFO - Epoch 5/30 completed in 10.72s
2025-03-02 21:00:29,914 - INFO - Training   - Loss: 0.9714, Accuracy: 0.6886, F1: 0.6933
2025-03-02 21:00:29,914 - INFO - Validation - Loss: 0.5573, Accuracy: 0.8278, F1: 0.8254
2025-03-02 21:00:29,914 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:29,976 - INFO - Checkpoint saved: checkpoint_epoch_5.pth (Epoch 5)
2025-03-02 21:00:29,976 - INFO - Epoch 6/30
2025-03-02 21:00:29,976 - INFO - ----------------------------------------
2025-03-02 21:00:30,193 - INFO - [TRAIN] Epoch: 6/30 | Batch: 0/452 (0.2%) | Loss: 0.9838 | Batch time: 0.03s
2025-03-02 21:00:31,197 - INFO - [TRAIN] Epoch: 6/30 | Batch: 45/452 (10.2%) | Loss: 1.3554 | Batch time: 0.02s
2025-03-02 21:00:32,112 - INFO - [TRAIN] Epoch: 6/30 | Batch: 90/452 (20.1%) | Loss: 0.9886 | Batch time: 0.02s
2025-03-02 21:00:33,013 - INFO - [TRAIN] Epoch: 6/30 | Batch: 135/452 (30.1%) | Loss: 0.9460 | Batch time: 0.02s
2025-03-02 21:00:33,989 - INFO - [TRAIN] Epoch: 6/30 | Batch: 180/452 (40.0%) | Loss: 1.3376 | Batch time: 0.02s
2025-03-02 21:00:34,963 - INFO - [TRAIN] Epoch: 6/30 | Batch: 225/452 (50.0%) | Loss: 0.9468 | Batch time: 0.03s
2025-03-02 21:00:36,080 - INFO - [TRAIN] Epoch: 6/30 | Batch: 270/452 (60.0%) | Loss: 1.2757 | Batch time: 0.02s
2025-03-02 21:00:37,038 - INFO - [TRAIN] Epoch: 6/30 | Batch: 315/452 (69.9%) | Loss: 1.0069 | Batch time: 0.02s
2025-03-02 21:00:38,048 - INFO - [TRAIN] Epoch: 6/30 | Batch: 360/452 (79.9%) | Loss: 0.9717 | Batch time: 0.02s
2025-03-02 21:00:39,013 - INFO - [TRAIN] Epoch: 6/30 | Batch: 405/452 (89.8%) | Loss: 0.8969 | Batch time: 0.02s
2025-03-02 21:00:39,891 - INFO - [TRAIN] Epoch: 6/30 | Batch: 450/452 (99.8%) | Loss: 0.8716 | Batch time: 0.02s
2025-03-02 21:00:39,903 - INFO - [TRAIN] Epoch: 6/30 | Batch: 451/452 (100.0%) | Loss: 0.9399 | Batch time: 0.01s
2025-03-02 21:00:39,983 - INFO - [VAL] Epoch: 6/30 | Batch: 0/97 (1.0%) | Loss: 0.5675 | Batch time: 0.02s
2025-03-02 21:00:40,116 - INFO - [VAL] Epoch: 6/30 | Batch: 9/97 (10.3%) | Loss: 0.9811 | Batch time: 0.01s
2025-03-02 21:00:40,238 - INFO - [VAL] Epoch: 6/30 | Batch: 18/97 (19.6%) | Loss: 0.3416 | Batch time: 0.01s
2025-03-02 21:00:40,362 - INFO - [VAL] Epoch: 6/30 | Batch: 27/97 (28.9%) | Loss: 0.7288 | Batch time: 0.01s
2025-03-02 21:00:40,485 - INFO - [VAL] Epoch: 6/30 | Batch: 36/97 (38.1%) | Loss: 0.6261 | Batch time: 0.01s
2025-03-02 21:00:40,608 - INFO - [VAL] Epoch: 6/30 | Batch: 45/97 (47.4%) | Loss: 0.3708 | Batch time: 0.01s
2025-03-02 21:00:40,731 - INFO - [VAL] Epoch: 6/30 | Batch: 54/97 (56.7%) | Loss: 0.9178 | Batch time: 0.01s
2025-03-02 21:00:40,855 - INFO - [VAL] Epoch: 6/30 | Batch: 63/97 (66.0%) | Loss: 0.3768 | Batch time: 0.01s
2025-03-02 21:00:40,978 - INFO - [VAL] Epoch: 6/30 | Batch: 72/97 (75.3%) | Loss: 0.6362 | Batch time: 0.01s
2025-03-02 21:00:41,100 - INFO - [VAL] Epoch: 6/30 | Batch: 81/97 (84.5%) | Loss: 0.6286 | Batch time: 0.01s
2025-03-02 21:00:41,223 - INFO - [VAL] Epoch: 6/30 | Batch: 90/97 (93.8%) | Loss: 0.8360 | Batch time: 0.01s
2025-03-02 21:00:41,302 - INFO - [VAL] Epoch: 6/30 | Batch: 96/97 (100.0%) | Loss: 0.6565 | Batch time: 0.01s
2025-03-02 21:00:41,306 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:41,306 - INFO - Epoch 6/30 completed in 11.33s
2025-03-02 21:00:41,306 - INFO - Training   - Loss: 0.9432, Accuracy: 0.6983, F1: 0.7027
2025-03-02 21:00:41,306 - INFO - Validation - Loss: 0.6234, Accuracy: 0.8123, F1: 0.8142
2025-03-02 21:00:41,306 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:41,306 - INFO - Epoch 7/30
2025-03-02 21:00:41,306 - INFO - ----------------------------------------
2025-03-02 21:00:41,518 - INFO - [TRAIN] Epoch: 7/30 | Batch: 0/452 (0.2%) | Loss: 0.9856 | Batch time: 0.04s
2025-03-02 21:00:42,546 - INFO - [TRAIN] Epoch: 7/30 | Batch: 45/452 (10.2%) | Loss: 0.7396 | Batch time: 0.02s
2025-03-02 21:00:43,422 - INFO - [TRAIN] Epoch: 7/30 | Batch: 90/452 (20.1%) | Loss: 0.8457 | Batch time: 0.02s
2025-03-02 21:00:44,303 - INFO - [TRAIN] Epoch: 7/30 | Batch: 135/452 (30.1%) | Loss: 0.6260 | Batch time: 0.02s
2025-03-02 21:00:45,232 - INFO - [TRAIN] Epoch: 7/30 | Batch: 180/452 (40.0%) | Loss: 1.2455 | Batch time: 0.02s
2025-03-02 21:00:46,142 - INFO - [TRAIN] Epoch: 7/30 | Batch: 225/452 (50.0%) | Loss: 1.4716 | Batch time: 0.02s
2025-03-02 21:00:47,090 - INFO - [TRAIN] Epoch: 7/30 | Batch: 270/452 (60.0%) | Loss: 0.6344 | Batch time: 0.02s
2025-03-02 21:00:48,054 - INFO - [TRAIN] Epoch: 7/30 | Batch: 315/452 (69.9%) | Loss: 0.8465 | Batch time: 0.02s
2025-03-02 21:00:49,021 - INFO - [TRAIN] Epoch: 7/30 | Batch: 360/452 (79.9%) | Loss: 0.5718 | Batch time: 0.02s
2025-03-02 21:00:49,996 - INFO - [TRAIN] Epoch: 7/30 | Batch: 405/452 (89.8%) | Loss: 0.6915 | Batch time: 0.02s
2025-03-02 21:00:50,860 - INFO - [TRAIN] Epoch: 7/30 | Batch: 450/452 (99.8%) | Loss: 1.0837 | Batch time: 0.02s
2025-03-02 21:00:50,872 - INFO - [TRAIN] Epoch: 7/30 | Batch: 451/452 (100.0%) | Loss: 1.3417 | Batch time: 0.01s
2025-03-02 21:00:50,957 - INFO - [VAL] Epoch: 7/30 | Batch: 0/97 (1.0%) | Loss: 0.2887 | Batch time: 0.02s
2025-03-02 21:00:51,098 - INFO - [VAL] Epoch: 7/30 | Batch: 9/97 (10.3%) | Loss: 0.5974 | Batch time: 0.01s
2025-03-02 21:00:51,225 - INFO - [VAL] Epoch: 7/30 | Batch: 18/97 (19.6%) | Loss: 0.2708 | Batch time: 0.01s
2025-03-02 21:00:51,349 - INFO - [VAL] Epoch: 7/30 | Batch: 27/97 (28.9%) | Loss: 0.4299 | Batch time: 0.01s
2025-03-02 21:00:51,473 - INFO - [VAL] Epoch: 7/30 | Batch: 36/97 (38.1%) | Loss: 0.3884 | Batch time: 0.01s
2025-03-02 21:00:51,598 - INFO - [VAL] Epoch: 7/30 | Batch: 45/97 (47.4%) | Loss: 0.4032 | Batch time: 0.01s
2025-03-02 21:00:51,724 - INFO - [VAL] Epoch: 7/30 | Batch: 54/97 (56.7%) | Loss: 0.5961 | Batch time: 0.01s
2025-03-02 21:00:51,850 - INFO - [VAL] Epoch: 7/30 | Batch: 63/97 (66.0%) | Loss: 0.3569 | Batch time: 0.01s
2025-03-02 21:00:51,975 - INFO - [VAL] Epoch: 7/30 | Batch: 72/97 (75.3%) | Loss: 0.5023 | Batch time: 0.01s
2025-03-02 21:00:52,098 - INFO - [VAL] Epoch: 7/30 | Batch: 81/97 (84.5%) | Loss: 0.3655 | Batch time: 0.01s
2025-03-02 21:00:52,221 - INFO - [VAL] Epoch: 7/30 | Batch: 90/97 (93.8%) | Loss: 0.5782 | Batch time: 0.01s
2025-03-02 21:00:52,301 - INFO - [VAL] Epoch: 7/30 | Batch: 96/97 (100.0%) | Loss: 0.4723 | Batch time: 0.01s
2025-03-02 21:00:52,411 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 7)
2025-03-02 21:00:52,411 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:52,411 - INFO - Epoch 7/30 completed in 11.11s
2025-03-02 21:00:52,411 - INFO - Training   - Loss: 0.9522, Accuracy: 0.6981, F1: 0.7022
2025-03-02 21:00:52,411 - INFO - Validation - Loss: 0.4834, Accuracy: 0.8592, F1: 0.8566
2025-03-02 21:00:52,411 - INFO - Validation F1 improved from 0.8274 to 0.8566
2025-03-02 21:00:52,411 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:00:52,411 - INFO - Epoch 8/30
2025-03-02 21:00:52,411 - INFO - ----------------------------------------
2025-03-02 21:00:52,647 - INFO - [TRAIN] Epoch: 8/30 | Batch: 0/452 (0.2%) | Loss: 0.6859 | Batch time: 0.04s
2025-03-02 21:00:53,619 - INFO - [TRAIN] Epoch: 8/30 | Batch: 45/452 (10.2%) | Loss: 0.7186 | Batch time: 0.02s
2025-03-02 21:00:54,561 - INFO - [TRAIN] Epoch: 8/30 | Batch: 90/452 (20.1%) | Loss: 1.0265 | Batch time: 0.02s
2025-03-02 21:00:55,579 - INFO - [TRAIN] Epoch: 8/30 | Batch: 135/452 (30.1%) | Loss: 1.0683 | Batch time: 0.03s
2025-03-02 21:00:56,555 - INFO - [TRAIN] Epoch: 8/30 | Batch: 180/452 (40.0%) | Loss: 0.7565 | Batch time: 0.02s
2025-03-02 21:00:57,569 - INFO - [TRAIN] Epoch: 8/30 | Batch: 225/452 (50.0%) | Loss: 0.9244 | Batch time: 0.02s
2025-03-02 21:00:58,594 - INFO - [TRAIN] Epoch: 8/30 | Batch: 270/452 (60.0%) | Loss: 0.6624 | Batch time: 0.02s
2025-03-02 21:00:59,604 - INFO - [TRAIN] Epoch: 8/30 | Batch: 315/452 (69.9%) | Loss: 1.2141 | Batch time: 0.02s
2025-03-02 21:01:00,586 - INFO - [TRAIN] Epoch: 8/30 | Batch: 360/452 (79.9%) | Loss: 0.9057 | Batch time: 0.02s
2025-03-02 21:01:01,587 - INFO - [TRAIN] Epoch: 8/30 | Batch: 405/452 (89.8%) | Loss: 1.0196 | Batch time: 0.02s
2025-03-02 21:01:02,488 - INFO - [TRAIN] Epoch: 8/30 | Batch: 450/452 (99.8%) | Loss: 0.9464 | Batch time: 0.02s
2025-03-02 21:01:02,501 - INFO - [TRAIN] Epoch: 8/30 | Batch: 451/452 (100.0%) | Loss: 0.3950 | Batch time: 0.01s
2025-03-02 21:01:02,592 - INFO - [VAL] Epoch: 8/30 | Batch: 0/97 (1.0%) | Loss: 0.3169 | Batch time: 0.02s
2025-03-02 21:01:02,716 - INFO - [VAL] Epoch: 8/30 | Batch: 9/97 (10.3%) | Loss: 0.4666 | Batch time: 0.01s
2025-03-02 21:01:02,841 - INFO - [VAL] Epoch: 8/30 | Batch: 18/97 (19.6%) | Loss: 0.2416 | Batch time: 0.01s
2025-03-02 21:01:02,967 - INFO - [VAL] Epoch: 8/30 | Batch: 27/97 (28.9%) | Loss: 0.4335 | Batch time: 0.01s
2025-03-02 21:01:03,088 - INFO - [VAL] Epoch: 8/30 | Batch: 36/97 (38.1%) | Loss: 0.3825 | Batch time: 0.01s
2025-03-02 21:01:03,211 - INFO - [VAL] Epoch: 8/30 | Batch: 45/97 (47.4%) | Loss: 0.3258 | Batch time: 0.01s
2025-03-02 21:01:03,335 - INFO - [VAL] Epoch: 8/30 | Batch: 54/97 (56.7%) | Loss: 0.5022 | Batch time: 0.01s
2025-03-02 21:01:03,458 - INFO - [VAL] Epoch: 8/30 | Batch: 63/97 (66.0%) | Loss: 0.2968 | Batch time: 0.01s
2025-03-02 21:01:03,580 - INFO - [VAL] Epoch: 8/30 | Batch: 72/97 (75.3%) | Loss: 0.4777 | Batch time: 0.01s
2025-03-02 21:01:03,700 - INFO - [VAL] Epoch: 8/30 | Batch: 81/97 (84.5%) | Loss: 0.2917 | Batch time: 0.01s
2025-03-02 21:01:03,822 - INFO - [VAL] Epoch: 8/30 | Batch: 90/97 (93.8%) | Loss: 0.4420 | Batch time: 0.01s
2025-03-02 21:01:03,900 - INFO - [VAL] Epoch: 8/30 | Batch: 96/97 (100.0%) | Loss: 0.5275 | Batch time: 0.01s
2025-03-02 21:01:04,010 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 8)
2025-03-02 21:01:04,011 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:04,011 - INFO - Epoch 8/30 completed in 11.60s
2025-03-02 21:01:04,011 - INFO - Training   - Loss: 0.8886, Accuracy: 0.7163, F1: 0.7191
2025-03-02 21:01:04,011 - INFO - Validation - Loss: 0.4547, Accuracy: 0.8608, F1: 0.8600
2025-03-02 21:01:04,011 - INFO - Validation F1 improved from 0.8566 to 0.8600
2025-03-02 21:01:04,011 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:04,011 - INFO - Epoch 9/30
2025-03-02 21:01:04,011 - INFO - ----------------------------------------
2025-03-02 21:01:04,246 - INFO - [TRAIN] Epoch: 9/30 | Batch: 0/452 (0.2%) | Loss: 1.0251 | Batch time: 0.03s
2025-03-02 21:01:05,226 - INFO - [TRAIN] Epoch: 9/30 | Batch: 45/452 (10.2%) | Loss: 1.0227 | Batch time: 0.02s
2025-03-02 21:01:06,197 - INFO - [TRAIN] Epoch: 9/30 | Batch: 90/452 (20.1%) | Loss: 1.5555 | Batch time: 0.02s
2025-03-02 21:01:07,152 - INFO - [TRAIN] Epoch: 9/30 | Batch: 135/452 (30.1%) | Loss: 0.5031 | Batch time: 0.03s
2025-03-02 21:01:08,207 - INFO - [TRAIN] Epoch: 9/30 | Batch: 180/452 (40.0%) | Loss: 1.0112 | Batch time: 0.02s
2025-03-02 21:01:09,146 - INFO - [TRAIN] Epoch: 9/30 | Batch: 225/452 (50.0%) | Loss: 0.7605 | Batch time: 0.02s
2025-03-02 21:01:10,111 - INFO - [TRAIN] Epoch: 9/30 | Batch: 270/452 (60.0%) | Loss: 0.4754 | Batch time: 0.02s
2025-03-02 21:01:11,071 - INFO - [TRAIN] Epoch: 9/30 | Batch: 315/452 (69.9%) | Loss: 0.6262 | Batch time: 0.02s
2025-03-02 21:01:12,080 - INFO - [TRAIN] Epoch: 9/30 | Batch: 360/452 (79.9%) | Loss: 1.0952 | Batch time: 0.02s
2025-03-02 21:01:13,056 - INFO - [TRAIN] Epoch: 9/30 | Batch: 405/452 (89.8%) | Loss: 0.6592 | Batch time: 0.02s
2025-03-02 21:01:13,909 - INFO - [TRAIN] Epoch: 9/30 | Batch: 450/452 (99.8%) | Loss: 0.4656 | Batch time: 0.02s
2025-03-02 21:01:13,920 - INFO - [TRAIN] Epoch: 9/30 | Batch: 451/452 (100.0%) | Loss: 0.6332 | Batch time: 0.01s
2025-03-02 21:01:13,997 - INFO - [VAL] Epoch: 9/30 | Batch: 0/97 (1.0%) | Loss: 0.3207 | Batch time: 0.02s
2025-03-02 21:01:14,136 - INFO - [VAL] Epoch: 9/30 | Batch: 9/97 (10.3%) | Loss: 0.4717 | Batch time: 0.01s
2025-03-02 21:01:14,262 - INFO - [VAL] Epoch: 9/30 | Batch: 18/97 (19.6%) | Loss: 0.2545 | Batch time: 0.01s
2025-03-02 21:01:14,393 - INFO - [VAL] Epoch: 9/30 | Batch: 27/97 (28.9%) | Loss: 0.4443 | Batch time: 0.01s
2025-03-02 21:01:14,520 - INFO - [VAL] Epoch: 9/30 | Batch: 36/97 (38.1%) | Loss: 0.3836 | Batch time: 0.01s
2025-03-02 21:01:14,649 - INFO - [VAL] Epoch: 9/30 | Batch: 45/97 (47.4%) | Loss: 0.3351 | Batch time: 0.01s
2025-03-02 21:01:14,778 - INFO - [VAL] Epoch: 9/30 | Batch: 54/97 (56.7%) | Loss: 0.4931 | Batch time: 0.01s
2025-03-02 21:01:14,904 - INFO - [VAL] Epoch: 9/30 | Batch: 63/97 (66.0%) | Loss: 0.2913 | Batch time: 0.01s
2025-03-02 21:01:15,027 - INFO - [VAL] Epoch: 9/30 | Batch: 72/97 (75.3%) | Loss: 0.4980 | Batch time: 0.01s
2025-03-02 21:01:15,149 - INFO - [VAL] Epoch: 9/30 | Batch: 81/97 (84.5%) | Loss: 0.3116 | Batch time: 0.01s
2025-03-02 21:01:15,272 - INFO - [VAL] Epoch: 9/30 | Batch: 90/97 (93.8%) | Loss: 0.4717 | Batch time: 0.01s
2025-03-02 21:01:15,351 - INFO - [VAL] Epoch: 9/30 | Batch: 96/97 (100.0%) | Loss: 0.5220 | Batch time: 0.01s
2025-03-02 21:01:15,354 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:15,354 - INFO - Epoch 9/30 completed in 11.34s
2025-03-02 21:01:15,354 - INFO - Training   - Loss: 0.8654, Accuracy: 0.7210, F1: 0.7240
2025-03-02 21:01:15,354 - INFO - Validation - Loss: 0.4564, Accuracy: 0.8595, F1: 0.8579
2025-03-02 21:01:15,354 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:15,354 - INFO - Epoch 10/30
2025-03-02 21:01:15,354 - INFO - ----------------------------------------
2025-03-02 21:01:15,592 - INFO - [TRAIN] Epoch: 10/30 | Batch: 0/452 (0.2%) | Loss: 0.7321 | Batch time: 0.04s
2025-03-02 21:01:16,565 - INFO - [TRAIN] Epoch: 10/30 | Batch: 45/452 (10.2%) | Loss: 0.9000 | Batch time: 0.02s
2025-03-02 21:01:17,498 - INFO - [TRAIN] Epoch: 10/30 | Batch: 90/452 (20.1%) | Loss: 0.8404 | Batch time: 0.02s
2025-03-02 21:01:18,420 - INFO - [TRAIN] Epoch: 10/30 | Batch: 135/452 (30.1%) | Loss: 1.0802 | Batch time: 0.02s
2025-03-02 21:01:19,355 - INFO - [TRAIN] Epoch: 10/30 | Batch: 180/452 (40.0%) | Loss: 1.1884 | Batch time: 0.02s
2025-03-02 21:01:20,345 - INFO - [TRAIN] Epoch: 10/30 | Batch: 225/452 (50.0%) | Loss: 0.7229 | Batch time: 0.02s
2025-03-02 21:01:21,361 - INFO - [TRAIN] Epoch: 10/30 | Batch: 270/452 (60.0%) | Loss: 0.8616 | Batch time: 0.02s
2025-03-02 21:01:22,317 - INFO - [TRAIN] Epoch: 10/30 | Batch: 315/452 (69.9%) | Loss: 0.7431 | Batch time: 0.02s
2025-03-02 21:01:23,261 - INFO - [TRAIN] Epoch: 10/30 | Batch: 360/452 (79.9%) | Loss: 1.5047 | Batch time: 0.02s
2025-03-02 21:01:24,245 - INFO - [TRAIN] Epoch: 10/30 | Batch: 405/452 (89.8%) | Loss: 0.6102 | Batch time: 0.02s
2025-03-02 21:01:25,104 - INFO - [TRAIN] Epoch: 10/30 | Batch: 450/452 (99.8%) | Loss: 0.7236 | Batch time: 0.02s
2025-03-02 21:01:25,116 - INFO - [TRAIN] Epoch: 10/30 | Batch: 451/452 (100.0%) | Loss: 1.0409 | Batch time: 0.01s
2025-03-02 21:01:25,194 - INFO - [VAL] Epoch: 10/30 | Batch: 0/97 (1.0%) | Loss: 0.3282 | Batch time: 0.02s
2025-03-02 21:01:25,337 - INFO - [VAL] Epoch: 10/30 | Batch: 9/97 (10.3%) | Loss: 0.4624 | Batch time: 0.01s
2025-03-02 21:01:25,465 - INFO - [VAL] Epoch: 10/30 | Batch: 18/97 (19.6%) | Loss: 0.2254 | Batch time: 0.01s
2025-03-02 21:01:25,591 - INFO - [VAL] Epoch: 10/30 | Batch: 27/97 (28.9%) | Loss: 0.4603 | Batch time: 0.01s
2025-03-02 21:01:25,719 - INFO - [VAL] Epoch: 10/30 | Batch: 36/97 (38.1%) | Loss: 0.3634 | Batch time: 0.01s
2025-03-02 21:01:25,847 - INFO - [VAL] Epoch: 10/30 | Batch: 45/97 (47.4%) | Loss: 0.3406 | Batch time: 0.01s
2025-03-02 21:01:25,973 - INFO - [VAL] Epoch: 10/30 | Batch: 54/97 (56.7%) | Loss: 0.5048 | Batch time: 0.01s
2025-03-02 21:01:26,100 - INFO - [VAL] Epoch: 10/30 | Batch: 63/97 (66.0%) | Loss: 0.3256 | Batch time: 0.01s
2025-03-02 21:01:26,224 - INFO - [VAL] Epoch: 10/30 | Batch: 72/97 (75.3%) | Loss: 0.5015 | Batch time: 0.01s
2025-03-02 21:01:26,346 - INFO - [VAL] Epoch: 10/30 | Batch: 81/97 (84.5%) | Loss: 0.3148 | Batch time: 0.01s
2025-03-02 21:01:26,470 - INFO - [VAL] Epoch: 10/30 | Batch: 90/97 (93.8%) | Loss: 0.4753 | Batch time: 0.01s
2025-03-02 21:01:26,549 - INFO - [VAL] Epoch: 10/30 | Batch: 96/97 (100.0%) | Loss: 0.5431 | Batch time: 0.01s
2025-03-02 21:01:26,553 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:26,553 - INFO - Epoch 10/30 completed in 11.20s
2025-03-02 21:01:26,553 - INFO - Training   - Loss: 0.8800, Accuracy: 0.7160, F1: 0.7191
2025-03-02 21:01:26,553 - INFO - Validation - Loss: 0.4659, Accuracy: 0.8592, F1: 0.8582
2025-03-02 21:01:26,553 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:26,612 - INFO - Checkpoint saved: checkpoint_epoch_10.pth (Epoch 10)
2025-03-02 21:01:26,612 - INFO - Epoch 11/30
2025-03-02 21:01:26,612 - INFO - ----------------------------------------
2025-03-02 21:01:26,839 - INFO - [TRAIN] Epoch: 11/30 | Batch: 0/452 (0.2%) | Loss: 1.1087 | Batch time: 0.03s
2025-03-02 21:01:27,821 - INFO - [TRAIN] Epoch: 11/30 | Batch: 45/452 (10.2%) | Loss: 0.6443 | Batch time: 0.02s
2025-03-02 21:01:28,717 - INFO - [TRAIN] Epoch: 11/30 | Batch: 90/452 (20.1%) | Loss: 1.0068 | Batch time: 0.02s
2025-03-02 21:01:29,652 - INFO - [TRAIN] Epoch: 11/30 | Batch: 135/452 (30.1%) | Loss: 0.7192 | Batch time: 0.02s
2025-03-02 21:01:30,615 - INFO - [TRAIN] Epoch: 11/30 | Batch: 180/452 (40.0%) | Loss: 0.8761 | Batch time: 0.02s
2025-03-02 21:01:31,568 - INFO - [TRAIN] Epoch: 11/30 | Batch: 225/452 (50.0%) | Loss: 0.7302 | Batch time: 0.02s
2025-03-02 21:01:32,633 - INFO - [TRAIN] Epoch: 11/30 | Batch: 270/452 (60.0%) | Loss: 1.0388 | Batch time: 0.02s
2025-03-02 21:01:33,700 - INFO - [TRAIN] Epoch: 11/30 | Batch: 315/452 (69.9%) | Loss: 1.2770 | Batch time: 0.02s
2025-03-02 21:01:34,703 - INFO - [TRAIN] Epoch: 11/30 | Batch: 360/452 (79.9%) | Loss: 1.2831 | Batch time: 0.03s
2025-03-02 21:01:35,800 - INFO - [TRAIN] Epoch: 11/30 | Batch: 405/452 (89.8%) | Loss: 1.2192 | Batch time: 0.02s
2025-03-02 21:01:36,700 - INFO - [TRAIN] Epoch: 11/30 | Batch: 450/452 (99.8%) | Loss: 0.6755 | Batch time: 0.02s
2025-03-02 21:01:36,713 - INFO - [TRAIN] Epoch: 11/30 | Batch: 451/452 (100.0%) | Loss: 0.8464 | Batch time: 0.01s
2025-03-02 21:01:36,792 - INFO - [VAL] Epoch: 11/30 | Batch: 0/97 (1.0%) | Loss: 0.3221 | Batch time: 0.02s
2025-03-02 21:01:36,936 - INFO - [VAL] Epoch: 11/30 | Batch: 9/97 (10.3%) | Loss: 0.4859 | Batch time: 0.01s
2025-03-02 21:01:37,064 - INFO - [VAL] Epoch: 11/30 | Batch: 18/97 (19.6%) | Loss: 0.2347 | Batch time: 0.01s
2025-03-02 21:01:37,190 - INFO - [VAL] Epoch: 11/30 | Batch: 27/97 (28.9%) | Loss: 0.4129 | Batch time: 0.01s
2025-03-02 21:01:37,314 - INFO - [VAL] Epoch: 11/30 | Batch: 36/97 (38.1%) | Loss: 0.3660 | Batch time: 0.01s
2025-03-02 21:01:37,439 - INFO - [VAL] Epoch: 11/30 | Batch: 45/97 (47.4%) | Loss: 0.3025 | Batch time: 0.01s
2025-03-02 21:01:37,564 - INFO - [VAL] Epoch: 11/30 | Batch: 54/97 (56.7%) | Loss: 0.4599 | Batch time: 0.01s
2025-03-02 21:01:37,690 - INFO - [VAL] Epoch: 11/30 | Batch: 63/97 (66.0%) | Loss: 0.3050 | Batch time: 0.01s
2025-03-02 21:01:37,812 - INFO - [VAL] Epoch: 11/30 | Batch: 72/97 (75.3%) | Loss: 0.4686 | Batch time: 0.01s
2025-03-02 21:01:37,933 - INFO - [VAL] Epoch: 11/30 | Batch: 81/97 (84.5%) | Loss: 0.2846 | Batch time: 0.01s
2025-03-02 21:01:38,056 - INFO - [VAL] Epoch: 11/30 | Batch: 90/97 (93.8%) | Loss: 0.4302 | Batch time: 0.01s
2025-03-02 21:01:38,134 - INFO - [VAL] Epoch: 11/30 | Batch: 96/97 (100.0%) | Loss: 0.5385 | Batch time: 0.01s
2025-03-02 21:01:38,232 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 11)
2025-03-02 21:01:38,232 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:38,232 - INFO - Epoch 11/30 completed in 11.62s
2025-03-02 21:01:38,232 - INFO - Training   - Loss: 0.8690, Accuracy: 0.7175, F1: 0.7209
2025-03-02 21:01:38,232 - INFO - Validation - Loss: 0.4380, Accuracy: 0.8611, F1: 0.8607
2025-03-02 21:01:38,232 - INFO - Validation F1 improved from 0.8600 to 0.8607
2025-03-02 21:01:38,232 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:38,232 - INFO - Epoch 12/30
2025-03-02 21:01:38,232 - INFO - ----------------------------------------
2025-03-02 21:01:38,473 - INFO - [TRAIN] Epoch: 12/30 | Batch: 0/452 (0.2%) | Loss: 0.7766 | Batch time: 0.04s
2025-03-02 21:01:39,479 - INFO - [TRAIN] Epoch: 12/30 | Batch: 45/452 (10.2%) | Loss: 0.5920 | Batch time: 0.02s
2025-03-02 21:01:40,368 - INFO - [TRAIN] Epoch: 12/30 | Batch: 90/452 (20.1%) | Loss: 0.7652 | Batch time: 0.02s
2025-03-02 21:01:41,343 - INFO - [TRAIN] Epoch: 12/30 | Batch: 135/452 (30.1%) | Loss: 0.5467 | Batch time: 0.02s
2025-03-02 21:01:42,336 - INFO - [TRAIN] Epoch: 12/30 | Batch: 180/452 (40.0%) | Loss: 1.0515 | Batch time: 0.02s
2025-03-02 21:01:43,289 - INFO - [TRAIN] Epoch: 12/30 | Batch: 225/452 (50.0%) | Loss: 0.7698 | Batch time: 0.02s
2025-03-02 21:01:44,248 - INFO - [TRAIN] Epoch: 12/30 | Batch: 270/452 (60.0%) | Loss: 1.1594 | Batch time: 0.02s
2025-03-02 21:01:45,247 - INFO - [TRAIN] Epoch: 12/30 | Batch: 315/452 (69.9%) | Loss: 1.3953 | Batch time: 0.02s
2025-03-02 21:01:46,213 - INFO - [TRAIN] Epoch: 12/30 | Batch: 360/452 (79.9%) | Loss: 0.8454 | Batch time: 0.02s
2025-03-02 21:01:47,174 - INFO - [TRAIN] Epoch: 12/30 | Batch: 405/452 (89.8%) | Loss: 0.7081 | Batch time: 0.02s
2025-03-02 21:01:48,046 - INFO - [TRAIN] Epoch: 12/30 | Batch: 450/452 (99.8%) | Loss: 0.6802 | Batch time: 0.02s
2025-03-02 21:01:48,059 - INFO - [TRAIN] Epoch: 12/30 | Batch: 451/452 (100.0%) | Loss: 0.8313 | Batch time: 0.01s
2025-03-02 21:01:48,152 - INFO - [VAL] Epoch: 12/30 | Batch: 0/97 (1.0%) | Loss: 0.3181 | Batch time: 0.02s
2025-03-02 21:01:48,272 - INFO - [VAL] Epoch: 12/30 | Batch: 9/97 (10.3%) | Loss: 0.4612 | Batch time: 0.01s
2025-03-02 21:01:48,394 - INFO - [VAL] Epoch: 12/30 | Batch: 18/97 (19.6%) | Loss: 0.2377 | Batch time: 0.01s
2025-03-02 21:01:48,514 - INFO - [VAL] Epoch: 12/30 | Batch: 27/97 (28.9%) | Loss: 0.4919 | Batch time: 0.01s
2025-03-02 21:01:48,636 - INFO - [VAL] Epoch: 12/30 | Batch: 36/97 (38.1%) | Loss: 0.3383 | Batch time: 0.01s
2025-03-02 21:01:48,760 - INFO - [VAL] Epoch: 12/30 | Batch: 45/97 (47.4%) | Loss: 0.3252 | Batch time: 0.01s
2025-03-02 21:01:48,883 - INFO - [VAL] Epoch: 12/30 | Batch: 54/97 (56.7%) | Loss: 0.5230 | Batch time: 0.01s
2025-03-02 21:01:49,007 - INFO - [VAL] Epoch: 12/30 | Batch: 63/97 (66.0%) | Loss: 0.3921 | Batch time: 0.01s
2025-03-02 21:01:49,129 - INFO - [VAL] Epoch: 12/30 | Batch: 72/97 (75.3%) | Loss: 0.5170 | Batch time: 0.01s
2025-03-02 21:01:49,251 - INFO - [VAL] Epoch: 12/30 | Batch: 81/97 (84.5%) | Loss: 0.2996 | Batch time: 0.01s
2025-03-02 21:01:49,372 - INFO - [VAL] Epoch: 12/30 | Batch: 90/97 (93.8%) | Loss: 0.4764 | Batch time: 0.01s
2025-03-02 21:01:49,450 - INFO - [VAL] Epoch: 12/30 | Batch: 96/97 (100.0%) | Loss: 0.5790 | Batch time: 0.01s
2025-03-02 21:01:49,453 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:49,453 - INFO - Epoch 12/30 completed in 11.22s
2025-03-02 21:01:49,453 - INFO - Training   - Loss: 0.8634, Accuracy: 0.7274, F1: 0.7307
2025-03-02 21:01:49,453 - INFO - Validation - Loss: 0.4738, Accuracy: 0.8589, F1: 0.8580
2025-03-02 21:01:49,453 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:01:49,453 - INFO - Epoch 13/30
2025-03-02 21:01:49,453 - INFO - ----------------------------------------
2025-03-02 21:01:49,688 - INFO - [TRAIN] Epoch: 13/30 | Batch: 0/452 (0.2%) | Loss: 0.6937 | Batch time: 0.05s
2025-03-02 21:01:50,630 - INFO - [TRAIN] Epoch: 13/30 | Batch: 45/452 (10.2%) | Loss: 0.3215 | Batch time: 0.02s
2025-03-02 21:01:51,582 - INFO - [TRAIN] Epoch: 13/30 | Batch: 90/452 (20.1%) | Loss: 0.9483 | Batch time: 0.02s
2025-03-02 21:01:52,556 - INFO - [TRAIN] Epoch: 13/30 | Batch: 135/452 (30.1%) | Loss: 0.5816 | Batch time: 0.02s
2025-03-02 21:01:53,524 - INFO - [TRAIN] Epoch: 13/30 | Batch: 180/452 (40.0%) | Loss: 0.9753 | Batch time: 0.03s
2025-03-02 21:01:54,531 - INFO - [TRAIN] Epoch: 13/30 | Batch: 225/452 (50.0%) | Loss: 0.7453 | Batch time: 0.02s
2025-03-02 21:01:55,518 - INFO - [TRAIN] Epoch: 13/30 | Batch: 270/452 (60.0%) | Loss: 0.8191 | Batch time: 0.02s
2025-03-02 21:01:56,506 - INFO - [TRAIN] Epoch: 13/30 | Batch: 315/452 (69.9%) | Loss: 0.8890 | Batch time: 0.02s
2025-03-02 21:01:57,498 - INFO - [TRAIN] Epoch: 13/30 | Batch: 360/452 (79.9%) | Loss: 0.6528 | Batch time: 0.02s
2025-03-02 21:01:58,474 - INFO - [TRAIN] Epoch: 13/30 | Batch: 405/452 (89.8%) | Loss: 0.9490 | Batch time: 0.02s
2025-03-02 21:01:59,342 - INFO - [TRAIN] Epoch: 13/30 | Batch: 450/452 (99.8%) | Loss: 0.8621 | Batch time: 0.02s
2025-03-02 21:01:59,354 - INFO - [TRAIN] Epoch: 13/30 | Batch: 451/452 (100.0%) | Loss: 0.4614 | Batch time: 0.01s
2025-03-02 21:01:59,428 - INFO - [VAL] Epoch: 13/30 | Batch: 0/97 (1.0%) | Loss: 0.2987 | Batch time: 0.03s
2025-03-02 21:01:59,561 - INFO - [VAL] Epoch: 13/30 | Batch: 9/97 (10.3%) | Loss: 0.5359 | Batch time: 0.01s
2025-03-02 21:01:59,684 - INFO - [VAL] Epoch: 13/30 | Batch: 18/97 (19.6%) | Loss: 0.2196 | Batch time: 0.01s
2025-03-02 21:01:59,809 - INFO - [VAL] Epoch: 13/30 | Batch: 27/97 (28.9%) | Loss: 0.4291 | Batch time: 0.01s
2025-03-02 21:01:59,935 - INFO - [VAL] Epoch: 13/30 | Batch: 36/97 (38.1%) | Loss: 0.4057 | Batch time: 0.01s
2025-03-02 21:02:00,068 - INFO - [VAL] Epoch: 13/30 | Batch: 45/97 (47.4%) | Loss: 0.3237 | Batch time: 0.01s
2025-03-02 21:02:00,194 - INFO - [VAL] Epoch: 13/30 | Batch: 54/97 (56.7%) | Loss: 0.5186 | Batch time: 0.01s
2025-03-02 21:02:00,320 - INFO - [VAL] Epoch: 13/30 | Batch: 63/97 (66.0%) | Loss: 0.3488 | Batch time: 0.01s
2025-03-02 21:02:00,443 - INFO - [VAL] Epoch: 13/30 | Batch: 72/97 (75.3%) | Loss: 0.4708 | Batch time: 0.01s
2025-03-02 21:02:00,564 - INFO - [VAL] Epoch: 13/30 | Batch: 81/97 (84.5%) | Loss: 0.2843 | Batch time: 0.01s
2025-03-02 21:02:00,686 - INFO - [VAL] Epoch: 13/30 | Batch: 90/97 (93.8%) | Loss: 0.4773 | Batch time: 0.01s
2025-03-02 21:02:00,766 - INFO - [VAL] Epoch: 13/30 | Batch: 96/97 (100.0%) | Loss: 0.5768 | Batch time: 0.01s
2025-03-02 21:02:00,874 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 13)
2025-03-02 21:02:00,874 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:00,874 - INFO - Epoch 13/30 completed in 11.42s
2025-03-02 21:02:00,874 - INFO - Training   - Loss: 0.8644, Accuracy: 0.7187, F1: 0.7224
2025-03-02 21:02:00,874 - INFO - Validation - Loss: 0.4505, Accuracy: 0.8669, F1: 0.8660
2025-03-02 21:02:00,874 - INFO - Validation F1 improved from 0.8607 to 0.8660
2025-03-02 21:02:00,874 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:00,874 - INFO - Epoch 14/30
2025-03-02 21:02:00,874 - INFO - ----------------------------------------
2025-03-02 21:02:01,095 - INFO - [TRAIN] Epoch: 14/30 | Batch: 0/452 (0.2%) | Loss: 0.8540 | Batch time: 0.03s
2025-03-02 21:02:02,110 - INFO - [TRAIN] Epoch: 14/30 | Batch: 45/452 (10.2%) | Loss: 0.6920 | Batch time: 0.02s
2025-03-02 21:02:03,092 - INFO - [TRAIN] Epoch: 14/30 | Batch: 90/452 (20.1%) | Loss: 0.7836 | Batch time: 0.02s
2025-03-02 21:02:04,063 - INFO - [TRAIN] Epoch: 14/30 | Batch: 135/452 (30.1%) | Loss: 1.3551 | Batch time: 0.02s
2025-03-02 21:02:05,116 - INFO - [TRAIN] Epoch: 14/30 | Batch: 180/452 (40.0%) | Loss: 1.4500 | Batch time: 0.02s
2025-03-02 21:02:06,131 - INFO - [TRAIN] Epoch: 14/30 | Batch: 225/452 (50.0%) | Loss: 0.8862 | Batch time: 0.02s
2025-03-02 21:02:07,154 - INFO - [TRAIN] Epoch: 14/30 | Batch: 270/452 (60.0%) | Loss: 0.8723 | Batch time: 0.02s
2025-03-02 21:02:08,175 - INFO - [TRAIN] Epoch: 14/30 | Batch: 315/452 (69.9%) | Loss: 0.8948 | Batch time: 0.02s
2025-03-02 21:02:09,187 - INFO - [TRAIN] Epoch: 14/30 | Batch: 360/452 (79.9%) | Loss: 0.9815 | Batch time: 0.02s
2025-03-02 21:02:10,213 - INFO - [TRAIN] Epoch: 14/30 | Batch: 405/452 (89.8%) | Loss: 0.8659 | Batch time: 0.02s
2025-03-02 21:02:11,099 - INFO - [TRAIN] Epoch: 14/30 | Batch: 450/452 (99.8%) | Loss: 0.6801 | Batch time: 0.02s
2025-03-02 21:02:11,111 - INFO - [TRAIN] Epoch: 14/30 | Batch: 451/452 (100.0%) | Loss: 0.8229 | Batch time: 0.01s
2025-03-02 21:02:11,198 - INFO - [VAL] Epoch: 14/30 | Batch: 0/97 (1.0%) | Loss: 0.3039 | Batch time: 0.02s
2025-03-02 21:02:11,334 - INFO - [VAL] Epoch: 14/30 | Batch: 9/97 (10.3%) | Loss: 0.5191 | Batch time: 0.01s
2025-03-02 21:02:11,458 - INFO - [VAL] Epoch: 14/30 | Batch: 18/97 (19.6%) | Loss: 0.2439 | Batch time: 0.01s
2025-03-02 21:02:11,582 - INFO - [VAL] Epoch: 14/30 | Batch: 27/97 (28.9%) | Loss: 0.4405 | Batch time: 0.01s
2025-03-02 21:02:11,705 - INFO - [VAL] Epoch: 14/30 | Batch: 36/97 (38.1%) | Loss: 0.3787 | Batch time: 0.01s
2025-03-02 21:02:11,832 - INFO - [VAL] Epoch: 14/30 | Batch: 45/97 (47.4%) | Loss: 0.2906 | Batch time: 0.01s
2025-03-02 21:02:11,960 - INFO - [VAL] Epoch: 14/30 | Batch: 54/97 (56.7%) | Loss: 0.4839 | Batch time: 0.01s
2025-03-02 21:02:12,086 - INFO - [VAL] Epoch: 14/30 | Batch: 63/97 (66.0%) | Loss: 0.3395 | Batch time: 0.01s
2025-03-02 21:02:12,210 - INFO - [VAL] Epoch: 14/30 | Batch: 72/97 (75.3%) | Loss: 0.4710 | Batch time: 0.01s
2025-03-02 21:02:12,334 - INFO - [VAL] Epoch: 14/30 | Batch: 81/97 (84.5%) | Loss: 0.2713 | Batch time: 0.01s
2025-03-02 21:02:12,457 - INFO - [VAL] Epoch: 14/30 | Batch: 90/97 (93.8%) | Loss: 0.4750 | Batch time: 0.01s
2025-03-02 21:02:12,536 - INFO - [VAL] Epoch: 14/30 | Batch: 96/97 (100.0%) | Loss: 0.5354 | Batch time: 0.01s
2025-03-02 21:02:12,646 - INFO - Checkpoint saved: mobilenet_v2_v1_best.pth (Epoch 14)
2025-03-02 21:02:12,646 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:12,646 - INFO - Epoch 14/30 completed in 11.77s
2025-03-02 21:02:12,646 - INFO - Training   - Loss: 0.8562, Accuracy: 0.7216, F1: 0.7247
2025-03-02 21:02:12,646 - INFO - Validation - Loss: 0.4381, Accuracy: 0.8714, F1: 0.8716
2025-03-02 21:02:12,646 - INFO - Validation F1 improved from 0.8660 to 0.8716
2025-03-02 21:02:12,646 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:12,646 - INFO - Epoch 15/30
2025-03-02 21:02:12,646 - INFO - ----------------------------------------
2025-03-02 21:02:12,881 - INFO - [TRAIN] Epoch: 15/30 | Batch: 0/452 (0.2%) | Loss: 0.6538 | Batch time: 0.03s
2025-03-02 21:02:13,899 - INFO - [TRAIN] Epoch: 15/30 | Batch: 45/452 (10.2%) | Loss: 0.7021 | Batch time: 0.03s
2025-03-02 21:02:14,944 - INFO - [TRAIN] Epoch: 15/30 | Batch: 90/452 (20.1%) | Loss: 0.6962 | Batch time: 0.02s
2025-03-02 21:02:15,996 - INFO - [TRAIN] Epoch: 15/30 | Batch: 135/452 (30.1%) | Loss: 0.6803 | Batch time: 0.02s
2025-03-02 21:02:17,052 - INFO - [TRAIN] Epoch: 15/30 | Batch: 180/452 (40.0%) | Loss: 0.9584 | Batch time: 0.02s
2025-03-02 21:02:18,107 - INFO - [TRAIN] Epoch: 15/30 | Batch: 225/452 (50.0%) | Loss: 0.8560 | Batch time: 0.02s
2025-03-02 21:02:19,148 - INFO - [TRAIN] Epoch: 15/30 | Batch: 270/452 (60.0%) | Loss: 0.8846 | Batch time: 0.02s
2025-03-02 21:02:20,223 - INFO - [TRAIN] Epoch: 15/30 | Batch: 315/452 (69.9%) | Loss: 0.8435 | Batch time: 0.02s
2025-03-02 21:02:21,265 - INFO - [TRAIN] Epoch: 15/30 | Batch: 360/452 (79.9%) | Loss: 0.7100 | Batch time: 0.02s
2025-03-02 21:02:22,318 - INFO - [TRAIN] Epoch: 15/30 | Batch: 405/452 (89.8%) | Loss: 1.1472 | Batch time: 0.02s
2025-03-02 21:02:23,236 - INFO - [TRAIN] Epoch: 15/30 | Batch: 450/452 (99.8%) | Loss: 0.8408 | Batch time: 0.02s
2025-03-02 21:02:23,248 - INFO - [TRAIN] Epoch: 15/30 | Batch: 451/452 (100.0%) | Loss: 0.7137 | Batch time: 0.01s
2025-03-02 21:02:23,334 - INFO - [VAL] Epoch: 15/30 | Batch: 0/97 (1.0%) | Loss: 0.3380 | Batch time: 0.02s
2025-03-02 21:02:23,467 - INFO - [VAL] Epoch: 15/30 | Batch: 9/97 (10.3%) | Loss: 0.4982 | Batch time: 0.01s
2025-03-02 21:02:23,592 - INFO - [VAL] Epoch: 15/30 | Batch: 18/97 (19.6%) | Loss: 0.2587 | Batch time: 0.01s
2025-03-02 21:02:23,714 - INFO - [VAL] Epoch: 15/30 | Batch: 27/97 (28.9%) | Loss: 0.4584 | Batch time: 0.01s
2025-03-02 21:02:23,838 - INFO - [VAL] Epoch: 15/30 | Batch: 36/97 (38.1%) | Loss: 0.3662 | Batch time: 0.01s
2025-03-02 21:02:23,966 - INFO - [VAL] Epoch: 15/30 | Batch: 45/97 (47.4%) | Loss: 0.3234 | Batch time: 0.01s
2025-03-02 21:02:24,097 - INFO - [VAL] Epoch: 15/30 | Batch: 54/97 (56.7%) | Loss: 0.4867 | Batch time: 0.02s
2025-03-02 21:02:24,223 - INFO - [VAL] Epoch: 15/30 | Batch: 63/97 (66.0%) | Loss: 0.3607 | Batch time: 0.01s
2025-03-02 21:02:24,347 - INFO - [VAL] Epoch: 15/30 | Batch: 72/97 (75.3%) | Loss: 0.4700 | Batch time: 0.01s
2025-03-02 21:02:24,469 - INFO - [VAL] Epoch: 15/30 | Batch: 81/97 (84.5%) | Loss: 0.2610 | Batch time: 0.01s
2025-03-02 21:02:24,593 - INFO - [VAL] Epoch: 15/30 | Batch: 90/97 (93.8%) | Loss: 0.4627 | Batch time: 0.01s
2025-03-02 21:02:24,671 - INFO - [VAL] Epoch: 15/30 | Batch: 96/97 (100.0%) | Loss: 0.5365 | Batch time: 0.01s
2025-03-02 21:02:24,675 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:24,675 - INFO - Epoch 15/30 completed in 12.03s
2025-03-02 21:02:24,675 - INFO - Training   - Loss: 0.8396, Accuracy: 0.7239, F1: 0.7277
2025-03-02 21:02:24,675 - INFO - Validation - Loss: 0.4547, Accuracy: 0.8618, F1: 0.8611
2025-03-02 21:02:24,675 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:24,738 - INFO - Checkpoint saved: checkpoint_epoch_15.pth (Epoch 15)
2025-03-02 21:02:24,738 - INFO - Epoch 16/30
2025-03-02 21:02:24,738 - INFO - ----------------------------------------
2025-03-02 21:02:24,957 - INFO - [TRAIN] Epoch: 16/30 | Batch: 0/452 (0.2%) | Loss: 1.1155 | Batch time: 0.03s
2025-03-02 21:02:26,023 - INFO - [TRAIN] Epoch: 16/30 | Batch: 45/452 (10.2%) | Loss: 1.1312 | Batch time: 0.02s
2025-03-02 21:02:27,056 - INFO - [TRAIN] Epoch: 16/30 | Batch: 90/452 (20.1%) | Loss: 0.6892 | Batch time: 0.02s
2025-03-02 21:02:28,140 - INFO - [TRAIN] Epoch: 16/30 | Batch: 135/452 (30.1%) | Loss: 1.0108 | Batch time: 0.02s
2025-03-02 21:02:29,193 - INFO - [TRAIN] Epoch: 16/30 | Batch: 180/452 (40.0%) | Loss: 0.7996 | Batch time: 0.02s
2025-03-02 21:02:30,413 - INFO - [TRAIN] Epoch: 16/30 | Batch: 225/452 (50.0%) | Loss: 1.0617 | Batch time: 0.03s
2025-03-02 21:02:31,542 - INFO - [TRAIN] Epoch: 16/30 | Batch: 270/452 (60.0%) | Loss: 0.7654 | Batch time: 0.02s
2025-03-02 21:02:32,647 - INFO - [TRAIN] Epoch: 16/30 | Batch: 315/452 (69.9%) | Loss: 0.8274 | Batch time: 0.02s
2025-03-02 21:02:33,735 - INFO - [TRAIN] Epoch: 16/30 | Batch: 360/452 (79.9%) | Loss: 0.6426 | Batch time: 0.02s
2025-03-02 21:02:34,826 - INFO - [TRAIN] Epoch: 16/30 | Batch: 405/452 (89.8%) | Loss: 0.9486 | Batch time: 0.02s
2025-03-02 21:02:35,748 - INFO - [TRAIN] Epoch: 16/30 | Batch: 450/452 (99.8%) | Loss: 0.8996 | Batch time: 0.02s
2025-03-02 21:02:35,760 - INFO - [TRAIN] Epoch: 16/30 | Batch: 451/452 (100.0%) | Loss: 0.9399 | Batch time: 0.01s
2025-03-02 21:02:35,841 - INFO - [VAL] Epoch: 16/30 | Batch: 0/97 (1.0%) | Loss: 0.3103 | Batch time: 0.02s
2025-03-02 21:02:35,982 - INFO - [VAL] Epoch: 16/30 | Batch: 9/97 (10.3%) | Loss: 0.4895 | Batch time: 0.01s
2025-03-02 21:02:36,107 - INFO - [VAL] Epoch: 16/30 | Batch: 18/97 (19.6%) | Loss: 0.2365 | Batch time: 0.01s
2025-03-02 21:02:36,233 - INFO - [VAL] Epoch: 16/30 | Batch: 27/97 (28.9%) | Loss: 0.4189 | Batch time: 0.01s
2025-03-02 21:02:36,357 - INFO - [VAL] Epoch: 16/30 | Batch: 36/97 (38.1%) | Loss: 0.3836 | Batch time: 0.01s
2025-03-02 21:02:36,483 - INFO - [VAL] Epoch: 16/30 | Batch: 45/97 (47.4%) | Loss: 0.2989 | Batch time: 0.01s
2025-03-02 21:02:36,610 - INFO - [VAL] Epoch: 16/30 | Batch: 54/97 (56.7%) | Loss: 0.4678 | Batch time: 0.01s
2025-03-02 21:02:36,737 - INFO - [VAL] Epoch: 16/30 | Batch: 63/97 (66.0%) | Loss: 0.3821 | Batch time: 0.01s
2025-03-02 21:02:36,862 - INFO - [VAL] Epoch: 16/30 | Batch: 72/97 (75.3%) | Loss: 0.4729 | Batch time: 0.01s
2025-03-02 21:02:36,986 - INFO - [VAL] Epoch: 16/30 | Batch: 81/97 (84.5%) | Loss: 0.2936 | Batch time: 0.01s
2025-03-02 21:02:37,111 - INFO - [VAL] Epoch: 16/30 | Batch: 90/97 (93.8%) | Loss: 0.5076 | Batch time: 0.01s
2025-03-02 21:02:37,194 - INFO - [VAL] Epoch: 16/30 | Batch: 96/97 (100.0%) | Loss: 0.5680 | Batch time: 0.01s
2025-03-02 21:02:37,198 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:37,198 - INFO - Epoch 16/30 completed in 12.46s
2025-03-02 21:02:37,198 - INFO - Training   - Loss: 0.8425, Accuracy: 0.7310, F1: 0.7333
2025-03-02 21:02:37,198 - INFO - Validation - Loss: 0.4499, Accuracy: 0.8656, F1: 0.8651
2025-03-02 21:02:37,198 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:37,198 - INFO - Epoch 17/30
2025-03-02 21:02:37,198 - INFO - ----------------------------------------
2025-03-02 21:02:37,390 - INFO - [TRAIN] Epoch: 17/30 | Batch: 0/452 (0.2%) | Loss: 0.8032 | Batch time: 0.03s
2025-03-02 21:02:38,627 - INFO - [TRAIN] Epoch: 17/30 | Batch: 45/452 (10.2%) | Loss: 0.7996 | Batch time: 0.02s
2025-03-02 21:02:39,804 - INFO - [TRAIN] Epoch: 17/30 | Batch: 90/452 (20.1%) | Loss: 0.5185 | Batch time: 0.03s
2025-03-02 21:02:40,980 - INFO - [TRAIN] Epoch: 17/30 | Batch: 135/452 (30.1%) | Loss: 1.0948 | Batch time: 0.03s
2025-03-02 21:02:42,181 - INFO - [TRAIN] Epoch: 17/30 | Batch: 180/452 (40.0%) | Loss: 1.3363 | Batch time: 0.02s
2025-03-02 21:02:43,338 - INFO - [TRAIN] Epoch: 17/30 | Batch: 225/452 (50.0%) | Loss: 1.2104 | Batch time: 0.02s
2025-03-02 21:02:44,460 - INFO - [TRAIN] Epoch: 17/30 | Batch: 270/452 (60.0%) | Loss: 0.6793 | Batch time: 0.02s
2025-03-02 21:02:45,597 - INFO - [TRAIN] Epoch: 17/30 | Batch: 315/452 (69.9%) | Loss: 0.9856 | Batch time: 0.02s
2025-03-02 21:02:46,722 - INFO - [TRAIN] Epoch: 17/30 | Batch: 360/452 (79.9%) | Loss: 0.6058 | Batch time: 0.02s
2025-03-02 21:02:47,911 - INFO - [TRAIN] Epoch: 17/30 | Batch: 405/452 (89.8%) | Loss: 1.1026 | Batch time: 0.03s
2025-03-02 21:02:48,907 - INFO - [TRAIN] Epoch: 17/30 | Batch: 450/452 (99.8%) | Loss: 0.8088 | Batch time: 0.02s
2025-03-02 21:02:48,920 - INFO - [TRAIN] Epoch: 17/30 | Batch: 451/452 (100.0%) | Loss: 1.4179 | Batch time: 0.01s
2025-03-02 21:02:49,012 - INFO - [VAL] Epoch: 17/30 | Batch: 0/97 (1.0%) | Loss: 0.3205 | Batch time: 0.02s
2025-03-02 21:02:49,150 - INFO - [VAL] Epoch: 17/30 | Batch: 9/97 (10.3%) | Loss: 0.5135 | Batch time: 0.01s
2025-03-02 21:02:49,282 - INFO - [VAL] Epoch: 17/30 | Batch: 18/97 (19.6%) | Loss: 0.2312 | Batch time: 0.01s
2025-03-02 21:02:49,407 - INFO - [VAL] Epoch: 17/30 | Batch: 27/97 (28.9%) | Loss: 0.4237 | Batch time: 0.01s
2025-03-02 21:02:49,532 - INFO - [VAL] Epoch: 17/30 | Batch: 36/97 (38.1%) | Loss: 0.4210 | Batch time: 0.01s
2025-03-02 21:02:49,660 - INFO - [VAL] Epoch: 17/30 | Batch: 45/97 (47.4%) | Loss: 0.3116 | Batch time: 0.01s
2025-03-02 21:02:49,786 - INFO - [VAL] Epoch: 17/30 | Batch: 54/97 (56.7%) | Loss: 0.4779 | Batch time: 0.01s
2025-03-02 21:02:49,916 - INFO - [VAL] Epoch: 17/30 | Batch: 63/97 (66.0%) | Loss: 0.3810 | Batch time: 0.01s
2025-03-02 21:02:50,041 - INFO - [VAL] Epoch: 17/30 | Batch: 72/97 (75.3%) | Loss: 0.4570 | Batch time: 0.01s
2025-03-02 21:02:50,164 - INFO - [VAL] Epoch: 17/30 | Batch: 81/97 (84.5%) | Loss: 0.2859 | Batch time: 0.01s
2025-03-02 21:02:50,290 - INFO - [VAL] Epoch: 17/30 | Batch: 90/97 (93.8%) | Loss: 0.5061 | Batch time: 0.01s
2025-03-02 21:02:50,371 - INFO - [VAL] Epoch: 17/30 | Batch: 96/97 (100.0%) | Loss: 0.5778 | Batch time: 0.01s
2025-03-02 21:02:50,374 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:50,374 - INFO - Epoch 17/30 completed in 13.18s
2025-03-02 21:02:50,374 - INFO - Training   - Loss: 0.8582, Accuracy: 0.7250, F1: 0.7279
2025-03-02 21:02:50,374 - INFO - Validation - Loss: 0.4519, Accuracy: 0.8640, F1: 0.8634
2025-03-02 21:02:50,374 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:02:50,374 - INFO - Epoch 18/30
2025-03-02 21:02:50,374 - INFO - ----------------------------------------
2025-03-02 21:02:50,617 - INFO - [TRAIN] Epoch: 18/30 | Batch: 0/452 (0.2%) | Loss: 0.9218 | Batch time: 0.06s
2025-03-02 21:02:52,229 - INFO - [TRAIN] Epoch: 18/30 | Batch: 45/452 (10.2%) | Loss: 1.4211 | Batch time: 0.03s
2025-03-02 21:02:53,458 - INFO - [TRAIN] Epoch: 18/30 | Batch: 90/452 (20.1%) | Loss: 0.7758 | Batch time: 0.02s
2025-03-02 21:02:54,572 - INFO - [TRAIN] Epoch: 18/30 | Batch: 135/452 (30.1%) | Loss: 0.4445 | Batch time: 0.02s
2025-03-02 21:02:55,739 - INFO - [TRAIN] Epoch: 18/30 | Batch: 180/452 (40.0%) | Loss: 0.9129 | Batch time: 0.03s
2025-03-02 21:02:56,884 - INFO - [TRAIN] Epoch: 18/30 | Batch: 225/452 (50.0%) | Loss: 0.5912 | Batch time: 0.03s
2025-03-02 21:02:58,129 - INFO - [TRAIN] Epoch: 18/30 | Batch: 270/452 (60.0%) | Loss: 0.6620 | Batch time: 0.02s
2025-03-02 21:02:59,330 - INFO - [TRAIN] Epoch: 18/30 | Batch: 315/452 (69.9%) | Loss: 0.6863 | Batch time: 0.02s
2025-03-02 21:03:00,520 - INFO - [TRAIN] Epoch: 18/30 | Batch: 360/452 (79.9%) | Loss: 1.1968 | Batch time: 0.02s
2025-03-02 21:03:01,618 - INFO - [TRAIN] Epoch: 18/30 | Batch: 405/452 (89.8%) | Loss: 1.4492 | Batch time: 0.02s
2025-03-02 21:03:02,573 - INFO - [TRAIN] Epoch: 18/30 | Batch: 450/452 (99.8%) | Loss: 1.1447 | Batch time: 0.02s
2025-03-02 21:03:02,586 - INFO - [TRAIN] Epoch: 18/30 | Batch: 451/452 (100.0%) | Loss: 0.3768 | Batch time: 0.01s
2025-03-02 21:03:02,670 - INFO - [VAL] Epoch: 18/30 | Batch: 0/97 (1.0%) | Loss: 0.3331 | Batch time: 0.02s
2025-03-02 21:03:02,807 - INFO - [VAL] Epoch: 18/30 | Batch: 9/97 (10.3%) | Loss: 0.4843 | Batch time: 0.01s
2025-03-02 21:03:02,932 - INFO - [VAL] Epoch: 18/30 | Batch: 18/97 (19.6%) | Loss: 0.2538 | Batch time: 0.01s
2025-03-02 21:03:03,058 - INFO - [VAL] Epoch: 18/30 | Batch: 27/97 (28.9%) | Loss: 0.4234 | Batch time: 0.01s
2025-03-02 21:03:03,185 - INFO - [VAL] Epoch: 18/30 | Batch: 36/97 (38.1%) | Loss: 0.3514 | Batch time: 0.01s
2025-03-02 21:03:03,313 - INFO - [VAL] Epoch: 18/30 | Batch: 45/97 (47.4%) | Loss: 0.3135 | Batch time: 0.01s
2025-03-02 21:03:03,441 - INFO - [VAL] Epoch: 18/30 | Batch: 54/97 (56.7%) | Loss: 0.4648 | Batch time: 0.01s
2025-03-02 21:03:03,568 - INFO - [VAL] Epoch: 18/30 | Batch: 63/97 (66.0%) | Loss: 0.3658 | Batch time: 0.01s
2025-03-02 21:03:03,694 - INFO - [VAL] Epoch: 18/30 | Batch: 72/97 (75.3%) | Loss: 0.4571 | Batch time: 0.01s
2025-03-02 21:03:03,819 - INFO - [VAL] Epoch: 18/30 | Batch: 81/97 (84.5%) | Loss: 0.2836 | Batch time: 0.01s
2025-03-02 21:03:03,944 - INFO - [VAL] Epoch: 18/30 | Batch: 90/97 (93.8%) | Loss: 0.4783 | Batch time: 0.01s
2025-03-02 21:03:04,023 - INFO - [VAL] Epoch: 18/30 | Batch: 96/97 (100.0%) | Loss: 0.5278 | Batch time: 0.01s
2025-03-02 21:03:04,026 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:04,026 - INFO - Epoch 18/30 completed in 13.65s
2025-03-02 21:03:04,026 - INFO - Training   - Loss: 0.8496, Accuracy: 0.7240, F1: 0.7272
2025-03-02 21:03:04,026 - INFO - Validation - Loss: 0.4470, Accuracy: 0.8666, F1: 0.8660
2025-03-02 21:03:04,026 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:04,026 - INFO - Epoch 19/30
2025-03-02 21:03:04,026 - INFO - ----------------------------------------
2025-03-02 21:03:04,268 - INFO - [TRAIN] Epoch: 19/30 | Batch: 0/452 (0.2%) | Loss: 0.7798 | Batch time: 0.04s
2025-03-02 21:03:05,443 - INFO - [TRAIN] Epoch: 19/30 | Batch: 45/452 (10.2%) | Loss: 0.8045 | Batch time: 0.03s
2025-03-02 21:03:06,606 - INFO - [TRAIN] Epoch: 19/30 | Batch: 90/452 (20.1%) | Loss: 1.2078 | Batch time: 0.03s
2025-03-02 21:03:07,798 - INFO - [TRAIN] Epoch: 19/30 | Batch: 135/452 (30.1%) | Loss: 0.4691 | Batch time: 0.02s
2025-03-02 21:03:08,972 - INFO - [TRAIN] Epoch: 19/30 | Batch: 180/452 (40.0%) | Loss: 0.6526 | Batch time: 0.02s
2025-03-02 21:03:10,150 - INFO - [TRAIN] Epoch: 19/30 | Batch: 225/452 (50.0%) | Loss: 1.1054 | Batch time: 0.03s
2025-03-02 21:03:11,281 - INFO - [TRAIN] Epoch: 19/30 | Batch: 270/452 (60.0%) | Loss: 0.8233 | Batch time: 0.02s
2025-03-02 21:03:12,441 - INFO - [TRAIN] Epoch: 19/30 | Batch: 315/452 (69.9%) | Loss: 1.2770 | Batch time: 0.03s
2025-03-02 21:03:13,576 - INFO - [TRAIN] Epoch: 19/30 | Batch: 360/452 (79.9%) | Loss: 0.9323 | Batch time: 0.02s
2025-03-02 21:03:14,779 - INFO - [TRAIN] Epoch: 19/30 | Batch: 405/452 (89.8%) | Loss: 0.6775 | Batch time: 0.03s
2025-03-02 21:03:15,753 - INFO - [TRAIN] Epoch: 19/30 | Batch: 450/452 (99.8%) | Loss: 0.6164 | Batch time: 0.02s
2025-03-02 21:03:15,765 - INFO - [TRAIN] Epoch: 19/30 | Batch: 451/452 (100.0%) | Loss: 0.8902 | Batch time: 0.01s
2025-03-02 21:03:15,850 - INFO - [VAL] Epoch: 19/30 | Batch: 0/97 (1.0%) | Loss: 0.3010 | Batch time: 0.02s
2025-03-02 21:03:15,985 - INFO - [VAL] Epoch: 19/30 | Batch: 9/97 (10.3%) | Loss: 0.4686 | Batch time: 0.01s
2025-03-02 21:03:16,111 - INFO - [VAL] Epoch: 19/30 | Batch: 18/97 (19.6%) | Loss: 0.2522 | Batch time: 0.01s
2025-03-02 21:03:16,242 - INFO - [VAL] Epoch: 19/30 | Batch: 27/97 (28.9%) | Loss: 0.4425 | Batch time: 0.02s
2025-03-02 21:03:16,367 - INFO - [VAL] Epoch: 19/30 | Batch: 36/97 (38.1%) | Loss: 0.3783 | Batch time: 0.01s
2025-03-02 21:03:16,495 - INFO - [VAL] Epoch: 19/30 | Batch: 45/97 (47.4%) | Loss: 0.2914 | Batch time: 0.01s
2025-03-02 21:03:16,623 - INFO - [VAL] Epoch: 19/30 | Batch: 54/97 (56.7%) | Loss: 0.4845 | Batch time: 0.01s
2025-03-02 21:03:16,750 - INFO - [VAL] Epoch: 19/30 | Batch: 63/97 (66.0%) | Loss: 0.3683 | Batch time: 0.01s
2025-03-02 21:03:16,874 - INFO - [VAL] Epoch: 19/30 | Batch: 72/97 (75.3%) | Loss: 0.4194 | Batch time: 0.01s
2025-03-02 21:03:16,998 - INFO - [VAL] Epoch: 19/30 | Batch: 81/97 (84.5%) | Loss: 0.2929 | Batch time: 0.01s
2025-03-02 21:03:17,122 - INFO - [VAL] Epoch: 19/30 | Batch: 90/97 (93.8%) | Loss: 0.4973 | Batch time: 0.01s
2025-03-02 21:03:17,202 - INFO - [VAL] Epoch: 19/30 | Batch: 96/97 (100.0%) | Loss: 0.5145 | Batch time: 0.01s
2025-03-02 21:03:17,206 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:17,206 - INFO - Epoch 19/30 completed in 13.18s
2025-03-02 21:03:17,206 - INFO - Training   - Loss: 0.8382, Accuracy: 0.7292, F1: 0.7319
2025-03-02 21:03:17,206 - INFO - Validation - Loss: 0.4468, Accuracy: 0.8660, F1: 0.8657
2025-03-02 21:03:17,206 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:17,206 - INFO - Epoch 20/30
2025-03-02 21:03:17,206 - INFO - ----------------------------------------
2025-03-02 21:03:17,393 - INFO - [TRAIN] Epoch: 20/30 | Batch: 0/452 (0.2%) | Loss: 0.7489 | Batch time: 0.03s
2025-03-02 21:03:18,766 - INFO - [TRAIN] Epoch: 20/30 | Batch: 45/452 (10.2%) | Loss: 0.7845 | Batch time: 0.03s
2025-03-02 21:03:19,973 - INFO - [TRAIN] Epoch: 20/30 | Batch: 90/452 (20.1%) | Loss: 0.7148 | Batch time: 0.03s
2025-03-02 21:03:21,147 - INFO - [TRAIN] Epoch: 20/30 | Batch: 135/452 (30.1%) | Loss: 0.8876 | Batch time: 0.03s
2025-03-02 21:03:22,361 - INFO - [TRAIN] Epoch: 20/30 | Batch: 180/452 (40.0%) | Loss: 1.1638 | Batch time: 0.03s
2025-03-02 21:03:23,608 - INFO - [TRAIN] Epoch: 20/30 | Batch: 225/452 (50.0%) | Loss: 0.7814 | Batch time: 0.03s
2025-03-02 21:03:24,830 - INFO - [TRAIN] Epoch: 20/30 | Batch: 270/452 (60.0%) | Loss: 0.7997 | Batch time: 0.03s
2025-03-02 21:03:26,057 - INFO - [TRAIN] Epoch: 20/30 | Batch: 315/452 (69.9%) | Loss: 0.5903 | Batch time: 0.03s
2025-03-02 21:03:27,288 - INFO - [TRAIN] Epoch: 20/30 | Batch: 360/452 (79.9%) | Loss: 0.4965 | Batch time: 0.02s
2025-03-02 21:03:28,499 - INFO - [TRAIN] Epoch: 20/30 | Batch: 405/452 (89.8%) | Loss: 0.8043 | Batch time: 0.03s
2025-03-02 21:03:29,489 - INFO - [TRAIN] Epoch: 20/30 | Batch: 450/452 (99.8%) | Loss: 1.0621 | Batch time: 0.02s
2025-03-02 21:03:29,502 - INFO - [TRAIN] Epoch: 20/30 | Batch: 451/452 (100.0%) | Loss: 1.4025 | Batch time: 0.01s
2025-03-02 21:03:29,588 - INFO - [VAL] Epoch: 20/30 | Batch: 0/97 (1.0%) | Loss: 0.3392 | Batch time: 0.02s
2025-03-02 21:03:29,727 - INFO - [VAL] Epoch: 20/30 | Batch: 9/97 (10.3%) | Loss: 0.5000 | Batch time: 0.01s
2025-03-02 21:03:29,852 - INFO - [VAL] Epoch: 20/30 | Batch: 18/97 (19.6%) | Loss: 0.2351 | Batch time: 0.01s
2025-03-02 21:03:29,977 - INFO - [VAL] Epoch: 20/30 | Batch: 27/97 (28.9%) | Loss: 0.4279 | Batch time: 0.01s
2025-03-02 21:03:30,103 - INFO - [VAL] Epoch: 20/30 | Batch: 36/97 (38.1%) | Loss: 0.4173 | Batch time: 0.01s
2025-03-02 21:03:30,231 - INFO - [VAL] Epoch: 20/30 | Batch: 45/97 (47.4%) | Loss: 0.3035 | Batch time: 0.01s
2025-03-02 21:03:30,364 - INFO - [VAL] Epoch: 20/30 | Batch: 54/97 (56.7%) | Loss: 0.4694 | Batch time: 0.01s
2025-03-02 21:03:30,493 - INFO - [VAL] Epoch: 20/30 | Batch: 63/97 (66.0%) | Loss: 0.3542 | Batch time: 0.01s
2025-03-02 21:03:30,620 - INFO - [VAL] Epoch: 20/30 | Batch: 72/97 (75.3%) | Loss: 0.5097 | Batch time: 0.01s
2025-03-02 21:03:30,744 - INFO - [VAL] Epoch: 20/30 | Batch: 81/97 (84.5%) | Loss: 0.2807 | Batch time: 0.01s
2025-03-02 21:03:30,869 - INFO - [VAL] Epoch: 20/30 | Batch: 90/97 (93.8%) | Loss: 0.4837 | Batch time: 0.01s
2025-03-02 21:03:30,948 - INFO - [VAL] Epoch: 20/30 | Batch: 96/97 (100.0%) | Loss: 0.5530 | Batch time: 0.01s
2025-03-02 21:03:30,952 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:30,952 - INFO - Epoch 20/30 completed in 13.75s
2025-03-02 21:03:30,952 - INFO - Training   - Loss: 0.8314, Accuracy: 0.7280, F1: 0.7309
2025-03-02 21:03:30,952 - INFO - Validation - Loss: 0.4502, Accuracy: 0.8624, F1: 0.8619
2025-03-02 21:03:30,952 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:31,015 - INFO - Checkpoint saved: checkpoint_epoch_20.pth (Epoch 20)
2025-03-02 21:03:31,015 - INFO - Epoch 21/30
2025-03-02 21:03:31,015 - INFO - ----------------------------------------
2025-03-02 21:03:31,230 - INFO - [TRAIN] Epoch: 21/30 | Batch: 0/452 (0.2%) | Loss: 0.6271 | Batch time: 0.03s
2025-03-02 21:03:32,598 - INFO - [TRAIN] Epoch: 21/30 | Batch: 45/452 (10.2%) | Loss: 0.5479 | Batch time: 0.03s
2025-03-02 21:03:33,779 - INFO - [TRAIN] Epoch: 21/30 | Batch: 90/452 (20.1%) | Loss: 0.7960 | Batch time: 0.03s
2025-03-02 21:03:34,980 - INFO - [TRAIN] Epoch: 21/30 | Batch: 135/452 (30.1%) | Loss: 0.9271 | Batch time: 0.02s
2025-03-02 21:03:36,226 - INFO - [TRAIN] Epoch: 21/30 | Batch: 180/452 (40.0%) | Loss: 0.5986 | Batch time: 0.03s
2025-03-02 21:03:37,678 - INFO - [TRAIN] Epoch: 21/30 | Batch: 225/452 (50.0%) | Loss: 0.9927 | Batch time: 0.03s
2025-03-02 21:03:38,894 - INFO - [TRAIN] Epoch: 21/30 | Batch: 270/452 (60.0%) | Loss: 0.8250 | Batch time: 0.02s
2025-03-02 21:03:40,111 - INFO - [TRAIN] Epoch: 21/30 | Batch: 315/452 (69.9%) | Loss: 0.7654 | Batch time: 0.03s
2025-03-02 21:03:41,376 - INFO - [TRAIN] Epoch: 21/30 | Batch: 360/452 (79.9%) | Loss: 0.8088 | Batch time: 0.03s
2025-03-02 21:03:42,617 - INFO - [TRAIN] Epoch: 21/30 | Batch: 405/452 (89.8%) | Loss: 0.7287 | Batch time: 0.03s
2025-03-02 21:03:43,571 - INFO - [TRAIN] Epoch: 21/30 | Batch: 450/452 (99.8%) | Loss: 1.0399 | Batch time: 0.02s
2025-03-02 21:03:43,584 - INFO - [TRAIN] Epoch: 21/30 | Batch: 451/452 (100.0%) | Loss: 0.8263 | Batch time: 0.01s
2025-03-02 21:03:43,671 - INFO - [VAL] Epoch: 21/30 | Batch: 0/97 (1.0%) | Loss: 0.3317 | Batch time: 0.02s
2025-03-02 21:03:43,811 - INFO - [VAL] Epoch: 21/30 | Batch: 9/97 (10.3%) | Loss: 0.5482 | Batch time: 0.01s
2025-03-02 21:03:43,937 - INFO - [VAL] Epoch: 21/30 | Batch: 18/97 (19.6%) | Loss: 0.2156 | Batch time: 0.01s
2025-03-02 21:03:44,064 - INFO - [VAL] Epoch: 21/30 | Batch: 27/97 (28.9%) | Loss: 0.4254 | Batch time: 0.01s
2025-03-02 21:03:44,192 - INFO - [VAL] Epoch: 21/30 | Batch: 36/97 (38.1%) | Loss: 0.4255 | Batch time: 0.01s
2025-03-02 21:03:44,319 - INFO - [VAL] Epoch: 21/30 | Batch: 45/97 (47.4%) | Loss: 0.2828 | Batch time: 0.01s
2025-03-02 21:03:44,448 - INFO - [VAL] Epoch: 21/30 | Batch: 54/97 (56.7%) | Loss: 0.4692 | Batch time: 0.01s
2025-03-02 21:03:44,578 - INFO - [VAL] Epoch: 21/30 | Batch: 63/97 (66.0%) | Loss: 0.3920 | Batch time: 0.01s
2025-03-02 21:03:44,705 - INFO - [VAL] Epoch: 21/30 | Batch: 72/97 (75.3%) | Loss: 0.4727 | Batch time: 0.01s
2025-03-02 21:03:44,831 - INFO - [VAL] Epoch: 21/30 | Batch: 81/97 (84.5%) | Loss: 0.3044 | Batch time: 0.01s
2025-03-02 21:03:44,956 - INFO - [VAL] Epoch: 21/30 | Batch: 90/97 (93.8%) | Loss: 0.5559 | Batch time: 0.01s
2025-03-02 21:03:45,037 - INFO - [VAL] Epoch: 21/30 | Batch: 96/97 (100.0%) | Loss: 0.6023 | Batch time: 0.01s
2025-03-02 21:03:45,040 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:45,040 - INFO - Epoch 21/30 completed in 14.03s
2025-03-02 21:03:45,040 - INFO - Training   - Loss: 0.8539, Accuracy: 0.7324, F1: 0.7355
2025-03-02 21:03:45,040 - INFO - Validation - Loss: 0.4540, Accuracy: 0.8611, F1: 0.8602
2025-03-02 21:03:45,040 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:45,040 - INFO - Epoch 22/30
2025-03-02 21:03:45,040 - INFO - ----------------------------------------
2025-03-02 21:03:45,239 - INFO - [TRAIN] Epoch: 22/30 | Batch: 0/452 (0.2%) | Loss: 0.4772 | Batch time: 0.03s
2025-03-02 21:03:46,567 - INFO - [TRAIN] Epoch: 22/30 | Batch: 45/452 (10.2%) | Loss: 0.8469 | Batch time: 0.03s
2025-03-02 21:03:47,829 - INFO - [TRAIN] Epoch: 22/30 | Batch: 90/452 (20.1%) | Loss: 0.6459 | Batch time: 0.04s
2025-03-02 21:03:49,086 - INFO - [TRAIN] Epoch: 22/30 | Batch: 135/452 (30.1%) | Loss: 0.7191 | Batch time: 0.03s
2025-03-02 21:03:50,372 - INFO - [TRAIN] Epoch: 22/30 | Batch: 180/452 (40.0%) | Loss: 0.8365 | Batch time: 0.02s
2025-03-02 21:03:51,629 - INFO - [TRAIN] Epoch: 22/30 | Batch: 225/452 (50.0%) | Loss: 0.4994 | Batch time: 0.02s
2025-03-02 21:03:52,912 - INFO - [TRAIN] Epoch: 22/30 | Batch: 270/452 (60.0%) | Loss: 0.4779 | Batch time: 0.03s
2025-03-02 21:03:54,155 - INFO - [TRAIN] Epoch: 22/30 | Batch: 315/452 (69.9%) | Loss: 0.9577 | Batch time: 0.02s
2025-03-02 21:03:55,407 - INFO - [TRAIN] Epoch: 22/30 | Batch: 360/452 (79.9%) | Loss: 1.0528 | Batch time: 0.03s
2025-03-02 21:03:56,703 - INFO - [TRAIN] Epoch: 22/30 | Batch: 405/452 (89.8%) | Loss: 0.8633 | Batch time: 0.03s
2025-03-02 21:03:57,704 - INFO - [TRAIN] Epoch: 22/30 | Batch: 450/452 (99.8%) | Loss: 0.6422 | Batch time: 0.02s
2025-03-02 21:03:57,717 - INFO - [TRAIN] Epoch: 22/30 | Batch: 451/452 (100.0%) | Loss: 1.1885 | Batch time: 0.01s
2025-03-02 21:03:57,808 - INFO - [VAL] Epoch: 22/30 | Batch: 0/97 (1.0%) | Loss: 0.2631 | Batch time: 0.02s
2025-03-02 21:03:57,936 - INFO - [VAL] Epoch: 22/30 | Batch: 9/97 (10.3%) | Loss: 0.4759 | Batch time: 0.01s
2025-03-02 21:03:58,062 - INFO - [VAL] Epoch: 22/30 | Batch: 18/97 (19.6%) | Loss: 0.2172 | Batch time: 0.01s
2025-03-02 21:03:58,188 - INFO - [VAL] Epoch: 22/30 | Batch: 27/97 (28.9%) | Loss: 0.3811 | Batch time: 0.01s
2025-03-02 21:03:58,315 - INFO - [VAL] Epoch: 22/30 | Batch: 36/97 (38.1%) | Loss: 0.3918 | Batch time: 0.01s
2025-03-02 21:03:58,443 - INFO - [VAL] Epoch: 22/30 | Batch: 45/97 (47.4%) | Loss: 0.3000 | Batch time: 0.01s
2025-03-02 21:03:58,573 - INFO - [VAL] Epoch: 22/30 | Batch: 54/97 (56.7%) | Loss: 0.4472 | Batch time: 0.01s
2025-03-02 21:03:58,703 - INFO - [VAL] Epoch: 22/30 | Batch: 63/97 (66.0%) | Loss: 0.3076 | Batch time: 0.01s
2025-03-02 21:03:58,830 - INFO - [VAL] Epoch: 22/30 | Batch: 72/97 (75.3%) | Loss: 0.4436 | Batch time: 0.01s
2025-03-02 21:03:58,957 - INFO - [VAL] Epoch: 22/30 | Batch: 81/97 (84.5%) | Loss: 0.2818 | Batch time: 0.01s
2025-03-02 21:03:59,083 - INFO - [VAL] Epoch: 22/30 | Batch: 90/97 (93.8%) | Loss: 0.4493 | Batch time: 0.01s
2025-03-02 21:03:59,164 - INFO - [VAL] Epoch: 22/30 | Batch: 96/97 (100.0%) | Loss: 0.5463 | Batch time: 0.01s
2025-03-02 21:03:59,167 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:59,167 - INFO - Epoch 22/30 completed in 14.13s
2025-03-02 21:03:59,167 - INFO - Training   - Loss: 0.8533, Accuracy: 0.7241, F1: 0.7278
2025-03-02 21:03:59,167 - INFO - Validation - Loss: 0.4259, Accuracy: 0.8718, F1: 0.8711
2025-03-02 21:03:59,167 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:03:59,167 - INFO - Epoch 23/30
2025-03-02 21:03:59,167 - INFO - ----------------------------------------
2025-03-02 21:03:59,396 - INFO - [TRAIN] Epoch: 23/30 | Batch: 0/452 (0.2%) | Loss: 0.6230 | Batch time: 0.03s
2025-03-02 21:04:00,762 - INFO - [TRAIN] Epoch: 23/30 | Batch: 45/452 (10.2%) | Loss: 0.8017 | Batch time: 0.03s
2025-03-02 21:04:02,047 - INFO - [TRAIN] Epoch: 23/30 | Batch: 90/452 (20.1%) | Loss: 0.6088 | Batch time: 0.03s
2025-03-02 21:04:03,265 - INFO - [TRAIN] Epoch: 23/30 | Batch: 135/452 (30.1%) | Loss: 0.8413 | Batch time: 0.03s
2025-03-02 21:04:04,495 - INFO - [TRAIN] Epoch: 23/30 | Batch: 180/452 (40.0%) | Loss: 0.8734 | Batch time: 0.03s
2025-03-02 21:04:05,743 - INFO - [TRAIN] Epoch: 23/30 | Batch: 225/452 (50.0%) | Loss: 1.1863 | Batch time: 0.03s
2025-03-02 21:04:07,005 - INFO - [TRAIN] Epoch: 23/30 | Batch: 270/452 (60.0%) | Loss: 0.5019 | Batch time: 0.03s
2025-03-02 21:04:08,260 - INFO - [TRAIN] Epoch: 23/30 | Batch: 315/452 (69.9%) | Loss: 1.0368 | Batch time: 0.03s
2025-03-02 21:04:09,601 - INFO - [TRAIN] Epoch: 23/30 | Batch: 360/452 (79.9%) | Loss: 0.8509 | Batch time: 0.03s
2025-03-02 21:04:10,940 - INFO - [TRAIN] Epoch: 23/30 | Batch: 405/452 (89.8%) | Loss: 0.8243 | Batch time: 0.03s
2025-03-02 21:04:11,967 - INFO - [TRAIN] Epoch: 23/30 | Batch: 450/452 (99.8%) | Loss: 0.9883 | Batch time: 0.02s
2025-03-02 21:04:11,982 - INFO - [TRAIN] Epoch: 23/30 | Batch: 451/452 (100.0%) | Loss: 1.5295 | Batch time: 0.01s
2025-03-02 21:04:12,071 - INFO - [VAL] Epoch: 23/30 | Batch: 0/97 (1.0%) | Loss: 0.3143 | Batch time: 0.02s
2025-03-02 21:04:12,212 - INFO - [VAL] Epoch: 23/30 | Batch: 9/97 (10.3%) | Loss: 0.5003 | Batch time: 0.01s
2025-03-02 21:04:12,339 - INFO - [VAL] Epoch: 23/30 | Batch: 18/97 (19.6%) | Loss: 0.2300 | Batch time: 0.01s
2025-03-02 21:04:12,465 - INFO - [VAL] Epoch: 23/30 | Batch: 27/97 (28.9%) | Loss: 0.4060 | Batch time: 0.01s
2025-03-02 21:04:12,592 - INFO - [VAL] Epoch: 23/30 | Batch: 36/97 (38.1%) | Loss: 0.3672 | Batch time: 0.01s
2025-03-02 21:04:12,721 - INFO - [VAL] Epoch: 23/30 | Batch: 45/97 (47.4%) | Loss: 0.2958 | Batch time: 0.01s
2025-03-02 21:04:12,850 - INFO - [VAL] Epoch: 23/30 | Batch: 54/97 (56.7%) | Loss: 0.4556 | Batch time: 0.01s
2025-03-02 21:04:12,980 - INFO - [VAL] Epoch: 23/30 | Batch: 63/97 (66.0%) | Loss: 0.3448 | Batch time: 0.01s
2025-03-02 21:04:13,108 - INFO - [VAL] Epoch: 23/30 | Batch: 72/97 (75.3%) | Loss: 0.4650 | Batch time: 0.01s
2025-03-02 21:04:13,235 - INFO - [VAL] Epoch: 23/30 | Batch: 81/97 (84.5%) | Loss: 0.2845 | Batch time: 0.01s
2025-03-02 21:04:13,369 - INFO - [VAL] Epoch: 23/30 | Batch: 90/97 (93.8%) | Loss: 0.4426 | Batch time: 0.02s
2025-03-02 21:04:13,451 - INFO - [VAL] Epoch: 23/30 | Batch: 96/97 (100.0%) | Loss: 0.5372 | Batch time: 0.01s
2025-03-02 21:04:13,454 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:13,454 - INFO - Epoch 23/30 completed in 14.29s
2025-03-02 21:04:13,454 - INFO - Training   - Loss: 0.8471, Accuracy: 0.7240, F1: 0.7270
2025-03-02 21:04:13,455 - INFO - Validation - Loss: 0.4410, Accuracy: 0.8647, F1: 0.8643
2025-03-02 21:04:13,455 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:13,455 - INFO - Epoch 24/30
2025-03-02 21:04:13,455 - INFO - ----------------------------------------
2025-03-02 21:04:13,681 - INFO - [TRAIN] Epoch: 24/30 | Batch: 0/452 (0.2%) | Loss: 1.0412 | Batch time: 0.03s
2025-03-02 21:04:15,264 - INFO - [TRAIN] Epoch: 24/30 | Batch: 45/452 (10.2%) | Loss: 0.6413 | Batch time: 0.03s
2025-03-02 21:04:16,484 - INFO - [TRAIN] Epoch: 24/30 | Batch: 90/452 (20.1%) | Loss: 0.7009 | Batch time: 0.03s
2025-03-02 21:04:17,684 - INFO - [TRAIN] Epoch: 24/30 | Batch: 135/452 (30.1%) | Loss: 0.8305 | Batch time: 0.03s
2025-03-02 21:04:18,965 - INFO - [TRAIN] Epoch: 24/30 | Batch: 180/452 (40.0%) | Loss: 0.8760 | Batch time: 0.03s
2025-03-02 21:04:20,288 - INFO - [TRAIN] Epoch: 24/30 | Batch: 225/452 (50.0%) | Loss: 0.5176 | Batch time: 0.03s
2025-03-02 21:04:21,574 - INFO - [TRAIN] Epoch: 24/30 | Batch: 270/452 (60.0%) | Loss: 0.7121 | Batch time: 0.03s
2025-03-02 21:04:22,857 - INFO - [TRAIN] Epoch: 24/30 | Batch: 315/452 (69.9%) | Loss: 1.1510 | Batch time: 0.03s
2025-03-02 21:04:24,151 - INFO - [TRAIN] Epoch: 24/30 | Batch: 360/452 (79.9%) | Loss: 0.3507 | Batch time: 0.03s
2025-03-02 21:04:25,437 - INFO - [TRAIN] Epoch: 24/30 | Batch: 405/452 (89.8%) | Loss: 1.0486 | Batch time: 0.03s
2025-03-02 21:04:26,422 - INFO - [TRAIN] Epoch: 24/30 | Batch: 450/452 (99.8%) | Loss: 1.2022 | Batch time: 0.02s
2025-03-02 21:04:26,436 - INFO - [TRAIN] Epoch: 24/30 | Batch: 451/452 (100.0%) | Loss: 0.8848 | Batch time: 0.01s
2025-03-02 21:04:26,521 - INFO - [VAL] Epoch: 24/30 | Batch: 0/97 (1.0%) | Loss: 0.3319 | Batch time: 0.02s
2025-03-02 21:04:26,659 - INFO - [VAL] Epoch: 24/30 | Batch: 9/97 (10.3%) | Loss: 0.4626 | Batch time: 0.01s
2025-03-02 21:04:26,785 - INFO - [VAL] Epoch: 24/30 | Batch: 18/97 (19.6%) | Loss: 0.2521 | Batch time: 0.01s
2025-03-02 21:04:26,911 - INFO - [VAL] Epoch: 24/30 | Batch: 27/97 (28.9%) | Loss: 0.4548 | Batch time: 0.01s
2025-03-02 21:04:27,038 - INFO - [VAL] Epoch: 24/30 | Batch: 36/97 (38.1%) | Loss: 0.3927 | Batch time: 0.01s
2025-03-02 21:04:27,165 - INFO - [VAL] Epoch: 24/30 | Batch: 45/97 (47.4%) | Loss: 0.3193 | Batch time: 0.01s
2025-03-02 21:04:27,294 - INFO - [VAL] Epoch: 24/30 | Batch: 54/97 (56.7%) | Loss: 0.4845 | Batch time: 0.01s
2025-03-02 21:04:27,423 - INFO - [VAL] Epoch: 24/30 | Batch: 63/97 (66.0%) | Loss: 0.3961 | Batch time: 0.01s
2025-03-02 21:04:27,548 - INFO - [VAL] Epoch: 24/30 | Batch: 72/97 (75.3%) | Loss: 0.5062 | Batch time: 0.01s
2025-03-02 21:04:27,672 - INFO - [VAL] Epoch: 24/30 | Batch: 81/97 (84.5%) | Loss: 0.2650 | Batch time: 0.01s
2025-03-02 21:04:27,797 - INFO - [VAL] Epoch: 24/30 | Batch: 90/97 (93.8%) | Loss: 0.4715 | Batch time: 0.01s
2025-03-02 21:04:27,878 - INFO - [VAL] Epoch: 24/30 | Batch: 96/97 (100.0%) | Loss: 0.5022 | Batch time: 0.01s
2025-03-02 21:04:27,881 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:27,881 - INFO - Epoch 24/30 completed in 14.43s
2025-03-02 21:04:27,881 - INFO - Training   - Loss: 0.8402, Accuracy: 0.7295, F1: 0.7325
2025-03-02 21:04:27,881 - INFO - Validation - Loss: 0.4616, Accuracy: 0.8585, F1: 0.8585
2025-03-02 21:04:27,881 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:27,881 - INFO - Epoch 25/30
2025-03-02 21:04:27,881 - INFO - ----------------------------------------
2025-03-02 21:04:28,113 - INFO - [TRAIN] Epoch: 25/30 | Batch: 0/452 (0.2%) | Loss: 0.6520 | Batch time: 0.04s
2025-03-02 21:04:29,577 - INFO - [TRAIN] Epoch: 25/30 | Batch: 45/452 (10.2%) | Loss: 1.2814 | Batch time: 0.03s
2025-03-02 21:04:30,833 - INFO - [TRAIN] Epoch: 25/30 | Batch: 90/452 (20.1%) | Loss: 1.0626 | Batch time: 0.03s
2025-03-02 21:04:32,103 - INFO - [TRAIN] Epoch: 25/30 | Batch: 135/452 (30.1%) | Loss: 0.7781 | Batch time: 0.02s
2025-03-02 21:04:33,348 - INFO - [TRAIN] Epoch: 25/30 | Batch: 180/452 (40.0%) | Loss: 1.1850 | Batch time: 0.03s
2025-03-02 21:04:34,707 - INFO - [TRAIN] Epoch: 25/30 | Batch: 225/452 (50.0%) | Loss: 0.7186 | Batch time: 0.03s
2025-03-02 21:04:36,042 - INFO - [TRAIN] Epoch: 25/30 | Batch: 270/452 (60.0%) | Loss: 0.8441 | Batch time: 0.03s
2025-03-02 21:04:37,364 - INFO - [TRAIN] Epoch: 25/30 | Batch: 315/452 (69.9%) | Loss: 0.7353 | Batch time: 0.03s
2025-03-02 21:04:38,676 - INFO - [TRAIN] Epoch: 25/30 | Batch: 360/452 (79.9%) | Loss: 0.4435 | Batch time: 0.03s
2025-03-02 21:04:39,984 - INFO - [TRAIN] Epoch: 25/30 | Batch: 405/452 (89.8%) | Loss: 0.9172 | Batch time: 0.03s
2025-03-02 21:04:41,010 - INFO - [TRAIN] Epoch: 25/30 | Batch: 450/452 (99.8%) | Loss: 0.5323 | Batch time: 0.02s
2025-03-02 21:04:41,024 - INFO - [TRAIN] Epoch: 25/30 | Batch: 451/452 (100.0%) | Loss: 0.2690 | Batch time: 0.01s
2025-03-02 21:04:41,121 - INFO - [VAL] Epoch: 25/30 | Batch: 0/97 (1.0%) | Loss: 0.3069 | Batch time: 0.02s
2025-03-02 21:04:41,265 - INFO - [VAL] Epoch: 25/30 | Batch: 9/97 (10.3%) | Loss: 0.4513 | Batch time: 0.01s
2025-03-02 21:04:41,390 - INFO - [VAL] Epoch: 25/30 | Batch: 18/97 (19.6%) | Loss: 0.2712 | Batch time: 0.01s
2025-03-02 21:04:41,517 - INFO - [VAL] Epoch: 25/30 | Batch: 27/97 (28.9%) | Loss: 0.4571 | Batch time: 0.01s
2025-03-02 21:04:41,647 - INFO - [VAL] Epoch: 25/30 | Batch: 36/97 (38.1%) | Loss: 0.3709 | Batch time: 0.01s
2025-03-02 21:04:41,779 - INFO - [VAL] Epoch: 25/30 | Batch: 45/97 (47.4%) | Loss: 0.3244 | Batch time: 0.01s
2025-03-02 21:04:41,913 - INFO - [VAL] Epoch: 25/30 | Batch: 54/97 (56.7%) | Loss: 0.5106 | Batch time: 0.01s
2025-03-02 21:04:42,045 - INFO - [VAL] Epoch: 25/30 | Batch: 63/97 (66.0%) | Loss: 0.3233 | Batch time: 0.01s
2025-03-02 21:04:42,173 - INFO - [VAL] Epoch: 25/30 | Batch: 72/97 (75.3%) | Loss: 0.4732 | Batch time: 0.01s
2025-03-02 21:04:42,301 - INFO - [VAL] Epoch: 25/30 | Batch: 81/97 (84.5%) | Loss: 0.3016 | Batch time: 0.01s
2025-03-02 21:04:42,429 - INFO - [VAL] Epoch: 25/30 | Batch: 90/97 (93.8%) | Loss: 0.4339 | Batch time: 0.01s
2025-03-02 21:04:42,513 - INFO - [VAL] Epoch: 25/30 | Batch: 96/97 (100.0%) | Loss: 0.5318 | Batch time: 0.01s
2025-03-02 21:04:42,516 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:42,516 - INFO - Epoch 25/30 completed in 14.64s
2025-03-02 21:04:42,516 - INFO - Training   - Loss: 0.8535, Accuracy: 0.7235, F1: 0.7265
2025-03-02 21:04:42,516 - INFO - Validation - Loss: 0.4547, Accuracy: 0.8621, F1: 0.8616
2025-03-02 21:04:42,517 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:42,580 - INFO - Checkpoint saved: checkpoint_epoch_25.pth (Epoch 25)
2025-03-02 21:04:42,580 - INFO - Epoch 26/30
2025-03-02 21:04:42,580 - INFO - ----------------------------------------
2025-03-02 21:04:42,833 - INFO - [TRAIN] Epoch: 26/30 | Batch: 0/452 (0.2%) | Loss: 0.9749 | Batch time: 0.03s
2025-03-02 21:04:44,308 - INFO - [TRAIN] Epoch: 26/30 | Batch: 45/452 (10.2%) | Loss: 0.8187 | Batch time: 0.03s
2025-03-02 21:04:45,654 - INFO - [TRAIN] Epoch: 26/30 | Batch: 90/452 (20.1%) | Loss: 0.8789 | Batch time: 0.03s
2025-03-02 21:04:46,976 - INFO - [TRAIN] Epoch: 26/30 | Batch: 135/452 (30.1%) | Loss: 0.7461 | Batch time: 0.03s
2025-03-02 21:04:48,291 - INFO - [TRAIN] Epoch: 26/30 | Batch: 180/452 (40.0%) | Loss: 0.9650 | Batch time: 0.03s
2025-03-02 21:04:49,569 - INFO - [TRAIN] Epoch: 26/30 | Batch: 225/452 (50.0%) | Loss: 0.7113 | Batch time: 0.03s
2025-03-02 21:04:50,844 - INFO - [TRAIN] Epoch: 26/30 | Batch: 270/452 (60.0%) | Loss: 0.5812 | Batch time: 0.03s
2025-03-02 21:04:52,126 - INFO - [TRAIN] Epoch: 26/30 | Batch: 315/452 (69.9%) | Loss: 1.0996 | Batch time: 0.03s
2025-03-02 21:04:53,416 - INFO - [TRAIN] Epoch: 26/30 | Batch: 360/452 (79.9%) | Loss: 0.8911 | Batch time: 0.03s
2025-03-02 21:04:54,822 - INFO - [TRAIN] Epoch: 26/30 | Batch: 405/452 (89.8%) | Loss: 1.1554 | Batch time: 0.03s
2025-03-02 21:04:55,801 - INFO - [TRAIN] Epoch: 26/30 | Batch: 450/452 (99.8%) | Loss: 0.6158 | Batch time: 0.02s
2025-03-02 21:04:55,814 - INFO - [TRAIN] Epoch: 26/30 | Batch: 451/452 (100.0%) | Loss: 1.2916 | Batch time: 0.01s
2025-03-02 21:04:55,907 - INFO - [VAL] Epoch: 26/30 | Batch: 0/97 (1.0%) | Loss: 0.3560 | Batch time: 0.02s
2025-03-02 21:04:56,052 - INFO - [VAL] Epoch: 26/30 | Batch: 9/97 (10.3%) | Loss: 0.4922 | Batch time: 0.01s
2025-03-02 21:04:56,181 - INFO - [VAL] Epoch: 26/30 | Batch: 18/97 (19.6%) | Loss: 0.2403 | Batch time: 0.01s
2025-03-02 21:04:56,308 - INFO - [VAL] Epoch: 26/30 | Batch: 27/97 (28.9%) | Loss: 0.4513 | Batch time: 0.01s
2025-03-02 21:04:56,438 - INFO - [VAL] Epoch: 26/30 | Batch: 36/97 (38.1%) | Loss: 0.3910 | Batch time: 0.01s
2025-03-02 21:04:56,570 - INFO - [VAL] Epoch: 26/30 | Batch: 45/97 (47.4%) | Loss: 0.2991 | Batch time: 0.01s
2025-03-02 21:04:56,701 - INFO - [VAL] Epoch: 26/30 | Batch: 54/97 (56.7%) | Loss: 0.4770 | Batch time: 0.01s
2025-03-02 21:04:56,834 - INFO - [VAL] Epoch: 26/30 | Batch: 63/97 (66.0%) | Loss: 0.3321 | Batch time: 0.01s
2025-03-02 21:04:56,968 - INFO - [VAL] Epoch: 26/30 | Batch: 72/97 (75.3%) | Loss: 0.4648 | Batch time: 0.01s
2025-03-02 21:04:57,099 - INFO - [VAL] Epoch: 26/30 | Batch: 81/97 (84.5%) | Loss: 0.2845 | Batch time: 0.01s
2025-03-02 21:04:57,232 - INFO - [VAL] Epoch: 26/30 | Batch: 90/97 (93.8%) | Loss: 0.5069 | Batch time: 0.02s
2025-03-02 21:04:57,317 - INFO - [VAL] Epoch: 26/30 | Batch: 96/97 (100.0%) | Loss: 0.5689 | Batch time: 0.01s
2025-03-02 21:04:57,321 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:57,321 - INFO - Epoch 26/30 completed in 14.74s
2025-03-02 21:04:57,322 - INFO - Training   - Loss: 0.8538, Accuracy: 0.7258, F1: 0.7291
2025-03-02 21:04:57,322 - INFO - Validation - Loss: 0.4543, Accuracy: 0.8618, F1: 0.8611
2025-03-02 21:04:57,322 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:04:57,322 - INFO - Epoch 27/30
2025-03-02 21:04:57,322 - INFO - ----------------------------------------
2025-03-02 21:04:57,688 - INFO - [TRAIN] Epoch: 27/30 | Batch: 0/452 (0.2%) | Loss: 0.4111 | Batch time: 0.05s
2025-03-02 21:04:59,306 - INFO - [TRAIN] Epoch: 27/30 | Batch: 45/452 (10.2%) | Loss: 1.1025 | Batch time: 0.02s
2025-03-02 21:05:00,604 - INFO - [TRAIN] Epoch: 27/30 | Batch: 90/452 (20.1%) | Loss: 0.7530 | Batch time: 0.03s
2025-03-02 21:05:01,957 - INFO - [TRAIN] Epoch: 27/30 | Batch: 135/452 (30.1%) | Loss: 0.7981 | Batch time: 0.03s
2025-03-02 21:05:03,262 - INFO - [TRAIN] Epoch: 27/30 | Batch: 180/452 (40.0%) | Loss: 0.5842 | Batch time: 0.03s
2025-03-02 21:05:04,540 - INFO - [TRAIN] Epoch: 27/30 | Batch: 225/452 (50.0%) | Loss: 0.6901 | Batch time: 0.02s
2025-03-02 21:05:05,850 - INFO - [TRAIN] Epoch: 27/30 | Batch: 270/452 (60.0%) | Loss: 0.6208 | Batch time: 0.03s
2025-03-02 21:05:07,164 - INFO - [TRAIN] Epoch: 27/30 | Batch: 315/452 (69.9%) | Loss: 1.0231 | Batch time: 0.03s
2025-03-02 21:05:08,448 - INFO - [TRAIN] Epoch: 27/30 | Batch: 360/452 (79.9%) | Loss: 0.7234 | Batch time: 0.03s
2025-03-02 21:05:09,709 - INFO - [TRAIN] Epoch: 27/30 | Batch: 405/452 (89.8%) | Loss: 0.8839 | Batch time: 0.03s
2025-03-02 21:05:10,737 - INFO - [TRAIN] Epoch: 27/30 | Batch: 450/452 (99.8%) | Loss: 0.8778 | Batch time: 0.02s
2025-03-02 21:05:10,750 - INFO - [TRAIN] Epoch: 27/30 | Batch: 451/452 (100.0%) | Loss: 0.9238 | Batch time: 0.01s
2025-03-02 21:05:10,848 - INFO - [VAL] Epoch: 27/30 | Batch: 0/97 (1.0%) | Loss: 0.2945 | Batch time: 0.02s
2025-03-02 21:05:10,987 - INFO - [VAL] Epoch: 27/30 | Batch: 9/97 (10.3%) | Loss: 0.4690 | Batch time: 0.01s
2025-03-02 21:05:11,115 - INFO - [VAL] Epoch: 27/30 | Batch: 18/97 (19.6%) | Loss: 0.2373 | Batch time: 0.01s
2025-03-02 21:05:11,243 - INFO - [VAL] Epoch: 27/30 | Batch: 27/97 (28.9%) | Loss: 0.4084 | Batch time: 0.01s
2025-03-02 21:05:11,372 - INFO - [VAL] Epoch: 27/30 | Batch: 36/97 (38.1%) | Loss: 0.3690 | Batch time: 0.01s
2025-03-02 21:05:11,504 - INFO - [VAL] Epoch: 27/30 | Batch: 45/97 (47.4%) | Loss: 0.3039 | Batch time: 0.01s
2025-03-02 21:05:11,636 - INFO - [VAL] Epoch: 27/30 | Batch: 54/97 (56.7%) | Loss: 0.4671 | Batch time: 0.01s
2025-03-02 21:05:11,769 - INFO - [VAL] Epoch: 27/30 | Batch: 63/97 (66.0%) | Loss: 0.3420 | Batch time: 0.01s
2025-03-02 21:05:11,898 - INFO - [VAL] Epoch: 27/30 | Batch: 72/97 (75.3%) | Loss: 0.4603 | Batch time: 0.01s
2025-03-02 21:05:12,027 - INFO - [VAL] Epoch: 27/30 | Batch: 81/97 (84.5%) | Loss: 0.2845 | Batch time: 0.01s
2025-03-02 21:05:12,156 - INFO - [VAL] Epoch: 27/30 | Batch: 90/97 (93.8%) | Loss: 0.4657 | Batch time: 0.01s
2025-03-02 21:05:12,239 - INFO - [VAL] Epoch: 27/30 | Batch: 96/97 (100.0%) | Loss: 0.5475 | Batch time: 0.01s
2025-03-02 21:05:12,243 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:12,243 - INFO - Epoch 27/30 completed in 14.92s
2025-03-02 21:05:12,243 - INFO - Training   - Loss: 0.8585, Accuracy: 0.7216, F1: 0.7245
2025-03-02 21:05:12,243 - INFO - Validation - Loss: 0.4413, Accuracy: 0.8669, F1: 0.8664
2025-03-02 21:05:12,243 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:12,243 - INFO - Epoch 28/30
2025-03-02 21:05:12,243 - INFO - ----------------------------------------
2025-03-02 21:05:12,500 - INFO - [TRAIN] Epoch: 28/30 | Batch: 0/452 (0.2%) | Loss: 0.6204 | Batch time: 0.04s
2025-03-02 21:05:13,952 - INFO - [TRAIN] Epoch: 28/30 | Batch: 45/452 (10.2%) | Loss: 0.8577 | Batch time: 0.03s
2025-03-02 21:05:15,337 - INFO - [TRAIN] Epoch: 28/30 | Batch: 90/452 (20.1%) | Loss: 0.6811 | Batch time: 0.03s
2025-03-02 21:05:16,657 - INFO - [TRAIN] Epoch: 28/30 | Batch: 135/452 (30.1%) | Loss: 0.7297 | Batch time: 0.02s
2025-03-02 21:05:17,973 - INFO - [TRAIN] Epoch: 28/30 | Batch: 180/452 (40.0%) | Loss: 1.2110 | Batch time: 0.03s
2025-03-02 21:05:19,422 - INFO - [TRAIN] Epoch: 28/30 | Batch: 225/452 (50.0%) | Loss: 0.6146 | Batch time: 0.04s
2025-03-02 21:05:20,720 - INFO - [TRAIN] Epoch: 28/30 | Batch: 270/452 (60.0%) | Loss: 1.0657 | Batch time: 0.03s
2025-03-02 21:05:21,998 - INFO - [TRAIN] Epoch: 28/30 | Batch: 315/452 (69.9%) | Loss: 0.7490 | Batch time: 0.03s
2025-03-02 21:05:23,272 - INFO - [TRAIN] Epoch: 28/30 | Batch: 360/452 (79.9%) | Loss: 1.2044 | Batch time: 0.03s
2025-03-02 21:05:24,487 - INFO - [TRAIN] Epoch: 28/30 | Batch: 405/452 (89.8%) | Loss: 0.7440 | Batch time: 0.04s
2025-03-02 21:05:25,499 - INFO - [TRAIN] Epoch: 28/30 | Batch: 450/452 (99.8%) | Loss: 0.9176 | Batch time: 0.02s
2025-03-02 21:05:25,513 - INFO - [TRAIN] Epoch: 28/30 | Batch: 451/452 (100.0%) | Loss: 0.8343 | Batch time: 0.01s
2025-03-02 21:05:25,597 - INFO - [VAL] Epoch: 28/30 | Batch: 0/97 (1.0%) | Loss: 0.3300 | Batch time: 0.02s
2025-03-02 21:05:25,732 - INFO - [VAL] Epoch: 28/30 | Batch: 9/97 (10.3%) | Loss: 0.4901 | Batch time: 0.01s
2025-03-02 21:05:25,860 - INFO - [VAL] Epoch: 28/30 | Batch: 18/97 (19.6%) | Loss: 0.2276 | Batch time: 0.01s
2025-03-02 21:05:25,987 - INFO - [VAL] Epoch: 28/30 | Batch: 27/97 (28.9%) | Loss: 0.4372 | Batch time: 0.01s
2025-03-02 21:05:26,117 - INFO - [VAL] Epoch: 28/30 | Batch: 36/97 (38.1%) | Loss: 0.4025 | Batch time: 0.01s
2025-03-02 21:05:26,249 - INFO - [VAL] Epoch: 28/30 | Batch: 45/97 (47.4%) | Loss: 0.3180 | Batch time: 0.01s
2025-03-02 21:05:26,382 - INFO - [VAL] Epoch: 28/30 | Batch: 54/97 (56.7%) | Loss: 0.4677 | Batch time: 0.01s
2025-03-02 21:05:26,515 - INFO - [VAL] Epoch: 28/30 | Batch: 63/97 (66.0%) | Loss: 0.3874 | Batch time: 0.01s
2025-03-02 21:05:26,644 - INFO - [VAL] Epoch: 28/30 | Batch: 72/97 (75.3%) | Loss: 0.4961 | Batch time: 0.01s
2025-03-02 21:05:26,773 - INFO - [VAL] Epoch: 28/30 | Batch: 81/97 (84.5%) | Loss: 0.2955 | Batch time: 0.01s
2025-03-02 21:05:26,900 - INFO - [VAL] Epoch: 28/30 | Batch: 90/97 (93.8%) | Loss: 0.4758 | Batch time: 0.01s
2025-03-02 21:05:26,981 - INFO - [VAL] Epoch: 28/30 | Batch: 96/97 (100.0%) | Loss: 0.5890 | Batch time: 0.01s
2025-03-02 21:05:26,985 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:26,985 - INFO - Epoch 28/30 completed in 14.74s
2025-03-02 21:05:26,985 - INFO - Training   - Loss: 0.8616, Accuracy: 0.7241, F1: 0.7270
2025-03-02 21:05:26,985 - INFO - Validation - Loss: 0.4545, Accuracy: 0.8614, F1: 0.8606
2025-03-02 21:05:26,985 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:26,985 - INFO - Epoch 29/30
2025-03-02 21:05:26,985 - INFO - ----------------------------------------
2025-03-02 21:05:27,199 - INFO - [TRAIN] Epoch: 29/30 | Batch: 0/452 (0.2%) | Loss: 1.2687 | Batch time: 0.03s
2025-03-02 21:05:28,565 - INFO - [TRAIN] Epoch: 29/30 | Batch: 45/452 (10.2%) | Loss: 1.1001 | Batch time: 0.03s
2025-03-02 21:05:29,766 - INFO - [TRAIN] Epoch: 29/30 | Batch: 90/452 (20.1%) | Loss: 1.4527 | Batch time: 0.03s
2025-03-02 21:05:30,969 - INFO - [TRAIN] Epoch: 29/30 | Batch: 135/452 (30.1%) | Loss: 0.5419 | Batch time: 0.02s
2025-03-02 21:05:32,199 - INFO - [TRAIN] Epoch: 29/30 | Batch: 180/452 (40.0%) | Loss: 0.9826 | Batch time: 0.03s
2025-03-02 21:05:33,385 - INFO - [TRAIN] Epoch: 29/30 | Batch: 225/452 (50.0%) | Loss: 1.1462 | Batch time: 0.02s
2025-03-02 21:05:34,590 - INFO - [TRAIN] Epoch: 29/30 | Batch: 270/452 (60.0%) | Loss: 0.8267 | Batch time: 0.03s
2025-03-02 21:05:35,806 - INFO - [TRAIN] Epoch: 29/30 | Batch: 315/452 (69.9%) | Loss: 0.9845 | Batch time: 0.03s
2025-03-02 21:05:37,029 - INFO - [TRAIN] Epoch: 29/30 | Batch: 360/452 (79.9%) | Loss: 1.1692 | Batch time: 0.03s
2025-03-02 21:05:38,257 - INFO - [TRAIN] Epoch: 29/30 | Batch: 405/452 (89.8%) | Loss: 0.6989 | Batch time: 0.03s
2025-03-02 21:05:39,268 - INFO - [TRAIN] Epoch: 29/30 | Batch: 450/452 (99.8%) | Loss: 1.0007 | Batch time: 0.02s
2025-03-02 21:05:39,282 - INFO - [TRAIN] Epoch: 29/30 | Batch: 451/452 (100.0%) | Loss: 0.7629 | Batch time: 0.01s
2025-03-02 21:05:39,370 - INFO - [VAL] Epoch: 29/30 | Batch: 0/97 (1.0%) | Loss: 0.2732 | Batch time: 0.02s
2025-03-02 21:05:39,501 - INFO - [VAL] Epoch: 29/30 | Batch: 9/97 (10.3%) | Loss: 0.4417 | Batch time: 0.01s
2025-03-02 21:05:39,626 - INFO - [VAL] Epoch: 29/30 | Batch: 18/97 (19.6%) | Loss: 0.2260 | Batch time: 0.01s
2025-03-02 21:05:39,751 - INFO - [VAL] Epoch: 29/30 | Batch: 27/97 (28.9%) | Loss: 0.3770 | Batch time: 0.01s
2025-03-02 21:05:39,878 - INFO - [VAL] Epoch: 29/30 | Batch: 36/97 (38.1%) | Loss: 0.3773 | Batch time: 0.01s
2025-03-02 21:05:40,008 - INFO - [VAL] Epoch: 29/30 | Batch: 45/97 (47.4%) | Loss: 0.2924 | Batch time: 0.01s
2025-03-02 21:05:40,138 - INFO - [VAL] Epoch: 29/30 | Batch: 54/97 (56.7%) | Loss: 0.4588 | Batch time: 0.01s
2025-03-02 21:05:40,268 - INFO - [VAL] Epoch: 29/30 | Batch: 63/97 (66.0%) | Loss: 0.3252 | Batch time: 0.01s
2025-03-02 21:05:40,394 - INFO - [VAL] Epoch: 29/30 | Batch: 72/97 (75.3%) | Loss: 0.4638 | Batch time: 0.01s
2025-03-02 21:05:40,521 - INFO - [VAL] Epoch: 29/30 | Batch: 81/97 (84.5%) | Loss: 0.2859 | Batch time: 0.01s
2025-03-02 21:05:40,648 - INFO - [VAL] Epoch: 29/30 | Batch: 90/97 (93.8%) | Loss: 0.4540 | Batch time: 0.01s
2025-03-02 21:05:40,730 - INFO - [VAL] Epoch: 29/30 | Batch: 96/97 (100.0%) | Loss: 0.4967 | Batch time: 0.01s
2025-03-02 21:05:40,734 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:40,734 - INFO - Epoch 29/30 completed in 13.75s
2025-03-02 21:05:40,734 - INFO - Training   - Loss: 0.8473, Accuracy: 0.7286, F1: 0.7317
2025-03-02 21:05:40,734 - INFO - Validation - Loss: 0.4221, Accuracy: 0.8705, F1: 0.8702
2025-03-02 21:05:40,734 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:40,734 - INFO - Epoch 30/30
2025-03-02 21:05:40,734 - INFO - ----------------------------------------
2025-03-02 21:05:40,960 - INFO - [TRAIN] Epoch: 30/30 | Batch: 0/452 (0.2%) | Loss: 0.8175 | Batch time: 0.03s
2025-03-02 21:05:42,367 - INFO - [TRAIN] Epoch: 30/30 | Batch: 45/452 (10.2%) | Loss: 0.6835 | Batch time: 0.03s
2025-03-02 21:05:43,578 - INFO - [TRAIN] Epoch: 30/30 | Batch: 90/452 (20.1%) | Loss: 0.9182 | Batch time: 0.03s
2025-03-02 21:05:44,799 - INFO - [TRAIN] Epoch: 30/30 | Batch: 135/452 (30.1%) | Loss: 0.5762 | Batch time: 0.03s
2025-03-02 21:05:46,019 - INFO - [TRAIN] Epoch: 30/30 | Batch: 180/452 (40.0%) | Loss: 0.5811 | Batch time: 0.03s
2025-03-02 21:05:47,278 - INFO - [TRAIN] Epoch: 30/30 | Batch: 225/452 (50.0%) | Loss: 0.5935 | Batch time: 0.03s
2025-03-02 21:05:48,496 - INFO - [TRAIN] Epoch: 30/30 | Batch: 270/452 (60.0%) | Loss: 0.5704 | Batch time: 0.03s
2025-03-02 21:05:49,779 - INFO - [TRAIN] Epoch: 30/30 | Batch: 315/452 (69.9%) | Loss: 0.7017 | Batch time: 0.03s
2025-03-02 21:05:51,045 - INFO - [TRAIN] Epoch: 30/30 | Batch: 360/452 (79.9%) | Loss: 0.6121 | Batch time: 0.03s
2025-03-02 21:05:52,277 - INFO - [TRAIN] Epoch: 30/30 | Batch: 405/452 (89.8%) | Loss: 0.8879 | Batch time: 0.03s
2025-03-02 21:05:53,267 - INFO - [TRAIN] Epoch: 30/30 | Batch: 450/452 (99.8%) | Loss: 0.8676 | Batch time: 0.02s
2025-03-02 21:05:53,281 - INFO - [TRAIN] Epoch: 30/30 | Batch: 451/452 (100.0%) | Loss: 0.8555 | Batch time: 0.01s
2025-03-02 21:05:53,365 - INFO - [VAL] Epoch: 30/30 | Batch: 0/97 (1.0%) | Loss: 0.2881 | Batch time: 0.02s
2025-03-02 21:05:53,499 - INFO - [VAL] Epoch: 30/30 | Batch: 9/97 (10.3%) | Loss: 0.4564 | Batch time: 0.01s
2025-03-02 21:05:53,626 - INFO - [VAL] Epoch: 30/30 | Batch: 18/97 (19.6%) | Loss: 0.2321 | Batch time: 0.01s
2025-03-02 21:05:53,750 - INFO - [VAL] Epoch: 30/30 | Batch: 27/97 (28.9%) | Loss: 0.3876 | Batch time: 0.01s
2025-03-02 21:05:53,876 - INFO - [VAL] Epoch: 30/30 | Batch: 36/97 (38.1%) | Loss: 0.3610 | Batch time: 0.01s
2025-03-02 21:05:54,002 - INFO - [VAL] Epoch: 30/30 | Batch: 45/97 (47.4%) | Loss: 0.3084 | Batch time: 0.01s
2025-03-02 21:05:54,129 - INFO - [VAL] Epoch: 30/30 | Batch: 54/97 (56.7%) | Loss: 0.4520 | Batch time: 0.01s
2025-03-02 21:05:54,256 - INFO - [VAL] Epoch: 30/30 | Batch: 63/97 (66.0%) | Loss: 0.2923 | Batch time: 0.01s
2025-03-02 21:05:54,383 - INFO - [VAL] Epoch: 30/30 | Batch: 72/97 (75.3%) | Loss: 0.4571 | Batch time: 0.01s
2025-03-02 21:05:54,509 - INFO - [VAL] Epoch: 30/30 | Batch: 81/97 (84.5%) | Loss: 0.2643 | Batch time: 0.01s
2025-03-02 21:05:54,632 - INFO - [VAL] Epoch: 30/30 | Batch: 90/97 (93.8%) | Loss: 0.4273 | Batch time: 0.01s
2025-03-02 21:05:54,711 - INFO - [VAL] Epoch: 30/30 | Batch: 96/97 (100.0%) | Loss: 0.5084 | Batch time: 0.01s
2025-03-02 21:05:54,714 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:54,714 - INFO - Epoch 30/30 completed in 13.98s
2025-03-02 21:05:54,714 - INFO - Training   - Loss: 0.8297, Accuracy: 0.7260, F1: 0.7287
2025-03-02 21:05:54,714 - INFO - Validation - Loss: 0.4294, Accuracy: 0.8721, F1: 0.8715
2025-03-02 21:05:54,714 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:54,772 - INFO - Checkpoint saved: checkpoint_epoch_30.pth (Epoch 30)
2025-03-02 21:05:54,772 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:54,772 - INFO - Training completed in 0h 7m 15.24s
2025-03-02 21:05:54,772 - INFO - Best validation F1: 0.8716 (Epoch 14)
2025-03-02 21:05:54,772 - INFO - --------------------------------------------------------------------------------
2025-03-02 21:05:55,157 - INFO - Final model saved to models/mobilenet_v2_v1/models/mobilenet_v2_v2_final.pth
